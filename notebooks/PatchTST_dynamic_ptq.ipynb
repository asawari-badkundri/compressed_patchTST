{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNhN1ZIShaCz",
        "outputId": "a8718a49-fe5c-4fc6-dfd5-d71690db85f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Using cached torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qoiO7Hl6-AxM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch import Tensor\n",
        "from typing import Callable, Optional\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch.quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9R5Qin7v-AxN",
        "outputId": "c2ef353c-43b4-47ad-ea77-835117eb1fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n"
          ]
        }
      ],
      "source": [
        "df_ETTh1 = pd.read_csv(\"/content/ETTh1.csv\")\n",
        "print(df_ETTh1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ggcvYGy-AxO"
      },
      "outputs": [],
      "source": [
        "df_ETTh1.iloc[:,1:].shape, df_ETTh1.shape, 12 * 30 * 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QpWkZWJK-AxO"
      },
      "outputs": [],
      "source": [
        "class ETTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset=\"ETTh1\", mode=\"train\", scale=True, seq_len=336, pred_len=96):\n",
        "        super().__init__()\n",
        "        df = pd.read_csv(\"/content/ETTh1.csv\".format(dataset))\n",
        "        x_y = df.iloc[:,1:]\n",
        "        time_stamp = df.iloc[:,0]\n",
        "\n",
        "        assert mode in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[mode]\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if scale:\n",
        "            train_x_y = x_y.iloc[border1s[0]: border2s[0]]\n",
        "            self.ss = StandardScaler()\n",
        "            self.ss.fit(train_x_y.to_numpy(dtype=np.float32))\n",
        "            x_y = self.ss.transform(x_y.to_numpy(dtype=np.float32))\n",
        "        else:\n",
        "            x_y = x_y.to_numpy(dtype=np.float32)\n",
        "\n",
        "        time_stamp = time_stamp.to_numpy()\n",
        "\n",
        "        self.data_x = x_y[border1: border2, :]\n",
        "        self.data_y = x_y[border1: border2, -1]\n",
        "\n",
        "        self.data_stamp = time_stamp[border1: border2]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end\n",
        "        r_end = r_begin + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        return seq_x, seq_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.ss.inverse_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LNP6-hQ2-AxP"
      },
      "outputs": [],
      "source": [
        "#Revin.py\n",
        "class RevIN(torch.nn.Module):\n",
        "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
        "        \"\"\"\n",
        "        :param num_features: the number of features or channels\n",
        "        :param eps: a value added for numerical stability\n",
        "        :param affine: if True, RevIN has learnable affine parameters\n",
        "        \"\"\"\n",
        "        super(RevIN, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.affine = affine\n",
        "        self.subtract_last = subtract_last\n",
        "        if self.affine:\n",
        "            self._init_params()\n",
        "\n",
        "    def forward(self, x, mode:str):\n",
        "        if mode == 'norm':\n",
        "            self._get_statistics(x)\n",
        "            x = self._normalize(x)\n",
        "        elif mode == 'denorm':\n",
        "            x = self._denormalize(x)\n",
        "        else: raise NotImplementedError\n",
        "        return x\n",
        "\n",
        "    def _init_params(self):\n",
        "        # initialize RevIN params: (C,)\n",
        "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
        "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
        "\n",
        "    def _get_statistics(self, x):\n",
        "        dim2reduce = tuple(range(1, x.ndim-1))\n",
        "        if self.subtract_last:\n",
        "            self.last = x[:,-1,:].unsqueeze(1)\n",
        "        else:\n",
        "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
        "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
        "\n",
        "    def _normalize(self, x):\n",
        "        if self.subtract_last:\n",
        "            x = x - self.last\n",
        "        else:\n",
        "            x = x - self.mean\n",
        "        x = x / self.stdev\n",
        "        if self.affine:\n",
        "            # print(f'x.mT.shape: {x.mT.shape} | self.affine_weight: {self.affine_weight.shape}')\n",
        "            x = x * self.affine_weight + self.affine_bias\n",
        "            # print(f'x.shape: {x.shape} | self.affine_weight: {self.affine_bias.shape}')\n",
        "            # x = x + self.affine_bias\n",
        "        return x.mT\n",
        "\n",
        "    def _denormalize(self, x):\n",
        "        if self.affine:\n",
        "            x = x - self.affine_bias\n",
        "            x = x / (self.affine_weight + self.eps*self.eps)\n",
        "        x = x * self.stdev\n",
        "        if self.subtract_last:\n",
        "            x = x + self.last\n",
        "        else:\n",
        "            x = x + self.mean\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lADgBb5r-AxP"
      },
      "outputs": [],
      "source": [
        "#PatchTST_layers.py\n",
        "class Transpose(torch.nn.Module):\n",
        "    def __init__(self, *dims, contiguous=False):\n",
        "        super().__init__()\n",
        "        self.dims, self.contiguous = dims, contiguous\n",
        "    def forward(self, x):\n",
        "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
        "        else: return x.transpose(*self.dims)\n",
        "\n",
        "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
        "    # Positional encoding\n",
        "    if pe == None:\n",
        "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "        learn_pe = False\n",
        "    elif pe == 'zero':\n",
        "        W_pos = torch.empty((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'zeros':\n",
        "        W_pos = torch.empty((q_len, d_model))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'normal' or pe == 'gauss':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
        "    elif pe == 'uniform':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
        "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
        "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
        "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
        "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
        "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
        "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
        "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
        "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1QYXGH1v-AxP"
      },
      "outputs": [],
      "source": [
        "#PatchTST_backbone.py\n",
        "class TSTiEncoder(torch.nn.Module):  #i means channel-independent\n",
        "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
        "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
        "                 d_ff=128, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
        "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
        "                 pe='zeros', learn_pe=True, verbose=False, **kwargs):\n",
        "                 #act=\"gelu\"\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_num = patch_num\n",
        "        self.patch_len = patch_len\n",
        "\n",
        "        # Input encoding\n",
        "        q_len = patch_num\n",
        "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
        "        self.seq_len = q_len\n",
        "\n",
        "        # Positional encoding\n",
        "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
        "\n",
        "        # Residual dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
        "\n",
        "\n",
        "    def forward(self, x) -> Tensor:                                              # x: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        n_vars = x.shape[1]\n",
        "        # Input encoding\n",
        "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
        "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
        "\n",
        "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
        "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
        "\n",
        "        # Encoder\n",
        "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
        "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
        "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "# Cell\n",
        "class TSTEncoder(torch.nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None,\n",
        "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
        "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
        "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                                      activation=activation, res_attention=res_attention,\n",
        "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
        "        self.res_attention = res_attention\n",
        "\n",
        "    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        output = src\n",
        "        scores = None\n",
        "        if self.res_attention:\n",
        "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "        else:\n",
        "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "\n",
        "\n",
        "\n",
        "class TSTEncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=128, store_attn=False,\n",
        "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
        "        super().__init__()\n",
        "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        # Multi-Head attention\n",
        "        self.res_attention = res_attention\n",
        "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_attn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_attn = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Position-wise Feed-Forward\n",
        "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
        "                                torch.nn.GELU(),\n",
        "                                nn.Dropout(dropout),\n",
        "                                nn.Linear(d_ff, d_model, bias=bias))\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_ffn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_ffn = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.pre_norm = pre_norm\n",
        "        self.store_attn = store_attn\n",
        "\n",
        "\n",
        "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
        "\n",
        "        # Multi-Head attention sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "        ## Multi-Head attention\n",
        "        if self.res_attention:\n",
        "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        if self.store_attn:\n",
        "            self.attn = attn\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "\n",
        "        # Feed-forward sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "        ## Position-wise Feed-Forward\n",
        "        src2 = self.ff(src)\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "\n",
        "        if self.res_attention:\n",
        "            return src, scores\n",
        "        else:\n",
        "            return src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OQjdKQf0-AxQ"
      },
      "outputs": [],
      "source": [
        "class _MultiheadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
        "        \"\"\"Multi Head Attention Layer\n",
        "        Input shape:\n",
        "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
        "            K, V:    [batch_size (bs) x q_len x d_model]\n",
        "            mask:    [q_len x q_len]\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
        "\n",
        "        # Scaled Dot-Product Attention (multiple heads)\n",
        "        self.res_attention = res_attention\n",
        "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
        "\n",
        "        # Poject output\n",
        "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
        "\n",
        "\n",
        "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,\n",
        "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "\n",
        "        bs = Q.size(0)\n",
        "        if K is None: K = Q\n",
        "        if V is None: V = Q\n",
        "\n",
        "        # Linear (+ split in multiple heads)\n",
        "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
        "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
        "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
        "\n",
        "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
        "        if self.res_attention:\n",
        "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # back to the original inputs dimensions\n",
        "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
        "        output = self.to_out(output)\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SvWR3zdH-AxQ"
      },
      "outputs": [],
      "source": [
        "class _ScaledDotProductAttention(torch.nn.Module):\n",
        "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
        "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
        "    by Lee et al, 2021)\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
        "        super().__init__()\n",
        "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
        "        self.res_attention = res_attention\n",
        "        head_dim = d_model // n_heads\n",
        "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
        "        self.lsa = lsa\n",
        "\n",
        "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        '''\n",
        "        Input shape:\n",
        "            q               : [bs x n_heads x max_q_len x d_k]\n",
        "            k               : [bs x n_heads x d_k x seq_len]\n",
        "            v               : [bs x n_heads x seq_len x d_v]\n",
        "            prev            : [bs x n_heads x q_len x seq_len]\n",
        "            key_padding_mask: [bs x seq_len]\n",
        "            attn_mask       : [1 x seq_len x seq_len]\n",
        "        Output shape:\n",
        "            output:  [bs x n_heads x q_len x d_v]\n",
        "            attn   : [bs x n_heads x q_len x seq_len]\n",
        "            scores : [bs x n_heads x q_len x seq_len]\n",
        "        '''\n",
        "\n",
        "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
        "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # Add pre-softmax attention scores from the previous layer (optional)\n",
        "        if prev is not None: attn_scores = attn_scores + prev\n",
        "\n",
        "        # Attention mask (optional)\n",
        "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
        "            if attn_mask.dtype == torch.bool:\n",
        "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
        "            else:\n",
        "                attn_scores += attn_mask\n",
        "\n",
        "        # Key padding mask (optional)\n",
        "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
        "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
        "\n",
        "        # normalize the attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # compute the new values given the attention weights\n",
        "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_jJViV8P-AxQ"
      },
      "outputs": [],
      "source": [
        "class Flatten_Head(torch.nn.Module):\n",
        "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.individual = individual\n",
        "        self.n_vars = n_vars\n",
        "\n",
        "        if self.individual:\n",
        "            self.linears = nn.ModuleList()\n",
        "            self.dropouts = nn.ModuleList()\n",
        "            self.flattens = nn.ModuleList()\n",
        "            for i in range(self.n_vars):\n",
        "                self.flattens.append(nn.Flatten(start_dim=-2)) #flattens last 2\n",
        "                self.linears.append(nn.Linear(nf, target_window))\n",
        "                self.dropouts.append(nn.Dropout(head_dropout))\n",
        "        else:\n",
        "            self.flatten = nn.Flatten(start_dim=-2)\n",
        "            self.linear = nn.Linear(nf, target_window)\n",
        "            self.dropout = nn.Dropout(head_dropout)\n",
        "\n",
        "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
        "        if self.individual:\n",
        "            x_out = []\n",
        "            for i in range(self.n_vars):\n",
        "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
        "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
        "                z = self.dropouts[i](z)\n",
        "                x_out.append(z)\n",
        "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
        "        else:\n",
        "            x = self.flatten(x)\n",
        "            x = self.linear(x)\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "#Implementation of PatchTST\n",
        "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n",
        "    x = .5 if exponential else 1\n",
        "    i = 0\n",
        "    for i in range(100):\n",
        "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
        "        pv(f'{i:4.0f}  {x:5.3f}  {cpe.mean():+6.3f}', verbose)\n",
        "        if abs(cpe.mean()) <= eps: break\n",
        "        elif cpe.mean() > eps: x += .001\n",
        "        else: x -= .001\n",
        "        i += 1\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
        "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "class PatchTST(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window, patch_len, stride, max_seq_len:Optional[int]=1024,\n",
        "                 n_layers=3, d_model=128, n_heads=4, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
        "                 d_ff:int=128, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0.3, act:str=\"gelu\", key_padding_mask:bool='auto',\n",
        "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
        "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0.3, head_dropout = 0, padding_patch = None,\n",
        "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
        "                 verbose:bool=False, **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # RevIn\n",
        "        self.revin = revin\n",
        "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
        "\n",
        "        # Patching\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.padding_patch = padding_patch\n",
        "        patch_num = int((context_window - patch_len)/stride + 1)\n",
        "        if padding_patch == 'end': # can be modified to general case\n",
        "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride))\n",
        "            patch_num += 1\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
        "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
        "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
        "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
        "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
        "\n",
        "        # Head\n",
        "        self.head_nf = d_model * patch_num\n",
        "        self.n_vars = c_in\n",
        "        self.pretrain_head = pretrain_head\n",
        "        self.head_type = head_type\n",
        "        self.individual = individual\n",
        "\n",
        "        if self.pretrain_head:\n",
        "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
        "        elif head_type == 'flatten':\n",
        "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
        "        # norm\n",
        "        if self.revin:\n",
        "            # z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'norm')\n",
        "            # z = z.permute(0,2,1)\n",
        "\n",
        "        # do patching\n",
        "        if self.padding_patch == 'end':\n",
        "            z = self.padding_patch_layer(z)\n",
        "        # print(f'z.shape: {z.shape}')\n",
        "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
        "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        # model\n",
        "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
        "        z = self.head(z)                                                                    # z: [bs x nvars x target_window]\n",
        "\n",
        "        # denorm\n",
        "        if self.revin:\n",
        "            z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'denorm')\n",
        "            # z = z.permute(0,2,1)\n",
        "        return z\n",
        "\n",
        "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
        "        return nn.Sequential(nn.Dropout(dropout),\n",
        "                    nn.Conv1d(head_nf, vars, 1)\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S_7jINE4-AxR"
      },
      "outputs": [],
      "source": [
        "#Linear model\n",
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window):\n",
        "        super().__init__()\n",
        "        self.c_in = c_in\n",
        "        self.context_winsoq = context_window\n",
        "        self.target_window = target_window\n",
        "\n",
        "        self.flatten = torch.nn.Flatten(start_dim=-2)\n",
        "\n",
        "        self.linear = torch.nn.Linear(c_in * context_window, target_window)\n",
        "\n",
        "    def forward(self, x):                   # x: [bs x seq_len Ã— nvars]\n",
        "        x = self.flatten(x)                 # x: [bs x seq_len * nvars]\n",
        "        x = self.linear(x)                  # x: [bs x target_window]\n",
        "        return x\n",
        "\n",
        "\n",
        "class moving_avg(torch.nn.Module):\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = torch.nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(torch.nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "class DLinear(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window):\n",
        "        super().__init__()\n",
        "        # Decompsition Kernel Size\n",
        "        kernel_size = 25\n",
        "        self.decompsition = series_decomp(kernel_size)\n",
        "        self.flatten_Seasonal = torch.nn.Flatten(start_dim=-2)\n",
        "        self.flatten_Trend = torch.nn.Flatten(start_dim=-2)\n",
        "\n",
        "        self.Linear_Seasonal = torch.nn.Linear(c_in * context_window, target_window)\n",
        "        self.Linear_Trend = torch.nn.Linear(c_in * context_window, target_window)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        seasonal_init, trend_init = self.decompsition(x)\n",
        "        seasonal_init = self.flatten_Seasonal(x)\n",
        "        trend_init = self.flatten_Trend(x)\n",
        "\n",
        "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
        "        trend_output = self.Linear_Trend(trend_init)\n",
        "\n",
        "        x = seasonal_output + trend_output\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ND6bur0m-Axa"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=100, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
        "        # self.model = model.to(\"cuda\")\n",
        "        self.model = model.to(\"cpu\")\n",
        "        self.batch_size = batch_size\n",
        "        train_dataset = dataset(mode=\"train\")\n",
        "        valid_dataset = dataset(mode=\"val\")\n",
        "        test_dataset = dataset(mode=\"test\")\n",
        "        self.train_datalen = len(train_dataset)\n",
        "        self.valid_datalen = len(valid_dataset)\n",
        "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        self.lr=lr\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.loss = torch.nn.MSELoss()\n",
        "        self.epochs = epochs\n",
        "        self.target_window=target_window\n",
        "        self.best_weight = self.model.state_dict()\n",
        "        self.d_model=d_model\n",
        "        self.adjust_lr = adjust_lr\n",
        "        self.adjust_factor = adjust_factor\n",
        "\n",
        "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
        "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
        "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
        "        else:\n",
        "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr_adjust\n",
        "        if printout:\n",
        "            print('Updating learning rate to {}'.format(lr_adjust))\n",
        "        return\n",
        "\n",
        "    def train(self):\n",
        "        best_valid_loss = np.inf\n",
        "        train_history = []\n",
        "        valid_history = []\n",
        "        train_steps = 1\n",
        "        if self.adjust_lr:\n",
        "            self.adjust_learning_rate(train_steps)\n",
        "        for epoch in range(self.epochs):\n",
        "            #train\n",
        "            self.model.train()\n",
        "            iter_count = 0\n",
        "            total_loss = 0\n",
        "\n",
        "            for train_x, train_y in self.train_dataloader:\n",
        "                # train_x = train_x.to(\"cuda\")\n",
        "                # train_y = train_y.to(\"cuda\")\n",
        "                train_x = train_x.to(\"cpu\")\n",
        "                train_y = train_y.to(\"cpu\")\n",
        "                # print(f'train_x.shape: {train_x.shape}')\n",
        "                pred_y = self.model(train_x)\n",
        "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                loss = self.loss(pred_y, train_y)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "                train_steps += 1\n",
        "            if self.adjust_lr:\n",
        "                self.adjust_learning_rate(train_steps)\n",
        "\n",
        "            #valid\n",
        "            self.model.eval()\n",
        "            valid_iter_count = 0\n",
        "            valid_total_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for valid_x, valid_y in self.valid_dataloader:\n",
        "                    # valid_x = valid_x.to(\"cuda\")\n",
        "                    # valid_y = valid_y.to(\"cuda\")\n",
        "                    valid_x = valid_x.to(\"cpu\")\n",
        "                    valid_y = valid_y.to(\"cpu\")\n",
        "                    pred_y = self.model(valid_x)\n",
        "                    pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                    loss = self.loss(pred_y, valid_y)\n",
        "                    valid_total_loss += loss.item()\n",
        "                    valid_iter_count += 1\n",
        "\n",
        "            total_loss /= iter_count\n",
        "            valid_total_loss /= valid_iter_count\n",
        "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
        "            if best_valid_loss >= valid_total_loss:\n",
        "                self.best_weight = self.model.state_dict()\n",
        "                best_valid_loss = valid_total_loss\n",
        "                print(\"Best score! Weights of the model are updated!\")\n",
        "            train_history.append(total_loss)\n",
        "            valid_history.append(valid_total_loss)\n",
        "        return train_history, valid_history\n",
        "\n",
        "    def test(self):\n",
        "        # self.model.load_state_dict(self.best_weight)\n",
        "        self.model.eval()\n",
        "        iter_count = 0\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for test_x, test_y in self.test_dataloader:\n",
        "                # test_x = test_x.to(\"cuda\")\n",
        "                # test_y = test_y.to(\"cuda\")\n",
        "                test_x = test_x.to(\"cpu\")\n",
        "                test_y = test_y.to(\"cpu\")\n",
        "                pred_y = self.model(test_x)\n",
        "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                loss = self.loss(pred_y, test_y)\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "        total_loss /= iter_count\n",
        "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
        "\n",
        "    def test_quantized_model(self):\n",
        "        self.model.eval()\n",
        "        iter_count = 0\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for test_x, test_y in self.test_dataloader:\n",
        "                test_x = test_x.to(\"cpu\")\n",
        "                test_y = test_y.to(\"cpu\")\n",
        "                # Perform inference using the quantized model\n",
        "                test_x = self.test_dataloader.dataset.quantizer.transform(test_x)\n",
        "                pred_y = self.model(test_x)\n",
        "                # Assuming the prediction is in the correct format, no further processing needed\n",
        "                # Calculate the loss\n",
        "                loss = self.loss(pred_y, test_y)\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "        total_loss /= iter_count\n",
        "        print(\"MSE test loss for quantized model: {:.4f}\".format(total_loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r4R3q_FF-Axb",
        "outputId": "cdd86d2f-5fa3-4d0b-96d0-d2e189682dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating learning rate to 4.811252243246882e-08\n",
            "Updating learning rate to 3.175426480542942e-06\n",
            "epoch: 0 MSE loss: 0.2329 MSE valid loss: 0.1329\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.302740438653415e-06\n",
            "epoch: 1 MSE loss: 0.2236 MSE valid loss: 0.1245\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 9.430054396763887e-06\n",
            "epoch: 2 MSE loss: 0.2082 MSE valid loss: 0.1152\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.2557368354874362e-05\n",
            "epoch: 3 MSE loss: 0.1931 MSE valid loss: 0.1087\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.3846219390542782e-05\n",
            "epoch: 4 MSE loss: 0.1835 MSE valid loss: 0.1046\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.264304343560434e-05\n",
            "epoch: 5 MSE loss: 0.1769 MSE valid loss: 0.1023\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.1707322644771175e-05\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-994547ff2b52>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# with profiler.profile(record_shapes=True, use_cuda=True) as prof:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpatchtst_train_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatchtst_valid_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatchtst_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-cd28605d870e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mvalid_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-418cec847dc7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m                                                                \u001b[0;31m# z: [bs x nvars x d_model x patch_num]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m                                                                    \u001b[0;31m# z: [bs x nvars x target_window]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2e1c4d548d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m                                                      \u001b[0;31m# z: [bs * nvars x patch_num x d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# z: [bs x nvars x patch_num x d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m                                                   \u001b[0;31m# z: [bs x nvars x d_model x patch_num]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2e1c4d548d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2e1c4d548d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, prev, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m## Multi-Head attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0msrc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0msrc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8f8a8b727b19>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, prev, key_padding_mask, attn_mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mq_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# q_s    : [bs x n_heads x max_q_len x d_k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mk_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mv_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# v_s    : [bs x n_heads x q_len x d_v]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Apply Scaled Dot-Product Attention (multiple heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "c_in = 7\n",
        "context_window = 336\n",
        "target_window = 96\n",
        "patch_len = 16\n",
        "stride = 8\n",
        "\n",
        "patchtst_model = PatchTST(c_in=c_in, context_window=context_window, target_window=target_window, patch_len=patch_len, stride=stride)\n",
        "\n",
        "# Linear_model = Linear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
        "# DLinear_model = DLinear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
        "\n",
        "# Linear_learner = Learner_2(model=Linear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
        "# DLinear_learner = Learner_2(model=DLinear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
        "patchtst_learner = Learner(model=patchtst_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
        "\n",
        "# Linear_train_history, Linear_valid_history = Linear_learner.train()\n",
        "# DLinear_train_history, DLinear_valid_history = DLinear_learner.train()\n",
        "# import torch.autograd.profiler as profiler\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
        "patchtst_train_history, patchtst_valid_history = patchtst_learner.train()\n",
        "\n",
        "end_time = time.perf_counter()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Elapsed Time:\", elapsed_time)\n",
        "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Techniques"
      ],
      "metadata": {
        "id": "KZwZyLsOPMO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_learner.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gz28atCO-aq",
        "outputId": "e4778501-7017-4df2-8867-7e8873f57fec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE test loss: 0.0587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "# import torchsummary"
      ],
      "metadata": {
        "id": "mQ5X0XDfUfmC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxy2PEbJcmj",
        "outputId": "4dc6efc3-f623-4246-d152-604aa0c10031"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTST(\n",
              "  (revin_layer): RevIN()\n",
              "  (backbone): TSTiEncoder(\n",
              "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (encoder): TSTEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-2): 3 x TSTEncoderLayer(\n",
              "          (self_attn): _MultiheadAttention(\n",
              "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sdp_attn): _ScaledDotProductAttention(\n",
              "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (1): Dropout(p=0.3, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_attn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "          (ff): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_ffn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Flatten_Head(\n",
              "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
              "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Memory and Time Usage"
      ],
      "metadata": {
        "id": "sO8YCi9qYNj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "grab a sample from the test dataloder"
      ],
      "metadata": {
        "id": "wXkvzCW8UOla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cpu')"
      ],
      "metadata": {
        "id": "Je-UKQlNTX3I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patchtst_model.eval()\n",
        "patchtst_model(next(iter(patchtst_learner.test_dataloader))[0].to('cpu')).squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qNEs840PO1I",
        "outputId": "97b3a22a-d212-4b6f-d45c-304a7f474b9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 96, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "ZurTHQ-BPNzf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIRaNODpM55s",
        "outputId": "4ffa439a-3557-4a08-eaca-37209a1eefaf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                 model_inference         0.97%      10.398ms       100.00%        1.071s        1.071s             1  \n",
            "                      aten::mean         0.00%      43.000us         0.04%     375.000us     375.000us             1  \n",
            "                       aten::sum         0.02%     248.000us         0.02%     254.000us     254.000us             1  \n",
            "                     aten::fill_         0.00%       9.000us         0.00%       9.000us       4.500us             2  \n",
            "                      aten::div_         0.00%      44.000us         0.01%      82.000us      41.000us             2  \n",
            "                        aten::to         0.00%      21.000us         0.01%     119.000us      29.750us             4  \n",
            "                  aten::_to_copy         0.01%      54.000us         0.01%      98.000us      24.500us             4  \n",
            "             aten::empty_strided         0.00%      16.000us         0.00%      16.000us       3.200us             5  \n",
            "                     aten::copy_        14.73%     157.743ms        14.73%     157.743ms       4.382ms            36  \n",
            "                    aten::detach         0.00%       8.000us         0.00%      21.000us      10.500us             2  \n",
            "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.071s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "patchtst_model_quantized = torch.quantization.quantize_dynamic(\n",
        "    patchtst_model, qconfig_spec={torch.nn.Linear}, dtype=torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "o_M7_Or7FIg_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "      patchtst_model_quantized.eval()\n",
        "      patchtst_model_quantized(input.to('cpu'))"
      ],
      "metadata": {
        "id": "C6-toPn0U0hy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybiaJXMlbdhX",
        "outputId": "86b9d381-5dc3-471a-b2a4-348d63e2332d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                              Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                   model_inference         1.22%      10.052ms       100.00%     821.935ms     821.935ms             1  \n",
            "                          aten::to         0.00%      40.000us         0.02%     143.000us       5.720us            25  \n",
            "                        aten::mean         0.01%      44.000us         0.05%     395.000us     395.000us             1  \n",
            "                         aten::sum         0.03%     265.000us         0.03%     271.000us     271.000us             1  \n",
            "                       aten::fill_         0.00%       9.000us         0.00%       9.000us       4.500us             2  \n",
            "                        aten::div_         0.01%      45.000us         0.01%      84.000us      42.000us             2  \n",
            "                    aten::_to_copy         0.01%      56.000us         0.01%     103.000us      25.750us             4  \n",
            "               aten::empty_strided         0.00%      15.000us         0.00%      15.000us       3.000us             5  \n",
            "                       aten::copy_        13.38%     109.943ms        13.38%     109.943ms       4.229ms            26  \n",
            "                      aten::detach         0.00%       8.000us         0.00%      23.000us      11.500us             2  \n",
            "----------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 821.957ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model_quantized.eval()\n",
        "iter_count = 0\n",
        "total_loss = 0\n",
        "with torch.no_grad():\n",
        "    for test_x, test_y in patchtst_learner.test_dataloader:\n",
        "        test_x = test_x.to(\"cpu\")\n",
        "        test_y = test_y.to(\"cpu\")\n",
        "        pred_y = patchtst_model_quantized(test_x)\n",
        "        pred_y = pred_y[:, -patchtst_learner.target_window:, -1:].squeeze(-1)\n",
        "        loss = patchtst_learner.loss(pred_y, test_y)\n",
        "        total_loss += loss.item()\n",
        "        iter_count += 1\n",
        "total_loss /= iter_count\n",
        "print(\"MSE test loss: {:.4f}\".format(total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJqnPKyLdP_J",
        "outputId": "a82979c2-0faa-4dae-e152-1f9efdbf792f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE test loss: 0.0587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model size"
      ],
      "metadata": {
        "id": "RjjiWJ_eYTbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def print_model_size(mdl):\n",
        "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
        "    print(\"Size of model: %.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
        "    os.remove('tmp.pt')"
      ],
      "metadata": {
        "id": "T-HD7C8ZYW0Y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_model_size(patchtst_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02JBc0VmFnKz",
        "outputId": "3a378b0c-eddd-44fe-902e-84f0a013a0ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of model: 3.27 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_model_size(patchtst_model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrvYr-i6Fvtg",
        "outputId": "ace65d9c-393b-4169-b0f1-32f1fc4d218e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of model: 3.29 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of params"
      ],
      "metadata": {
        "id": "uBG0zuzKWK64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary"
      ],
      "metadata": {
        "id": "kGSW3r4SNfD0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(patchtst_model, input_size=(128,96,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeSn4U3nWOZo",
        "outputId": "b06e028c-ed9d-4fef-fd6c-2dd61026234d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "â”œâ”€RevIN: 1-1                                  14\n",
            "â”œâ”€TSTiEncoder: 1-2                            --\n",
            "|    â””â”€Linear: 2-1                            2,176\n",
            "|    â””â”€Dropout: 2-2                           --\n",
            "|    â””â”€TSTEncoder: 2-3                        --\n",
            "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
            "â”œâ”€Flatten_Head: 1-3                           --\n",
            "|    â””â”€Flatten: 2-4                           --\n",
            "|    â””â”€Linear: 2-5                            503,904\n",
            "|    â””â”€Dropout: 2-6                           --\n",
            "======================================================================\n",
            "Total params: 804,849\n",
            "Trainable params: 506,094\n",
            "Non-trainable params: 298,755\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "â”œâ”€RevIN: 1-1                                  14\n",
              "â”œâ”€TSTiEncoder: 1-2                            --\n",
              "|    â””â”€Linear: 2-1                            2,176\n",
              "|    â””â”€Dropout: 2-2                           --\n",
              "|    â””â”€TSTEncoder: 2-3                        --\n",
              "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
              "â”œâ”€Flatten_Head: 1-3                           --\n",
              "|    â””â”€Flatten: 2-4                           --\n",
              "|    â””â”€Linear: 2-5                            503,904\n",
              "|    â””â”€Dropout: 2-6                           --\n",
              "======================================================================\n",
              "Total params: 804,849\n",
              "Trainable params: 506,094\n",
              "Non-trainable params: 298,755\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(patchtst_model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfsKJASmW22g",
        "outputId": "de7e2746-be54-4783-8f82-db43b2222f00"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "â”œâ”€RevIN: 1-1                                  14\n",
            "â”œâ”€TSTiEncoder: 1-2                            --\n",
            "|    â””â”€Linear: 2-1                            --\n",
            "|    |    â””â”€LinearPackedParams: 3-1           --\n",
            "|    â””â”€Dropout: 2-2                           --\n",
            "|    â””â”€TSTEncoder: 2-3                        --\n",
            "|    |    â””â”€ModuleList: 3-2                   (1,539)\n",
            "â”œâ”€Flatten_Head: 1-3                           --\n",
            "|    â””â”€Flatten: 2-4                           --\n",
            "|    â””â”€Linear: 2-5                            --\n",
            "|    |    â””â”€LinearPackedParams: 3-3           --\n",
            "|    â””â”€Dropout: 2-6                           --\n",
            "======================================================================\n",
            "Total params: 1,553\n",
            "Trainable params: 14\n",
            "Non-trainable params: 1,539\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "â”œâ”€RevIN: 1-1                                  14\n",
              "â”œâ”€TSTiEncoder: 1-2                            --\n",
              "|    â””â”€Linear: 2-1                            --\n",
              "|    |    â””â”€LinearPackedParams: 3-1           --\n",
              "|    â””â”€Dropout: 2-2                           --\n",
              "|    â””â”€TSTEncoder: 2-3                        --\n",
              "|    |    â””â”€ModuleList: 3-2                   (1,539)\n",
              "â”œâ”€Flatten_Head: 1-3                           --\n",
              "|    â””â”€Flatten: 2-4                           --\n",
              "|    â””â”€Linear: 2-5                            --\n",
              "|    |    â””â”€LinearPackedParams: 3-3           --\n",
              "|    â””â”€Dropout: 2-6                           --\n",
              "======================================================================\n",
              "Total params: 1,553\n",
              "Trainable params: 14\n",
              "Non-trainable params: 1,539\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pruning"
      ],
      "metadata": {
        "id": "3Gc9b93cPO2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0IBqSu_PVet",
        "outputId": "0019f930-d1e7-4a89-f876-59c790db957f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTST(\n",
              "  (revin_layer): RevIN()\n",
              "  (backbone): TSTiEncoder(\n",
              "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (encoder): TSTEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-2): 3 x TSTEncoderLayer(\n",
              "          (self_attn): _MultiheadAttention(\n",
              "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sdp_attn): _ScaledDotProductAttention(\n",
              "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (1): Dropout(p=0.3, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_attn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "          (ff): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_ffn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Flatten_Head(\n",
              "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
              "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "_nuRpdbtP7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module = patchtst_model.backbone.encoder.layers[0].self_attn.to_out[0]\n",
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICCXO7wEPQMt",
        "outputId": "8bba6935-bc08-431e-83a4-90e1db8ff2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[-0.0197,  0.0588,  0.0385,  ...,  0.0356, -0.0543,  0.0730],\n",
            "        [-0.0233,  0.0058, -0.0757,  ...,  0.0214,  0.0534, -0.0474],\n",
            "        [-0.0189, -0.0106, -0.0685,  ..., -0.0731,  0.0209, -0.0900],\n",
            "        ...,\n",
            "        [-0.0318,  0.0346,  0.0207,  ...,  0.0098,  0.0825,  0.0619],\n",
            "        [-0.0345,  0.0083, -0.0215,  ...,  0.0850, -0.0390,  0.0604],\n",
            "        [-0.0178, -0.0034,  0.0400,  ..., -0.0727,  0.0534, -0.0246]],\n",
            "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([-0.0382, -0.0397,  0.0522,  0.0473, -0.0440, -0.0247,  0.0591,  0.0469,\n",
            "         0.0685,  0.0199,  0.0132, -0.0233,  0.0440,  0.0440, -0.0406,  0.0724,\n",
            "         0.0090,  0.0823, -0.0245, -0.0219,  0.0379, -0.0662, -0.0756,  0.0255,\n",
            "         0.0833,  0.0756,  0.0576, -0.0282,  0.0317,  0.0686,  0.0197,  0.0183,\n",
            "         0.0251,  0.0263,  0.0379,  0.0171,  0.0133, -0.0690,  0.0312, -0.0509,\n",
            "         0.0616,  0.0203,  0.0769,  0.0430,  0.0021,  0.0110, -0.0077,  0.0809,\n",
            "         0.0547, -0.0422,  0.0468,  0.0801, -0.0822, -0.0209, -0.0774,  0.0351,\n",
            "         0.0618, -0.0078, -0.0384, -0.0580, -0.0083,  0.0100, -0.0439,  0.0422,\n",
            "        -0.0224, -0.0162,  0.0196,  0.0001, -0.0196, -0.0203, -0.0503, -0.0397,\n",
            "         0.0143, -0.0291,  0.0424,  0.0181, -0.0282,  0.0530, -0.0226, -0.0053,\n",
            "        -0.0715, -0.0657,  0.0753,  0.0525,  0.0405,  0.0389, -0.0461,  0.0718,\n",
            "         0.0116, -0.0705,  0.0805, -0.0007, -0.0370,  0.0763, -0.0385, -0.0497,\n",
            "         0.0443,  0.0483, -0.0330, -0.0443, -0.0566, -0.0097, -0.0829, -0.0273,\n",
            "         0.0709,  0.0110, -0.0503,  0.0748, -0.0520,  0.0146, -0.0573,  0.0813,\n",
            "         0.0114, -0.0806, -0.0250,  0.0527,  0.0192,  0.0023,  0.0495, -0.0239,\n",
            "        -0.0062,  0.0099,  0.0517,  0.0145, -0.0034, -0.0103,  0.0035,  0.0750],\n",
            "       device='cuda:0', requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prune.random_unstructured(module, name=\"weight\", amount=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlmyBhlBQ2Ob",
        "outputId": "7a621420-2584-4708-e7a2-1b8d48a29b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=128, out_features=128, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyebneqxRWTU",
        "outputId": "fb596725-664f-4dfb-94a0-183bcff4ab1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0197,  0.0000,  0.0000,  ...,  0.0356, -0.0000,  0.0730],\n",
            "        [-0.0233,  0.0058, -0.0000,  ...,  0.0214,  0.0000, -0.0474],\n",
            "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
            "        ...,\n",
            "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0000,  0.0000, -0.0000,  ...,  0.0850, -0.0390,  0.0000],\n",
            "        [-0.0000, -0.0034,  0.0400,  ..., -0.0000,  0.0000, -0.0246]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(patchtst_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOVEsvSFRIrH",
        "outputId": "e92dbe7e-1eaa-4836-df07-da5e596fbda6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "â”œâ”€RevIN: 1-1                                  14\n",
            "â”œâ”€TSTiEncoder: 1-2                            --\n",
            "|    â””â”€Linear: 2-1                            2,176\n",
            "|    â””â”€Dropout: 2-2                           --\n",
            "|    â””â”€TSTEncoder: 2-3                        --\n",
            "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
            "â”œâ”€Flatten_Head: 1-3                           --\n",
            "|    â””â”€Flatten: 2-4                           --\n",
            "|    â””â”€Linear: 2-5                            503,904\n",
            "|    â””â”€Dropout: 2-6                           --\n",
            "======================================================================\n",
            "Total params: 804,849\n",
            "Trainable params: 506,094\n",
            "Non-trainable params: 298,755\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "â”œâ”€RevIN: 1-1                                  14\n",
              "â”œâ”€TSTiEncoder: 1-2                            --\n",
              "|    â””â”€Linear: 2-1                            2,176\n",
              "|    â””â”€Dropout: 2-2                           --\n",
              "|    â””â”€TSTEncoder: 2-3                        --\n",
              "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
              "â”œâ”€Flatten_Head: 1-3                           --\n",
              "|    â””â”€Flatten: 2-4                           --\n",
              "|    â””â”€Linear: 2-5                            503,904\n",
              "|    â””â”€Dropout: 2-6                           --\n",
              "======================================================================\n",
              "Total params: 804,849\n",
              "Trainable params: 506,094\n",
              "Non-trainable params: 298,755\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cuda')\n",
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "o9JZwalwRcES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1tLVKeuRlG8",
        "outputId": "11ad39f1-b940-4ad0-c1a4-f03dfe3b5ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        33.44%       5.336ms        99.84%      15.932ms      15.932ms       0.000us         0.00%       9.314ms       9.314ms             1  \n",
            "                                           aten::linear         1.81%     289.000us        25.97%       4.144ms     207.200us       0.000us         0.00%       4.993ms     249.650us            20  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.599ms        40.62%       3.599ms     189.421us            19  \n",
            "                                           aten::matmul         2.11%     336.000us        22.38%       3.571ms     223.188us       0.000us         0.00%       3.093ms     193.312us            16  \n",
            "                                            aten::addmm         4.60%     734.000us         6.07%     969.000us      96.900us       2.677ms        30.21%       2.677ms     267.700us            10  \n",
            "                                       aten::batch_norm         0.17%      27.000us         6.95%       1.109ms     184.833us       0.000us         0.00%       1.485ms     247.500us             6  \n",
            "                           aten::_batch_norm_impl_index         0.34%      55.000us         6.78%       1.082ms     180.333us       0.000us         0.00%       1.485ms     247.500us             6  \n",
            "                                 aten::cudnn_batch_norm         2.97%     474.000us         5.93%     946.000us     157.667us       1.142ms        12.89%       1.428ms     238.000us             6  \n",
            "                                            aten::clone         1.61%     257.000us        10.87%       1.735ms      75.435us       0.000us         0.00%       1.410ms      61.304us            23  \n",
            "                                            aten::copy_         2.98%     475.000us         5.78%     923.000us      40.130us       1.410ms        15.91%       1.410ms      61.304us            23  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 15.957ms\n",
            "Self CUDA time total: 8.861ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in patchtst_model.named_modules():\n",
        "    # prune 20% of connections in all 2D-conv layers\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
        "    # prune 40% of connections in all linear layers\n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.4)"
      ],
      "metadata": {
        "id": "opiX08OdRyh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cuda')\n",
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "Y7WLFmk4Sh50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8v5fcOeSlT0",
        "outputId": "e2fbcedd-8cd9-46b2-cea4-ebd79a1f7e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        28.18%       4.006ms        94.15%      13.386ms      13.386ms       0.000us         0.00%       8.880ms       8.880ms             1  \n",
            "                                           aten::linear         1.39%     197.000us        16.76%       2.383ms     119.150us       0.000us         0.00%       4.966ms     248.300us            20  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.587ms        40.39%       3.587ms     188.789us            19  \n",
            "                                           aten::matmul         1.30%     185.000us        14.16%       2.013ms     125.812us       0.000us         0.00%       3.071ms     191.938us            16  \n",
            "                                            aten::addmm         3.42%     486.000us         4.17%     593.000us      59.300us       2.668ms        30.05%       2.668ms     266.800us            10  \n",
            "                                            aten::clone         1.17%     167.000us         6.60%     938.000us      40.783us       0.000us         0.00%       1.417ms      61.609us            23  \n",
            "                                            aten::copy_         2.19%     311.000us         3.58%     509.000us      22.130us       1.417ms        15.96%       1.417ms      61.609us            23  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.417ms        15.96%       1.417ms      61.609us            23  \n",
            "                                          aten::reshape         1.16%     165.000us         7.55%       1.073ms      31.559us       0.000us         0.00%       1.212ms      35.647us            34  \n",
            "                                       aten::batch_norm         0.11%      15.000us         4.75%     675.000us     112.500us       0.000us         0.00%       1.204ms     200.667us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.218ms\n",
            "Self CUDA time total: 8.880ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model.eval()\n",
        "iter_count = 0\n",
        "total_loss = 0\n",
        "with torch.no_grad():\n",
        "    for test_x, test_y in patchtst_learner.test_dataloader:\n",
        "        test_x = test_x.to(\"cuda\")\n",
        "        test_y = test_y.to(\"cuda\")\n",
        "        pred_y = patchtst_model(test_x)\n",
        "        pred_y = pred_y[:, -patchtst_learner.target_window:, -1:].squeeze(-1)\n",
        "        loss = patchtst_learner.loss(pred_y, test_y)\n",
        "        total_loss += loss.item()\n",
        "        iter_count += 1\n",
        "total_loss /= iter_count\n",
        "print(\"MSE test loss: {:.4f}\".format(total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb71VTTtSrSU",
        "outputId": "c83a472f-27d3-461b-a85e-02568d189307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE test loss: 0.0562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# other"
      ],
      "metadata": {
        "id": "qPODEG82FOA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFH-n0KS-Axb",
        "outputId": "0425863d-7cb3-4a86-c41c-7ba13bc14cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size: 3.136MB\n"
          ]
        }
      ],
      "source": [
        "init_model = patchtst_model\n",
        "init_model.eval()\n",
        "param_size = 0\n",
        "for param in init_model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in init_model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIJoNNuy-Axc",
        "outputId": "95de4f0d-1c8c-42db-a1e5-d91d9a87d69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size: 0.032MB\n"
          ]
        }
      ],
      "source": [
        "# model = model\n",
        "import copy\n",
        "fused_model_cpu = copy.deepcopy(fused_model).to('cpu')\n",
        "quantized_model = torch.quantization.convert(fused_model_cpu, inplace=False)\n",
        "# model = quantized_PatchTST.cuda()\n",
        "param_size = 0\n",
        "for param in quantized_model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in quantized_model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVQKB2-I-Axc",
        "outputId": "7d9f8f25-ed3b-44fe-a306-575a74dfa3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE test loss: 0.0696\n"
          ]
        }
      ],
      "source": [
        "patchtst_learner = Learner(model=init_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
        "patchtst_learner.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKv06fa3-Axc",
        "outputId": "275eb626-7e44-4918-fc62-52b63d501e25"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qlinear.cpp:1140 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Linear.cpp:360 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m patchtst_learner \u001b[39m=\u001b[39m Learner(model\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mcpu(), dataset\u001b[39m=\u001b[39mETTDataset, adjust_lr\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, adjust_factor\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m patchtst_learner\u001b[39m.\u001b[39mtest_quantized_model()\n",
            "\u001b[1;32m/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=112'>113</a>\u001b[0m test_y \u001b[39m=\u001b[39m test_y\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39m# Perform inference using the quantized model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(test_x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39m# Assuming the prediction is in the correct format, no further processing needed\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m \u001b[39m# Calculate the loss\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(pred_y, test_y)\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;32m/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m z \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m)                                                              \u001b[39m# z: [bs x nvars x patch_len x patch_num]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(z)                                                                \u001b[39m# z: [bs x nvars x d_model x patch_num]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=118'>119</a>\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(z)                                                                    \u001b[39m# z: [bs x nvars x target_window] \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39m# denorm\u001b[39;00m\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;32m/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Input encoding\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m)                                                   \u001b[39m# x: [bs x nvars x patch_num x patch_len]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_P(x)                                                          \u001b[39m# x: [bs x nvars x patch_num x d_model]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m u \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(x, (x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],x\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],x\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]))      \u001b[39m# u: [bs * nvars x patch_num x d_model]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(u \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_pos)                                         \u001b[39m# u: [bs * nvars x patch_num x d_model]\u001b[39;00m\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/linear.py:168\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mquantized\u001b[39m.\u001b[39mlinear(\n\u001b[1;32m    169\u001b[0m         x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params\u001b[39m.\u001b[39m_packed_params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_point)\n",
            "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(kwargs \u001b[39mor\u001b[39;00m {}))\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qlinear.cpp:1140 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Linear.cpp:360 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"
          ]
        }
      ],
      "source": [
        "patchtst_learner = Learner(model=quantized_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
        "patchtst_learner.test_quantized_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA6lR65A-Axc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "NotImplementedError: Could not run 'quantized::linear' with arguments from the 'CUDA' backend.\n",
        "This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom\n",
        "build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes\n",
        "for possible resolutions. 'quantized::linear' is only available for these backends:\n",
        "\n",
        "    [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode,\n",
        "    Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU,\n",
        "    AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer,\n",
        "    AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode,\n",
        "    FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my_env",
      "language": "python",
      "name": "my_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}