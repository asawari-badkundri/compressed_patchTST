{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOcN3Qftn0Mq",
        "outputId": "de8e3a6b-788b-4334-d419-331cddadeba1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qoiO7Hl6-AxM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch import Tensor\n",
        "from typing import Callable, Optional\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch.quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9R5Qin7v-AxN",
        "outputId": "d8c930fb-ded3-48ff-fc53-88d01f77d545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
            "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
            "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n"
          ]
        }
      ],
      "source": [
        "df_ETTh1 = pd.read_csv(\"/content/ETTh1.csv\")\n",
        "print(df_ETTh1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3ggcvYGy-AxO",
        "outputId": "bc07a42f-502d-400c-dc67-4d715a4f984b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17420, 7), (17420, 8), 8640)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df_ETTh1.iloc[:,1:].shape, df_ETTh1.shape, 12 * 30 * 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QpWkZWJK-AxO"
      },
      "outputs": [],
      "source": [
        "class ETTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset=\"ETTh1\", mode=\"train\", scale=True, seq_len=336, pred_len=96):\n",
        "        super().__init__()\n",
        "        df = pd.read_csv(\"/content/ETTh1.csv\".format(dataset))\n",
        "        x_y = df.iloc[:,1:]\n",
        "        time_stamp = df.iloc[:,0]\n",
        "\n",
        "        assert mode in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[mode]\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if scale:\n",
        "            train_x_y = x_y.iloc[border1s[0]: border2s[0]]\n",
        "            self.ss = StandardScaler()\n",
        "            self.ss.fit(train_x_y.to_numpy(dtype=np.float32))\n",
        "            x_y = self.ss.transform(x_y.to_numpy(dtype=np.float32))\n",
        "        else:\n",
        "            x_y = x_y.to_numpy(dtype=np.float32)\n",
        "\n",
        "        time_stamp = time_stamp.to_numpy()\n",
        "\n",
        "        self.data_x = x_y[border1: border2, :]\n",
        "        self.data_y = x_y[border1: border2, -1]\n",
        "\n",
        "        self.data_stamp = time_stamp[border1: border2]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end\n",
        "        r_end = r_begin + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        return seq_x, seq_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.ss.inverse_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LNP6-hQ2-AxP"
      },
      "outputs": [],
      "source": [
        "#Revin.py\n",
        "class RevIN(torch.nn.Module):\n",
        "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
        "        \"\"\"\n",
        "        :param num_features: the number of features or channels\n",
        "        :param eps: a value added for numerical stability\n",
        "        :param affine: if True, RevIN has learnable affine parameters\n",
        "        \"\"\"\n",
        "        super(RevIN, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.affine = affine\n",
        "        self.subtract_last = subtract_last\n",
        "        if self.affine:\n",
        "            self._init_params()\n",
        "\n",
        "    def forward(self, x, mode:str):\n",
        "        if mode == 'norm':\n",
        "            self._get_statistics(x)\n",
        "            x = self._normalize(x)\n",
        "        elif mode == 'denorm':\n",
        "            x = self._denormalize(x)\n",
        "        else: raise NotImplementedError\n",
        "        return x\n",
        "\n",
        "    def _init_params(self):\n",
        "        # initialize RevIN params: (C,)\n",
        "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
        "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
        "\n",
        "    def _get_statistics(self, x):\n",
        "        dim2reduce = tuple(range(1, x.ndim-1))\n",
        "        if self.subtract_last:\n",
        "            self.last = x[:,-1,:].unsqueeze(1)\n",
        "        else:\n",
        "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
        "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
        "\n",
        "    def _normalize(self, x):\n",
        "        if self.subtract_last:\n",
        "            x = x - self.last\n",
        "        else:\n",
        "            x = x - self.mean\n",
        "        x = x / self.stdev\n",
        "        if self.affine:\n",
        "            # print(f'x.mT.shape: {x.mT.shape} | self.affine_weight: {self.affine_weight.shape}')\n",
        "            x = x * self.affine_weight + self.affine_bias\n",
        "            # print(f'x.shape: {x.shape} | self.affine_weight: {self.affine_bias.shape}')\n",
        "            # x = x + self.affine_bias\n",
        "        return x.mT\n",
        "\n",
        "    def _denormalize(self, x):\n",
        "        if self.affine:\n",
        "            x = x - self.affine_bias\n",
        "            x = x / (self.affine_weight + self.eps*self.eps)\n",
        "        x = x * self.stdev\n",
        "        if self.subtract_last:\n",
        "            x = x + self.last\n",
        "        else:\n",
        "            x = x + self.mean\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lADgBb5r-AxP"
      },
      "outputs": [],
      "source": [
        "#PatchTST_layers.py\n",
        "class Transpose(torch.nn.Module):\n",
        "    def __init__(self, *dims, contiguous=False):\n",
        "        super().__init__()\n",
        "        self.dims, self.contiguous = dims, contiguous\n",
        "    def forward(self, x):\n",
        "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
        "        else: return x.transpose(*self.dims)\n",
        "\n",
        "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
        "    # Positional encoding\n",
        "    if pe == None:\n",
        "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "        learn_pe = False\n",
        "    elif pe == 'zero':\n",
        "        W_pos = torch.empty((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'zeros':\n",
        "        W_pos = torch.empty((q_len, d_model))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'normal' or pe == 'gauss':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
        "    elif pe == 'uniform':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
        "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
        "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
        "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
        "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
        "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
        "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
        "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
        "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1QYXGH1v-AxP"
      },
      "outputs": [],
      "source": [
        "#PatchTST_backbone.py\n",
        "class TSTiEncoder(torch.nn.Module):  #i means channel-independent\n",
        "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
        "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
        "                 d_ff=128, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
        "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
        "                 pe='zeros', learn_pe=True, verbose=False, **kwargs):\n",
        "                 #act=\"gelu\"\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_num = patch_num\n",
        "        self.patch_len = patch_len\n",
        "\n",
        "        # Input encoding\n",
        "        q_len = patch_num\n",
        "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
        "        self.seq_len = q_len\n",
        "\n",
        "        # Positional encoding\n",
        "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
        "\n",
        "        # Residual dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
        "\n",
        "\n",
        "    def forward(self, x) -> Tensor:                                              # x: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        n_vars = x.shape[1]\n",
        "        # Input encoding\n",
        "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
        "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
        "\n",
        "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
        "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
        "\n",
        "        # Encoder\n",
        "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
        "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
        "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "# Cell\n",
        "class TSTEncoder(torch.nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None,\n",
        "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
        "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
        "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                                      activation=activation, res_attention=res_attention,\n",
        "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
        "        self.res_attention = res_attention\n",
        "\n",
        "    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        output = src\n",
        "        scores = None\n",
        "        if self.res_attention:\n",
        "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "        else:\n",
        "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "\n",
        "\n",
        "\n",
        "class TSTEncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=128, store_attn=False,\n",
        "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
        "        super().__init__()\n",
        "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        # Multi-Head attention\n",
        "        self.res_attention = res_attention\n",
        "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_attn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_attn = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Position-wise Feed-Forward\n",
        "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
        "                                torch.nn.GELU(),\n",
        "                                nn.Dropout(dropout),\n",
        "                                nn.Linear(d_ff, d_model, bias=bias))\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_ffn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_ffn = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.pre_norm = pre_norm\n",
        "        self.store_attn = store_attn\n",
        "\n",
        "\n",
        "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
        "\n",
        "        # Multi-Head attention sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "        ## Multi-Head attention\n",
        "        if self.res_attention:\n",
        "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        if self.store_attn:\n",
        "            self.attn = attn\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "\n",
        "        # Feed-forward sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "        ## Position-wise Feed-Forward\n",
        "        src2 = self.ff(src)\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "\n",
        "        if self.res_attention:\n",
        "            return src, scores\n",
        "        else:\n",
        "            return src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OQjdKQf0-AxQ"
      },
      "outputs": [],
      "source": [
        "class _MultiheadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
        "        \"\"\"Multi Head Attention Layer\n",
        "        Input shape:\n",
        "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
        "            K, V:    [batch_size (bs) x q_len x d_model]\n",
        "            mask:    [q_len x q_len]\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
        "\n",
        "        # Scaled Dot-Product Attention (multiple heads)\n",
        "        self.res_attention = res_attention\n",
        "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
        "\n",
        "        # Poject output\n",
        "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
        "\n",
        "\n",
        "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,\n",
        "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "\n",
        "        bs = Q.size(0)\n",
        "        if K is None: K = Q\n",
        "        if V is None: V = Q\n",
        "\n",
        "        # Linear (+ split in multiple heads)\n",
        "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
        "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
        "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
        "\n",
        "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
        "        if self.res_attention:\n",
        "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # back to the original inputs dimensions\n",
        "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
        "        output = self.to_out(output)\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "SvWR3zdH-AxQ"
      },
      "outputs": [],
      "source": [
        "class _ScaledDotProductAttention(torch.nn.Module):\n",
        "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
        "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
        "    by Lee et al, 2021)\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
        "        super().__init__()\n",
        "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
        "        self.res_attention = res_attention\n",
        "        head_dim = d_model // n_heads\n",
        "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
        "        self.lsa = lsa\n",
        "\n",
        "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        '''\n",
        "        Input shape:\n",
        "            q               : [bs x n_heads x max_q_len x d_k]\n",
        "            k               : [bs x n_heads x d_k x seq_len]\n",
        "            v               : [bs x n_heads x seq_len x d_v]\n",
        "            prev            : [bs x n_heads x q_len x seq_len]\n",
        "            key_padding_mask: [bs x seq_len]\n",
        "            attn_mask       : [1 x seq_len x seq_len]\n",
        "        Output shape:\n",
        "            output:  [bs x n_heads x q_len x d_v]\n",
        "            attn   : [bs x n_heads x q_len x seq_len]\n",
        "            scores : [bs x n_heads x q_len x seq_len]\n",
        "        '''\n",
        "\n",
        "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
        "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # Add pre-softmax attention scores from the previous layer (optional)\n",
        "        if prev is not None: attn_scores = attn_scores + prev\n",
        "\n",
        "        # Attention mask (optional)\n",
        "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
        "            if attn_mask.dtype == torch.bool:\n",
        "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
        "            else:\n",
        "                attn_scores += attn_mask\n",
        "\n",
        "        # Key padding mask (optional)\n",
        "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
        "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
        "\n",
        "        # normalize the attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # compute the new values given the attention weights\n",
        "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_jJViV8P-AxQ"
      },
      "outputs": [],
      "source": [
        "class Flatten_Head(torch.nn.Module):\n",
        "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.individual = individual\n",
        "        self.n_vars = n_vars\n",
        "\n",
        "        if self.individual:\n",
        "            self.linears = nn.ModuleList()\n",
        "            self.dropouts = nn.ModuleList()\n",
        "            self.flattens = nn.ModuleList()\n",
        "            for i in range(self.n_vars):\n",
        "                self.flattens.append(nn.Flatten(start_dim=-2)) #flattens last 2\n",
        "                self.linears.append(nn.Linear(nf, target_window))\n",
        "                self.dropouts.append(nn.Dropout(head_dropout))\n",
        "        else:\n",
        "            self.flatten = nn.Flatten(start_dim=-2)\n",
        "            self.linear = nn.Linear(nf, target_window)\n",
        "            self.dropout = nn.Dropout(head_dropout)\n",
        "\n",
        "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
        "        if self.individual:\n",
        "            x_out = []\n",
        "            for i in range(self.n_vars):\n",
        "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
        "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
        "                z = self.dropouts[i](z)\n",
        "                x_out.append(z)\n",
        "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
        "        else:\n",
        "            x = self.flatten(x)\n",
        "            x = self.linear(x)\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "#Implementation of PatchTST\n",
        "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n",
        "    x = .5 if exponential else 1\n",
        "    i = 0\n",
        "    for i in range(100):\n",
        "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
        "        pv(f'{i:4.0f}  {x:5.3f}  {cpe.mean():+6.3f}', verbose)\n",
        "        if abs(cpe.mean()) <= eps: break\n",
        "        elif cpe.mean() > eps: x += .001\n",
        "        else: x -= .001\n",
        "        i += 1\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
        "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "class PatchTST(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window, patch_len, stride, max_seq_len:Optional[int]=1024,\n",
        "                 n_layers=3, d_model=128, n_heads=4, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
        "                 d_ff:int=128, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0.3, act:str=\"gelu\", key_padding_mask:bool='auto',\n",
        "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
        "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0.3, head_dropout = 0, padding_patch = None,\n",
        "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
        "                 verbose:bool=False, **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # RevIn\n",
        "        self.revin = revin\n",
        "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
        "\n",
        "        # Patching\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.padding_patch = padding_patch\n",
        "        patch_num = int((context_window - patch_len)/stride + 1)\n",
        "        if padding_patch == 'end': # can be modified to general case\n",
        "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride))\n",
        "            patch_num += 1\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
        "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
        "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
        "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
        "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
        "\n",
        "        # Head\n",
        "        self.head_nf = d_model * patch_num\n",
        "        self.n_vars = c_in\n",
        "        self.pretrain_head = pretrain_head\n",
        "        self.head_type = head_type\n",
        "        self.individual = individual\n",
        "\n",
        "        if self.pretrain_head:\n",
        "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
        "        elif head_type == 'flatten':\n",
        "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
        "        # norm\n",
        "        if self.revin:\n",
        "            # z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'norm')\n",
        "            # z = z.permute(0,2,1)\n",
        "\n",
        "        # do patching\n",
        "        if self.padding_patch == 'end':\n",
        "            z = self.padding_patch_layer(z)\n",
        "        # print(f'z.shape: {z.shape}')\n",
        "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
        "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        # model\n",
        "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
        "        z = self.head(z)                                                                    # z: [bs x nvars x target_window]\n",
        "\n",
        "        # denorm\n",
        "        if self.revin:\n",
        "            z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'denorm')\n",
        "            # z = z.permute(0,2,1)\n",
        "        return z\n",
        "\n",
        "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
        "        return nn.Sequential(nn.Dropout(dropout),\n",
        "                    nn.Conv1d(head_nf, vars, 1)\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "S_7jINE4-AxR"
      },
      "outputs": [],
      "source": [
        "#Linear model\n",
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window):\n",
        "        super().__init__()\n",
        "        self.c_in = c_in\n",
        "        self.context_winsoq = context_window\n",
        "        self.target_window = target_window\n",
        "\n",
        "        self.flatten = torch.nn.Flatten(start_dim=-2)\n",
        "\n",
        "        self.linear = torch.nn.Linear(c_in * context_window, target_window)\n",
        "\n",
        "    def forward(self, x):                   # x: [bs x seq_len Ã— nvars]\n",
        "        x = self.flatten(x)                 # x: [bs x seq_len * nvars]\n",
        "        x = self.linear(x)                  # x: [bs x target_window]\n",
        "        return x\n",
        "\n",
        "\n",
        "class moving_avg(torch.nn.Module):\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = torch.nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(torch.nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "class DLinear(torch.nn.Module):\n",
        "    def __init__(self, c_in, context_window, target_window):\n",
        "        super().__init__()\n",
        "        # Decompsition Kernel Size\n",
        "        kernel_size = 25\n",
        "        self.decompsition = series_decomp(kernel_size)\n",
        "        self.flatten_Seasonal = torch.nn.Flatten(start_dim=-2)\n",
        "        self.flatten_Trend = torch.nn.Flatten(start_dim=-2)\n",
        "\n",
        "        self.Linear_Seasonal = torch.nn.Linear(c_in * context_window, target_window)\n",
        "        self.Linear_Trend = torch.nn.Linear(c_in * context_window, target_window)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        seasonal_init, trend_init = self.decompsition(x)\n",
        "        seasonal_init = self.flatten_Seasonal(x)\n",
        "        trend_init = self.flatten_Trend(x)\n",
        "\n",
        "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
        "        trend_output = self.Linear_Trend(trend_init)\n",
        "\n",
        "        x = seasonal_output + trend_output\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ND6bur0m-Axa"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=100, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
        "        self.model = model.to(\"cuda\")\n",
        "        # self.model = model.to(\"cpu\")\n",
        "        self.batch_size = batch_size\n",
        "        train_dataset = dataset(mode=\"train\")\n",
        "        valid_dataset = dataset(mode=\"val\")\n",
        "        test_dataset = dataset(mode=\"test\")\n",
        "        self.train_datalen = len(train_dataset)\n",
        "        self.valid_datalen = len(valid_dataset)\n",
        "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        self.lr=lr\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.loss = torch.nn.MSELoss()\n",
        "        self.epochs = epochs\n",
        "        self.target_window=target_window\n",
        "        self.best_weight = self.model.state_dict()\n",
        "        self.d_model=d_model\n",
        "        self.adjust_lr = adjust_lr\n",
        "        self.adjust_factor = adjust_factor\n",
        "\n",
        "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
        "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
        "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
        "        else:\n",
        "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr_adjust\n",
        "        if printout:\n",
        "            print('Updating learning rate to {}'.format(lr_adjust))\n",
        "        return\n",
        "\n",
        "    def train(self):\n",
        "        best_valid_loss = np.inf\n",
        "        train_history = []\n",
        "        valid_history = []\n",
        "        train_steps = 1\n",
        "        if self.adjust_lr:\n",
        "            self.adjust_learning_rate(train_steps)\n",
        "        for epoch in range(self.epochs):\n",
        "            #train\n",
        "            self.model.train()\n",
        "            iter_count = 0\n",
        "            total_loss = 0\n",
        "\n",
        "            for train_x, train_y in self.train_dataloader:\n",
        "                train_x = train_x.to(\"cuda\")\n",
        "                train_y = train_y.to(\"cuda\")\n",
        "                # train_x = train_x.to(\"cpu\")\n",
        "                # train_y = train_y.to(\"cpu\")\n",
        "                # print(f'train_x.shape: {train_x.shape}')\n",
        "                pred_y = self.model(train_x)\n",
        "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                loss = self.loss(pred_y, train_y)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "                train_steps += 1\n",
        "            if self.adjust_lr:\n",
        "                self.adjust_learning_rate(train_steps)\n",
        "\n",
        "            #valid\n",
        "            self.model.eval()\n",
        "            valid_iter_count = 0\n",
        "            valid_total_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for valid_x, valid_y in self.valid_dataloader:\n",
        "                    valid_x = valid_x.to(\"cuda\")\n",
        "                    valid_y = valid_y.to(\"cuda\")\n",
        "                    # valid_x = valid_x.to(\"cpu\")\n",
        "                    # valid_y = valid_y.to(\"cpu\")\n",
        "                    pred_y = self.model(valid_x)\n",
        "                    pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                    loss = self.loss(pred_y, valid_y)\n",
        "                    valid_total_loss += loss.item()\n",
        "                    valid_iter_count += 1\n",
        "\n",
        "            total_loss /= iter_count\n",
        "            valid_total_loss /= valid_iter_count\n",
        "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
        "            if best_valid_loss >= valid_total_loss:\n",
        "                self.best_weight = self.model.state_dict()\n",
        "                best_valid_loss = valid_total_loss\n",
        "                print(\"Best score! Weights of the model are updated!\")\n",
        "            train_history.append(total_loss)\n",
        "            valid_history.append(valid_total_loss)\n",
        "        return train_history, valid_history\n",
        "\n",
        "    def test(self):\n",
        "        # self.model.load_state_dict(self.best_weight)\n",
        "        self.model.eval()\n",
        "        iter_count = 0\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for test_x, test_y in self.test_dataloader:\n",
        "                test_x = test_x.to(\"cuda\")\n",
        "                test_y = test_y.to(\"cuda\")\n",
        "                # test_x = test_x.to(\"cpu\")\n",
        "                # test_y = test_y.to(\"cpu\")\n",
        "                pred_y = self.model(test_x)\n",
        "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
        "                loss = self.loss(pred_y, test_y)\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "        total_loss /= iter_count\n",
        "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
        "\n",
        "    def test_quantized_model(self):\n",
        "        self.model.eval()\n",
        "        iter_count = 0\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for test_x, test_y in self.test_dataloader:\n",
        "                test_x = test_x.to(\"cpu\")\n",
        "                test_y = test_y.to(\"cpu\")\n",
        "                # Perform inference using the quantized model\n",
        "                test_x = self.test_dataloader.dataset.quantizer.transform(test_x)\n",
        "                pred_y = self.model(test_x)\n",
        "                # Assuming the prediction is in the correct format, no further processing needed\n",
        "                # Calculate the loss\n",
        "                loss = self.loss(pred_y, test_y)\n",
        "                total_loss += loss.item()\n",
        "                iter_count += 1\n",
        "        total_loss /= iter_count\n",
        "        print(\"MSE test loss for quantized model: {:.4f}\".format(total_loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "r4R3q_FF-Axb",
        "outputId": "b96c4683-ebb1-4b44-99cb-923628dbf97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating learning rate to 4.811252243246882e-08\n",
            "Updating learning rate to 3.175426480542942e-06\n",
            "epoch: 0 MSE loss: 0.2358 MSE valid loss: 0.1334\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.302740438653415e-06\n",
            "epoch: 1 MSE loss: 0.2272 MSE valid loss: 0.1246\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 9.430054396763887e-06\n",
            "epoch: 2 MSE loss: 0.2091 MSE valid loss: 0.1151\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.2557368354874362e-05\n",
            "epoch: 3 MSE loss: 0.1945 MSE valid loss: 0.1087\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.3846219390542782e-05\n",
            "epoch: 4 MSE loss: 0.1843 MSE valid loss: 0.1045\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.264304343560434e-05\n",
            "epoch: 5 MSE loss: 0.1786 MSE valid loss: 0.1023\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.1707322644771175e-05\n",
            "epoch: 6 MSE loss: 0.1743 MSE valid loss: 0.1003\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.0952698858458087e-05\n",
            "epoch: 7 MSE loss: 0.1714 MSE valid loss: 0.0996\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 1.0327404809650346e-05\n",
            "epoch: 8 MSE loss: 0.1684 MSE valid loss: 0.0988\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 9.798272520870257e-06\n",
            "epoch: 9 MSE loss: 0.1668 MSE valid loss: 0.0977\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 9.342938659399199e-06\n",
            "epoch: 10 MSE loss: 0.1656 MSE valid loss: 0.0971\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 8.945703337056415e-06\n",
            "epoch: 11 MSE loss: 0.1628 MSE valid loss: 0.0966\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 8.595177052156612e-06\n",
            "epoch: 12 MSE loss: 0.1622 MSE valid loss: 0.0963\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 8.282869524032146e-06\n",
            "epoch: 13 MSE loss: 0.1613 MSE valid loss: 0.0959\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 8.002304995806e-06\n",
            "epoch: 14 MSE loss: 0.1588 MSE valid loss: 0.0956\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 7.748446592171797e-06\n",
            "epoch: 15 MSE loss: 0.1584 MSE valid loss: 0.0952\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 7.517309741553296e-06\n",
            "epoch: 16 MSE loss: 0.1569 MSE valid loss: 0.0949\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 7.305695402335044e-06\n",
            "epoch: 17 MSE loss: 0.1557 MSE valid loss: 0.0947\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 7.1110015498571785e-06\n",
            "epoch: 18 MSE loss: 0.1555 MSE valid loss: 0.0945\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.931087162517846e-06\n",
            "epoch: 19 MSE loss: 0.1541 MSE valid loss: 0.0946\n",
            "Updating learning rate to 6.76417225936176e-06\n",
            "epoch: 20 MSE loss: 0.1537 MSE valid loss: 0.0943\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.608763214317868e-06\n",
            "epoch: 21 MSE loss: 0.1529 MSE valid loss: 0.0942\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.463596124937739e-06\n",
            "epoch: 22 MSE loss: 0.1521 MSE valid loss: 0.0941\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.327593294406922e-06\n",
            "epoch: 23 MSE loss: 0.1518 MSE valid loss: 0.0941\n",
            "Updating learning rate to 6.199829383043036e-06\n",
            "epoch: 24 MSE loss: 0.1507 MSE valid loss: 0.0941\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 6.079504788572469e-06\n",
            "epoch: 25 MSE loss: 0.1507 MSE valid loss: 0.0941\n",
            "Best score! Weights of the model are updated!\n",
            "Updating learning rate to 5.965924498791846e-06\n",
            "epoch: 26 MSE loss: 0.1501 MSE valid loss: 0.0941\n",
            "Updating learning rate to 5.8584811349126495e-06\n",
            "epoch: 27 MSE loss: 0.1494 MSE valid loss: 0.0941\n",
            "Updating learning rate to 5.7566412382313e-06\n",
            "epoch: 28 MSE loss: 0.1494 MSE valid loss: 0.0941\n",
            "Updating learning rate to 5.659934091583234e-06\n",
            "epoch: 29 MSE loss: 0.1478 MSE valid loss: 0.0942\n",
            "Updating learning rate to 5.567942539842175e-06\n",
            "epoch: 30 MSE loss: 0.1490 MSE valid loss: 0.0943\n",
            "Updating learning rate to 5.48029540026768e-06\n",
            "epoch: 31 MSE loss: 0.1482 MSE valid loss: 0.0942\n",
            "Updating learning rate to 5.39666114720432e-06\n",
            "epoch: 32 MSE loss: 0.1471 MSE valid loss: 0.0945\n",
            "Updating learning rate to 5.316742625738919e-06\n",
            "epoch: 33 MSE loss: 0.1465 MSE valid loss: 0.0945\n",
            "Updating learning rate to 5.240272601878983e-06\n",
            "epoch: 34 MSE loss: 0.1456 MSE valid loss: 0.0948\n",
            "Updating learning rate to 5.16700999718195e-06\n",
            "epoch: 35 MSE loss: 0.1455 MSE valid loss: 0.0948\n",
            "Updating learning rate to 5.096736686795811e-06\n",
            "epoch: 36 MSE loss: 0.1451 MSE valid loss: 0.0950\n",
            "Updating learning rate to 5.029254763916053e-06\n",
            "epoch: 37 MSE loss: 0.1458 MSE valid loss: 0.0950\n",
            "Updating learning rate to 4.964384192434611e-06\n",
            "epoch: 38 MSE loss: 0.1454 MSE valid loss: 0.0952\n",
            "Updating learning rate to 4.901960784313726e-06\n",
            "epoch: 39 MSE loss: 0.1436 MSE valid loss: 0.0954\n",
            "Updating learning rate to 4.841834449897069e-06\n",
            "epoch: 40 MSE loss: 0.1430 MSE valid loss: 0.0956\n",
            "Updating learning rate to 4.783867678672252e-06\n",
            "epoch: 41 MSE loss: 0.1437 MSE valid loss: 0.0959\n",
            "Updating learning rate to 4.727934215451461e-06\n",
            "epoch: 42 MSE loss: 0.1421 MSE valid loss: 0.0961\n",
            "Updating learning rate to 4.673917902941745e-06\n",
            "epoch: 43 MSE loss: 0.1434 MSE valid loss: 0.0964\n",
            "Updating learning rate to 4.621711666540848e-06\n",
            "epoch: 44 MSE loss: 0.1421 MSE valid loss: 0.0964\n",
            "Updating learning rate to 4.571216621155238e-06\n",
            "epoch: 45 MSE loss: 0.1422 MSE valid loss: 0.0968\n",
            "Updating learning rate to 4.5223412830776355e-06\n",
            "epoch: 46 MSE loss: 0.1420 MSE valid loss: 0.0968\n",
            "Updating learning rate to 4.475000872625255e-06\n",
            "epoch: 47 MSE loss: 0.1407 MSE valid loss: 0.0970\n",
            "Updating learning rate to 4.42911669543945e-06\n",
            "epoch: 48 MSE loss: 0.1403 MSE valid loss: 0.0974\n",
            "Updating learning rate to 4.3846155921711576e-06\n",
            "epoch: 49 MSE loss: 0.1410 MSE valid loss: 0.0975\n",
            "Updating learning rate to 4.341429447794925e-06\n",
            "epoch: 50 MSE loss: 0.1397 MSE valid loss: 0.0978\n",
            "Updating learning rate to 4.299494753063186e-06\n",
            "epoch: 51 MSE loss: 0.1396 MSE valid loss: 0.0978\n",
            "Updating learning rate to 4.258752211677067e-06\n",
            "epoch: 52 MSE loss: 0.1398 MSE valid loss: 0.0980\n",
            "Updating learning rate to 4.219146387646126e-06\n",
            "epoch: 53 MSE loss: 0.1396 MSE valid loss: 0.0983\n",
            "Updating learning rate to 4.18062538806657e-06\n",
            "epoch: 54 MSE loss: 0.1402 MSE valid loss: 0.0984\n",
            "Updating learning rate to 4.143140577189122e-06\n",
            "epoch: 55 MSE loss: 0.1398 MSE valid loss: 0.0984\n",
            "Updating learning rate to 4.106646318193315e-06\n",
            "epoch: 56 MSE loss: 0.1391 MSE valid loss: 0.0985\n",
            "Updating learning rate to 4.071099739550263e-06\n",
            "epoch: 57 MSE loss: 0.1384 MSE valid loss: 0.0988\n",
            "Updating learning rate to 4.036460523253916e-06\n",
            "epoch: 58 MSE loss: 0.1383 MSE valid loss: 0.0987\n",
            "Updating learning rate to 4.002690712542218e-06\n",
            "epoch: 59 MSE loss: 0.1379 MSE valid loss: 0.0988\n",
            "Updating learning rate to 3.969754537023144e-06\n",
            "epoch: 60 MSE loss: 0.1377 MSE valid loss: 0.0991\n",
            "Updating learning rate to 3.937618253373847e-06\n",
            "epoch: 61 MSE loss: 0.1371 MSE valid loss: 0.0991\n",
            "Updating learning rate to 3.90625e-06\n",
            "epoch: 62 MSE loss: 0.1370 MSE valid loss: 0.0992\n",
            "Updating learning rate to 3.8756196642321895e-06\n",
            "epoch: 63 MSE loss: 0.1369 MSE valid loss: 0.0994\n",
            "Updating learning rate to 3.845698760800996e-06\n",
            "epoch: 64 MSE loss: 0.1371 MSE valid loss: 0.0994\n",
            "Updating learning rate to 3.816460320475954e-06\n",
            "epoch: 65 MSE loss: 0.1368 MSE valid loss: 0.0994\n",
            "Updating learning rate to 3.7878787878787882e-06\n",
            "epoch: 66 MSE loss: 0.1367 MSE valid loss: 0.1000\n",
            "Updating learning rate to 3.759929927590882e-06\n",
            "epoch: 67 MSE loss: 0.1358 MSE valid loss: 0.0998\n",
            "Updating learning rate to 3.732590737770921e-06\n",
            "epoch: 68 MSE loss: 0.1362 MSE valid loss: 0.1000\n",
            "Updating learning rate to 3.7058393705829336e-06\n",
            "epoch: 69 MSE loss: 0.1358 MSE valid loss: 0.1002\n",
            "Updating learning rate to 3.6796550588091485e-06\n",
            "epoch: 70 MSE loss: 0.1357 MSE valid loss: 0.1001\n",
            "Updating learning rate to 3.6540180480874438e-06\n",
            "epoch: 71 MSE loss: 0.1360 MSE valid loss: 0.1003\n",
            "Updating learning rate to 3.6289095342709304e-06\n",
            "epoch: 72 MSE loss: 0.1357 MSE valid loss: 0.1002\n",
            "Updating learning rate to 3.604311605458291e-06\n",
            "epoch: 73 MSE loss: 0.1351 MSE valid loss: 0.1004\n",
            "Updating learning rate to 3.58020718828878e-06\n",
            "epoch: 74 MSE loss: 0.1350 MSE valid loss: 0.1006\n",
            "Updating learning rate to 3.5565799981359997e-06\n",
            "epoch: 75 MSE loss: 0.1349 MSE valid loss: 0.1004\n",
            "Updating learning rate to 3.5334144928703013e-06\n",
            "epoch: 76 MSE loss: 0.1352 MSE valid loss: 0.1005\n",
            "Updating learning rate to 3.5106958298915256e-06\n",
            "epoch: 77 MSE loss: 0.1345 MSE valid loss: 0.1006\n",
            "Updating learning rate to 3.4884098261621723e-06\n",
            "epoch: 78 MSE loss: 0.1348 MSE valid loss: 0.1007\n",
            "Updating learning rate to 3.466542920996499e-06\n",
            "epoch: 79 MSE loss: 0.1341 MSE valid loss: 0.1010\n",
            "Updating learning rate to 3.4450821413837328e-06\n",
            "epoch: 80 MSE loss: 0.1342 MSE valid loss: 0.1008\n",
            "Updating learning rate to 3.4240150696439336e-06\n",
            "epoch: 81 MSE loss: 0.1345 MSE valid loss: 0.1009\n",
            "Updating learning rate to 3.4033298132333132e-06\n",
            "epoch: 82 MSE loss: 0.1340 MSE valid loss: 0.1008\n",
            "Updating learning rate to 3.383014976532195e-06\n",
            "epoch: 83 MSE loss: 0.1343 MSE valid loss: 0.1012\n",
            "Updating learning rate to 3.3630596344635904e-06\n",
            "epoch: 84 MSE loss: 0.1336 MSE valid loss: 0.1009\n",
            "Updating learning rate to 3.3434533078036348e-06\n",
            "epoch: 85 MSE loss: 0.1335 MSE valid loss: 0.1013\n",
            "Updating learning rate to 3.3241859400571367e-06\n",
            "epoch: 86 MSE loss: 0.1338 MSE valid loss: 0.1016\n",
            "Updating learning rate to 3.305247875782325e-06\n",
            "epoch: 87 MSE loss: 0.1332 MSE valid loss: 0.1011\n",
            "Updating learning rate to 3.2866298402586612e-06\n",
            "epoch: 88 MSE loss: 0.1332 MSE valid loss: 0.1012\n",
            "Updating learning rate to 3.2683229204004673e-06\n",
            "epoch: 89 MSE loss: 0.1332 MSE valid loss: 0.1018\n",
            "Updating learning rate to 3.2503185468271486e-06\n",
            "epoch: 90 MSE loss: 0.1335 MSE valid loss: 0.1018\n",
            "Updating learning rate to 3.232608477008077e-06\n",
            "epoch: 91 MSE loss: 0.1338 MSE valid loss: 0.1016\n",
            "Updating learning rate to 3.2151847794068398e-06\n",
            "epoch: 92 MSE loss: 0.1327 MSE valid loss: 0.1015\n",
            "Updating learning rate to 3.1980398185555676e-06\n",
            "epoch: 93 MSE loss: 0.1333 MSE valid loss: 0.1015\n",
            "Updating learning rate to 3.1811662409955475e-06\n",
            "epoch: 94 MSE loss: 0.1331 MSE valid loss: 0.1018\n",
            "Updating learning rate to 3.1645569620253167e-06\n",
            "epoch: 95 MSE loss: 0.1325 MSE valid loss: 0.1019\n",
            "Updating learning rate to 3.1482051532020014e-06\n",
            "epoch: 96 MSE loss: 0.1327 MSE valid loss: 0.1016\n",
            "Updating learning rate to 3.1321042305458136e-06\n",
            "epoch: 97 MSE loss: 0.1320 MSE valid loss: 0.1015\n",
            "Updating learning rate to 3.116247843401426e-06\n",
            "epoch: 98 MSE loss: 0.1321 MSE valid loss: 0.1020\n",
            "Updating learning rate to 3.1006298639134353e-06\n",
            "epoch: 99 MSE loss: 0.1321 MSE valid loss: 0.1024\n",
            "Elapsed Time: 172.92387808500007\n"
          ]
        }
      ],
      "source": [
        "c_in = 7\n",
        "context_window = 336\n",
        "target_window = 96\n",
        "patch_len = 16\n",
        "stride = 8\n",
        "\n",
        "patchtst_model = PatchTST(c_in=c_in, context_window=context_window, target_window=target_window, patch_len=patch_len, stride=stride)\n",
        "\n",
        "# Linear_model = Linear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
        "# DLinear_model = DLinear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
        "\n",
        "# Linear_learner = Learner_2(model=Linear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
        "# DLinear_learner = Learner_2(model=DLinear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
        "patchtst_learner = Learner(model=patchtst_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
        "\n",
        "# Linear_train_history, Linear_valid_history = Linear_learner.train()\n",
        "# DLinear_train_history, DLinear_valid_history = DLinear_learner.train()\n",
        "# import torch.autograd.profiler as profiler\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
        "patchtst_train_history, patchtst_valid_history = patchtst_learner.train()\n",
        "\n",
        "end_time = time.perf_counter()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Elapsed Time:\", elapsed_time)\n",
        "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
        "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Techniques"
      ],
      "metadata": {
        "id": "KZwZyLsOPMO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_learner.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gz28atCO-aq",
        "outputId": "15291dfa-ea6e-42e9-f3f2-bfbe528728eb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE test loss: 0.0550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "# import torchsummary"
      ],
      "metadata": {
        "id": "mQ5X0XDfUfmC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxy2PEbJcmj",
        "outputId": "697a3233-ba6e-40b3-ea12-1c5146b1ea5e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTST(\n",
              "  (revin_layer): RevIN()\n",
              "  (backbone): TSTiEncoder(\n",
              "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (encoder): TSTEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-2): 3 x TSTEncoderLayer(\n",
              "          (self_attn): _MultiheadAttention(\n",
              "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sdp_attn): _ScaledDotProductAttention(\n",
              "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (1): Dropout(p=0.3, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_attn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "          (ff): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_ffn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Flatten_Head(\n",
              "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
              "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Memory and Time Usage"
      ],
      "metadata": {
        "id": "sO8YCi9qYNj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "grab a sample from the test dataloder"
      ],
      "metadata": {
        "id": "wXkvzCW8UOla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cuda')"
      ],
      "metadata": {
        "id": "Je-UKQlNTX3I"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patchtst_model.eval()\n",
        "patchtst_model(next(iter(patchtst_learner.test_dataloader))[0].to('cuda')).squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qNEs840PO1I",
        "outputId": "4b15f188-1023-4237-d4b5-231cfdb30c95"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 96, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "ZurTHQ-BPNzf"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIRaNODpM55s",
        "outputId": "ad1a6ba5-f32e-465f-c90c-b8146c34e9f8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        22.76%       4.219ms        99.83%      18.504ms      18.504ms       0.000us         0.00%       8.832ms       8.832ms             1  \n",
            "                                           aten::linear         1.45%     269.000us        41.75%       7.738ms     386.900us       0.000us         0.00%       4.970ms     248.500us            20  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.587ms        40.61%       3.587ms     188.789us            19  \n",
            "                                           aten::matmul         1.51%     279.000us        17.23%       3.193ms     199.562us       0.000us         0.00%       3.067ms     191.688us            16  \n",
            "                                            aten::addmm         3.63%     672.000us        26.49%       4.910ms     491.000us       2.669ms        30.22%       2.669ms     266.900us            10  \n",
            "                                            aten::clone         1.21%     224.000us         8.52%       1.579ms      68.652us       0.000us         0.00%       1.417ms      61.609us            23  \n",
            "                                            aten::copy_         2.62%     485.000us         4.66%     863.000us      37.522us       1.417ms        16.04%       1.417ms      61.609us            23  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.417ms        16.04%       1.417ms      61.609us            23  \n",
            "                                          aten::reshape         1.54%     286.000us         9.72%       1.802ms      53.000us       0.000us         0.00%       1.212ms      35.647us            34  \n",
            "                           aten::_batch_norm_impl_index         0.27%      50.000us         4.79%     887.000us     147.833us       0.000us         0.00%       1.203ms     200.500us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 18.536ms\n",
            "Self CUDA time total: 8.832ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model size"
      ],
      "metadata": {
        "id": "RjjiWJ_eYTbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def print_model_size(mdl):\n",
        "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
        "    print(\"Size of model: %.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
        "    os.remove('tmp.pt')"
      ],
      "metadata": {
        "id": "T-HD7C8ZYW0Y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_model_size(patchtst_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02JBc0VmFnKz",
        "outputId": "726618bc-ef24-4993-8196-b4b052d44f87"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of model: 3.27 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of params"
      ],
      "metadata": {
        "id": "uBG0zuzKWK64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "Q5Ri8PqgNP_I",
        "outputId": "d0ce3d4f-27fd-409e-abc6-8ee64526e2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchsummary"
                ]
              },
              "id": "de48bfe7f5f84ee79436618f904bf874"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary"
      ],
      "metadata": {
        "id": "kGSW3r4SNfD0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(patchtst_model, input_size=(128,96,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeSn4U3nWOZo",
        "outputId": "8416e004-0503-4515-a861-309e6da41862"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "â”œâ”€RevIN: 1-1                                  14\n",
            "â”œâ”€TSTiEncoder: 1-2                            --\n",
            "|    â””â”€Linear: 2-1                            2,176\n",
            "|    â””â”€Dropout: 2-2                           --\n",
            "|    â””â”€TSTEncoder: 2-3                        --\n",
            "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
            "â”œâ”€Flatten_Head: 1-3                           --\n",
            "|    â””â”€Flatten: 2-4                           --\n",
            "|    â””â”€Linear: 2-5                            503,904\n",
            "|    â””â”€Dropout: 2-6                           --\n",
            "======================================================================\n",
            "Total params: 804,849\n",
            "Trainable params: 506,094\n",
            "Non-trainable params: 298,755\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "â”œâ”€RevIN: 1-1                                  14\n",
              "â”œâ”€TSTiEncoder: 1-2                            --\n",
              "|    â””â”€Linear: 2-1                            2,176\n",
              "|    â””â”€Dropout: 2-2                           --\n",
              "|    â””â”€TSTEncoder: 2-3                        --\n",
              "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
              "â”œâ”€Flatten_Head: 1-3                           --\n",
              "|    â””â”€Flatten: 2-4                           --\n",
              "|    â””â”€Linear: 2-5                            503,904\n",
              "|    â””â”€Dropout: 2-6                           --\n",
              "======================================================================\n",
              "Total params: 804,849\n",
              "Trainable params: 506,094\n",
              "Non-trainable params: 298,755\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qi8eMSHGOpRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pruning"
      ],
      "metadata": {
        "id": "3Gc9b93cPO2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0IBqSu_PVet",
        "outputId": "b56e1c6e-670b-48d1-a955-b5ac17d380f9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTST(\n",
              "  (revin_layer): RevIN()\n",
              "  (backbone): TSTiEncoder(\n",
              "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (encoder): TSTEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-2): 3 x TSTEncoderLayer(\n",
              "          (self_attn): _MultiheadAttention(\n",
              "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sdp_attn): _ScaledDotProductAttention(\n",
              "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (to_out): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (1): Dropout(p=0.3, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_attn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "          (ff): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
              "          (norm_ffn): Sequential(\n",
              "            (0): Transpose()\n",
              "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): Transpose()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Flatten_Head(\n",
              "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
              "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "_nuRpdbtP7_a"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module = patchtst_model.backbone.encoder.layers[0].self_attn.to_out[0]\n",
        "print(list(module.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICCXO7wEPQMt",
        "outputId": "bdff67f4-d908-4d6f-d7ad-d504e8352003"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[-0.0661, -0.0228, -0.0930,  ...,  0.0015,  0.0707,  0.0676],\n",
            "        [ 0.0242, -0.0577,  0.0072,  ..., -0.0612,  0.0173,  0.0642],\n",
            "        [ 0.0344, -0.0070, -0.0215,  ..., -0.0756,  0.0797,  0.0391],\n",
            "        ...,\n",
            "        [-0.0070, -0.0466, -0.0398,  ..., -0.0076,  0.0144,  0.0026],\n",
            "        [ 0.0648, -0.0052,  0.0814,  ..., -0.0625,  0.0162,  0.0224],\n",
            "        [-0.0798,  0.0583, -0.0068,  ..., -0.0488, -0.0343,  0.0521]],\n",
            "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([-0.0803,  0.0176,  0.0573,  0.0228, -0.0348,  0.0357, -0.0368,  0.0630,\n",
            "         0.0456, -0.0574,  0.0387, -0.0698, -0.0418, -0.0623,  0.0378,  0.0615,\n",
            "         0.0727, -0.0588,  0.0535, -0.0467,  0.0512, -0.0745,  0.0329, -0.0139,\n",
            "        -0.0644,  0.0532,  0.0612, -0.0370, -0.0311,  0.0747, -0.0438,  0.0252,\n",
            "         0.0277, -0.0413,  0.0403,  0.0159, -0.0515, -0.0389, -0.0589, -0.0402,\n",
            "         0.0659,  0.0020,  0.0012,  0.0309,  0.0107, -0.0229,  0.0319,  0.0835,\n",
            "        -0.0463,  0.0217,  0.0811,  0.0266,  0.0341, -0.0182,  0.0062, -0.0469,\n",
            "        -0.0478, -0.0727, -0.0274, -0.0271,  0.0273, -0.0363,  0.0373,  0.0269,\n",
            "        -0.0425, -0.0256, -0.0161, -0.0659,  0.0474, -0.0784, -0.0090, -0.0406,\n",
            "        -0.0353,  0.0064, -0.0696, -0.0790,  0.0019,  0.0024, -0.0744,  0.0346,\n",
            "         0.0331,  0.0700,  0.0594, -0.0045,  0.0459,  0.0185,  0.0663,  0.0625,\n",
            "         0.0793,  0.0172,  0.0305,  0.0204,  0.0521, -0.0640,  0.0146, -0.0722,\n",
            "        -0.0515,  0.0596,  0.0812,  0.0322, -0.0795, -0.0442,  0.0705,  0.0406,\n",
            "        -0.0769, -0.0155,  0.0569,  0.0481, -0.0336, -0.0030, -0.0223,  0.0074,\n",
            "         0.0613, -0.0820, -0.0572, -0.0366, -0.0504, -0.0778,  0.0169,  0.0685,\n",
            "        -0.0498, -0.0130, -0.0245,  0.0152,  0.0004,  0.0630, -0.0281,  0.0282],\n",
            "       device='cuda:0', requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prune.random_unstructured(module, name=\"weight\", amount=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlmyBhlBQ2Ob",
        "outputId": "c9ba0dc4-770d-445f-d871-ffce98ddaad0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=128, out_features=128, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyebneqxRWTU",
        "outputId": "26c4bb40-209b-402b-9b81-dc54c93894f3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0661, -0.0000, -0.0930,  ...,  0.0015,  0.0000,  0.0000],\n",
            "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0173,  0.0642],\n",
            "        [ 0.0344, -0.0000, -0.0215,  ..., -0.0000,  0.0797,  0.0391],\n",
            "        ...,\n",
            "        [-0.0070, -0.0466, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000, -0.0052,  0.0814,  ..., -0.0000,  0.0162,  0.0224],\n",
            "        [-0.0798,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(patchtst_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOVEsvSFRIrH",
        "outputId": "d71bcce1-334d-4c00-d340-e9a66ab48f11"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "â”œâ”€RevIN: 1-1                                  14\n",
            "â”œâ”€TSTiEncoder: 1-2                            --\n",
            "|    â””â”€Linear: 2-1                            2,176\n",
            "|    â””â”€Dropout: 2-2                           --\n",
            "|    â””â”€TSTEncoder: 2-3                        --\n",
            "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
            "â”œâ”€Flatten_Head: 1-3                           --\n",
            "|    â””â”€Flatten: 2-4                           --\n",
            "|    â””â”€Linear: 2-5                            503,904\n",
            "|    â””â”€Dropout: 2-6                           --\n",
            "======================================================================\n",
            "Total params: 804,849\n",
            "Trainable params: 506,094\n",
            "Non-trainable params: 298,755\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "â”œâ”€RevIN: 1-1                                  14\n",
              "â”œâ”€TSTiEncoder: 1-2                            --\n",
              "|    â””â”€Linear: 2-1                            2,176\n",
              "|    â””â”€Dropout: 2-2                           --\n",
              "|    â””â”€TSTEncoder: 2-3                        --\n",
              "|    |    â””â”€ModuleList: 3-1                   (298,755)\n",
              "â”œâ”€Flatten_Head: 1-3                           --\n",
              "|    â””â”€Flatten: 2-4                           --\n",
              "|    â””â”€Linear: 2-5                            503,904\n",
              "|    â””â”€Dropout: 2-6                           --\n",
              "======================================================================\n",
              "Total params: 804,849\n",
              "Trainable params: 506,094\n",
              "Non-trainable params: 298,755\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cuda')\n",
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "o9JZwalwRcES"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1tLVKeuRlG8",
        "outputId": "864fbfb4-27ae-4a83-ad1a-304b28c303d9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        30.49%       4.379ms        86.82%      12.470ms      12.470ms       0.000us         0.00%       8.882ms       8.882ms             1  \n",
            "                                           aten::linear         1.28%     184.000us        17.41%       2.500ms     125.000us       0.000us         0.00%       4.991ms     249.550us            20  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.605ms        40.59%       3.605ms     189.737us            19  \n",
            "                                           aten::matmul         1.34%     193.000us        15.25%       2.191ms     136.938us       0.000us         0.00%       3.100ms     193.750us            16  \n",
            "                                            aten::addmm         3.44%     494.000us         4.26%     612.000us      61.200us       2.671ms        30.07%       2.671ms     267.100us            10  \n",
            "                                            aten::clone         0.94%     135.000us         7.04%       1.011ms      43.957us       0.000us         0.00%       1.426ms      62.000us            23  \n",
            "                                            aten::copy_         2.37%     340.000us         4.13%     593.000us      25.783us       1.426ms        16.05%       1.426ms      62.000us            23  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.426ms        16.05%       1.426ms      62.000us            23  \n",
            "                                          aten::reshape         1.30%     187.000us         8.00%       1.149ms      33.794us       0.000us         0.00%       1.220ms      35.882us            34  \n",
            "                                       aten::batch_norm         0.13%      18.000us         4.55%     654.000us     109.000us       0.000us         0.00%       1.204ms     200.667us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.363ms\n",
            "Self CUDA time total: 8.882ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in patchtst_model.named_modules():\n",
        "    # prune 20% of connections in all 2D-conv layers\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
        "    # prune 40% of connections in all linear layers\n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.4)"
      ],
      "metadata": {
        "id": "opiX08OdRyh4"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = next(iter(patchtst_learner.test_dataloader))[0].to('cuda')\n",
        "with profile(activities=[\n",
        "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "       patchtst_model.eval()\n",
        "       patchtst_model(input)"
      ],
      "metadata": {
        "id": "Y7WLFmk4Sh50"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8v5fcOeSlT0",
        "outputId": "faee1098-c40f-4d62-f6da-75c9961e3b2d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        35.10%       4.818ms        97.61%      13.400ms      13.400ms       0.000us         0.00%       8.884ms       8.884ms             1  \n",
            "                                           aten::linear         1.67%     229.000us        20.87%       2.865ms     143.250us       0.000us         0.00%       4.969ms     248.450us            20  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.592ms        40.43%       3.592ms     189.053us            19  \n",
            "                                           aten::matmul         1.47%     202.000us        16.31%       2.239ms     139.938us       0.000us         0.00%       3.069ms     191.812us            16  \n",
            "                                            aten::addmm         4.09%     562.000us         5.24%     719.000us      71.900us       2.669ms        30.04%       2.669ms     266.900us            10  \n",
            "                                            aten::clone         1.25%     172.000us         7.33%       1.006ms      43.739us       0.000us         0.00%       1.414ms      61.478us            23  \n",
            "                                            aten::copy_         2.24%     308.000us         3.84%     527.000us      22.913us       1.414ms        15.92%       1.414ms      61.478us            23  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.414ms        15.92%       1.414ms      61.478us            23  \n",
            "                                          aten::reshape         1.42%     195.000us         8.46%       1.162ms      34.176us       0.000us         0.00%       1.209ms      35.559us            34  \n",
            "                                       aten::batch_norm         0.12%      17.000us         5.41%     743.000us     123.833us       0.000us         0.00%       1.204ms     200.667us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 13.728ms\n",
            "Self CUDA time total: 8.884ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patchtst_model.eval()\n",
        "iter_count = 0\n",
        "total_loss = 0\n",
        "with torch.no_grad():\n",
        "    for test_x, test_y in patchtst_learner.test_dataloader:\n",
        "        test_x = test_x.to(\"cuda\")\n",
        "        test_y = test_y.to(\"cuda\")\n",
        "        pred_y = patchtst_model(test_x)\n",
        "        pred_y = pred_y[:, -patchtst_learner.target_window:, -1:].squeeze(-1)\n",
        "        loss = patchtst_learner.loss(pred_y, test_y)\n",
        "        total_loss += loss.item()\n",
        "        iter_count += 1\n",
        "total_loss /= iter_count\n",
        "print(\"MSE test loss: {:.4f}\".format(total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb71VTTtSrSU",
        "outputId": "6d17ad47-3b95-4b33-a403-53c8432e353b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE test loss: 0.0562\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my_env",
      "language": "python",
      "name": "my_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}