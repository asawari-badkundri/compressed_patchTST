{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from typing import Callable, Optional\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
      "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
      "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
      "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
      "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n"
     ]
    }
   ],
   "source": [
    "df_ETTh1 = pd.read_csv(\"/scratch/ab10445/hpml/PatchTST/dataset/ETT-small/ETTh1.csv\")\n",
    "print(df_ETTh1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train test datasets\n",
    "class ETTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset=\"ETTh1\", mode=\"train\", scale=True, seq_len=336, pred_len=96):\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(\"/scratch/ab10445/hpml/PatchTST/dataset/ETT-small/ETTh1.csv\".format(dataset))\n",
    "        x_y = df.iloc[:,1:]\n",
    "        time_stamp = df.iloc[:,0]\n",
    "\n",
    "        assert mode in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[mode]\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        if scale:\n",
    "            train_x_y = x_y.iloc[border1s[0]: border2s[0]]\n",
    "            self.ss = StandardScaler()\n",
    "            self.ss.fit(train_x_y.to_numpy(dtype=np.float32))\n",
    "            x_y = self.ss.transform(x_y.to_numpy(dtype=np.float32))\n",
    "        else:\n",
    "            x_y = x_y.to_numpy(dtype=np.float32)\n",
    "        \n",
    "        time_stamp = time_stamp.to_numpy()     \n",
    "        \n",
    "        self.data_x = x_y[border1: border2, :]\n",
    "        self.data_y = x_y[border1: border2, -1]\n",
    "\n",
    "        self.data_stamp = time_stamp[border1: border2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return seq_x, seq_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.ss.inverse_transform(data)\n",
    "'''\n",
    "Reversible instance normalization\n",
    "RevIN is symmetrically structured to return the original distribution information to the model output by \n",
    "scaling and shifting the output in the denormalization layer in an amount equivalent to the shifting and \n",
    "scaling of the input data in the normalization layer.\n",
    "'''\n",
    "#Revin.py\n",
    "class RevIN(torch.nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        # initialize RevIN params: (C,)\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            # print(f'x.mT.shape: {x.mT.shape} | self.affine_weight: {self.affine_weight.shape}')\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "            # print(f'x.shape: {x.shape} | self.affine_weight: {self.affine_bias.shape}')\n",
    "            # x = x + self.affine_bias\n",
    "        return x.mT\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x\n",
    "\n",
    "#PatchTST_layers.py\n",
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False): \n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
    "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "   class TSTiEncoder(torch.nn.Module):  #i means channel-independent\n",
    "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
    "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
    "                 d_ff=128, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
    "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True, verbose=False, **kwargs):\n",
    "                 #act=\"gelu\" \n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_num = patch_num\n",
    "        self.patch_len = patch_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = patch_num\n",
    "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "        self.seq_len = q_len\n",
    "\n",
    "        # Positional encoding\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
    "\n",
    "        \n",
    "    def forward(self, x) -> Tensor:                                              # x: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        n_vars = x.shape[1]\n",
    "        # Input encoding\n",
    "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
    "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
    "\n",
    "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
    "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
    "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
    "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
    "        \n",
    "        return z                \n",
    "    \n",
    "# Cell\n",
    "class TSTEncoder(torch.nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, \n",
    "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
    "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
    "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                                      activation=activation, res_attention=res_attention,\n",
    "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "        else:\n",
    "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "\n",
    "class TSTEncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=128, store_attn=False,\n",
    "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
    "                                torch.nn.GELU(),\n",
    "                                nn.Dropout(dropout),\n",
    "                                nn.Linear(d_ff, d_model, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "\n",
    "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn:\n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "\n",
    "class _MultiheadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
    "        \"\"\"Multi Head Attention Layer\n",
    "        Input shape:\n",
    "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
    "            K, V:    [batch_size (bs) x q_len x d_model]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
    "        prev = None\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        # self.sdp_attn = lora.MergedLinear(\n",
    "        #     nx, n_state * 3, \n",
    "        #     r=config.lora_attn_dim, \n",
    "        #     lora_alpha=config.lora_attn_alpha, \n",
    "        #     lora_dropout=config.lora_dropout, \n",
    "        #     enable_lora=[True, False, True], \n",
    "        #     fan_in_fan_out=True,\n",
    "        #     merge_weights=False\n",
    "        # )\n",
    "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
    "\n",
    "        # Poject output\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
    "\n",
    "\n",
    "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,\n",
    "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            # self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights\n",
    "\n",
    "class _ScaledDotProductAttention(torch.nn.Module):\n",
    "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
    "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
    "    by Lee et al, 2021)\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
    "        super().__init__()\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.res_attention = res_attention\n",
    "        head_dim = d_model // n_heads\n",
    "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
    "        self.lsa = lsa\n",
    "\n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "        Output shape:\n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev\n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights\n",
    "\n",
    "class Flatten_Head(torch.nn.Module):\n",
    "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.individual = individual\n",
    "        self.n_vars = n_vars\n",
    "        \n",
    "        if self.individual:\n",
    "            self.linears = nn.ModuleList()\n",
    "            self.dropouts = nn.ModuleList()\n",
    "            self.flattens = nn.ModuleList()\n",
    "            for i in range(self.n_vars):\n",
    "                self.flattens.append(nn.Flatten(start_dim=-2)) #flattens last 2\n",
    "                self.linears.append(nn.Linear(nf, target_window))\n",
    "                self.dropouts.append(nn.Dropout(head_dropout))\n",
    "        else:\n",
    "            self.flatten = nn.Flatten(start_dim=-2)\n",
    "            self.linear = nn.Linear(nf, target_window)\n",
    "            self.dropout = nn.Dropout(head_dropout)\n",
    "            \n",
    "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
    "        if self.individual:\n",
    "            x_out = []\n",
    "            for i in range(self.n_vars):\n",
    "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
    "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
    "                z = self.dropouts[i](z)\n",
    "                x_out.append(z)\n",
    "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
    "        else:\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "#Implementation of PatchTST\n",
    "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n",
    "    x = .5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
    "        pv(f'{i:4.0f}  {x:5.3f}  {cpe.mean():+6.3f}', verbose)\n",
    "        if abs(cpe.mean()) <= eps: break\n",
    "        elif cpe.mean() > eps: x += .001\n",
    "        else: x -= .001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "\n",
    "class PatchTST(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window, patch_len, stride, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers=3, d_model=128, n_heads=4, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 d_ff:int=128, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0.3, act:str=\"gelu\", key_padding_mask:bool='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0.3, head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
    "                 verbose:bool=False, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "        \n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((context_window - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "        \n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = d_model * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        if self.revin: \n",
    "            # z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            # z = z.permute(0,2,1)\n",
    "            \n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        # print(f'z.shape: {z.shape}')\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x target_window] \n",
    "        \n",
    "        # denorm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            # z = z.permute(0,2,1)\n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear model\n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window):\n",
    "        super().__init__()\n",
    "        self.c_in = c_in\n",
    "        self.context_winsoq = context_window\n",
    "        self.target_window = target_window\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(start_dim=-2)\n",
    "\n",
    "        self.linear = torch.nn.Linear(c_in * context_window, target_window)\n",
    "    \n",
    "    def forward(self, x):                   # x: [bs x seq_len × nvars]\n",
    "        x = self.flatten(x)                 # x: [bs x seq_len * nvars]\n",
    "        x = self.linear(x)                  # x: [bs x target_window]\n",
    "        return x\n",
    "    \n",
    "\n",
    "class moving_avg(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = torch.nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "class DLinear(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window):\n",
    "        super().__init__()\n",
    "        # Decompsition Kernel Size\n",
    "        kernel_size = 25\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.flatten_Seasonal = torch.nn.Flatten(start_dim=-2)\n",
    "        self.flatten_Trend = torch.nn.Flatten(start_dim=-2)\n",
    "        \n",
    "        self.Linear_Seasonal = torch.nn.Linear(c_in * context_window, target_window)\n",
    "        self.Linear_Trend = torch.nn.Linear(c_in * context_window, target_window)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init = self.flatten_Seasonal(x)\n",
    "        trend_init = self.flatten_Trend(x)\n",
    "\n",
    "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x\n",
    "\n",
    "class Learner:\n",
    "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=1, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
    "        self.model = model.to(\"cuda\")\n",
    "        self.batch_size = batch_size\n",
    "        train_dataset = dataset(mode=\"train\")\n",
    "        valid_dataset = dataset(mode=\"val\")\n",
    "        test_dataset = dataset(mode=\"test\")\n",
    "        self.train_datalen = len(train_dataset)\n",
    "        self.valid_datalen = len(valid_dataset)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.lr=lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.epochs = epochs\n",
    "        self.target_window=target_window\n",
    "        self.best_weight = self.model.state_dict()\n",
    "        self.d_model=d_model\n",
    "        self.adjust_lr = adjust_lr\n",
    "        self.adjust_factor = adjust_factor\n",
    "    \n",
    "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
    "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
    "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
    "        else:\n",
    "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr_adjust\n",
    "        if printout: \n",
    "            print('Updating learning rate to {}'.format(lr_adjust))\n",
    "        return \n",
    "\n",
    "    def train(self):\n",
    "        best_valid_loss = np.inf\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "        train_steps = 1\n",
    "        if self.adjust_lr:\n",
    "            self.adjust_learning_rate(train_steps)\n",
    "        for epoch in range(self.epochs):\n",
    "            #train\n",
    "            self.model.train()\n",
    "            iter_count = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for train_x, train_y in self.train_dataloader:\n",
    "                train_x = train_x.to(\"cuda\")\n",
    "                train_y = train_y.to(\"cuda\")\n",
    "                # print(f'train_x.shape: {train_x.shape}')\n",
    "                pred_y = self.model(train_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "                train_steps += 1\n",
    "            if self.adjust_lr:\n",
    "                self.adjust_learning_rate(train_steps)\n",
    "\n",
    "            #valid\n",
    "            self.model.eval()\n",
    "            valid_iter_count = 0\n",
    "            valid_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for valid_x, valid_y in self.valid_dataloader:\n",
    "                    valid_x = valid_x.to(\"cuda\")\n",
    "                    valid_y = valid_y.to(\"cuda\")\n",
    "                    pred_y = self.model(valid_x)\n",
    "                    pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                    loss = self.loss(pred_y, valid_y)\n",
    "                    valid_total_loss += loss.item()\n",
    "                    valid_iter_count += 1\n",
    "            \n",
    "            total_loss /= iter_count\n",
    "            valid_total_loss /= valid_iter_count\n",
    "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
    "            if best_valid_loss >= valid_total_loss:\n",
    "                self.best_weight = self.model.state_dict()\n",
    "                best_valid_loss = valid_total_loss\n",
    "                print(\"Best score! Weights of the model are updated!\")\n",
    "            train_history.append(total_loss)\n",
    "            valid_history.append(valid_total_loss)\n",
    "        return train_history, valid_history\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cuda\")\n",
    "                test_y = test_y.to(\"cuda\")\n",
    "                pred_y = self.model(test_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "\n",
    "class Learner_2:\n",
    "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=50, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
    "        self.model = model.to(\"cuda\")\n",
    "        self.batch_size = batch_size\n",
    "        train_dataset = dataset(mode=\"train\")\n",
    "        valid_dataset = dataset(mode=\"val\")\n",
    "        test_dataset = dataset(mode=\"test\")\n",
    "        self.train_datalen = len(train_dataset)\n",
    "        self.valid_datalen = len(valid_dataset)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.lr=lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.epochs = epochs\n",
    "        self.target_window=target_window\n",
    "        self.best_weight = self.model.state_dict()\n",
    "        self.d_model=d_model\n",
    "        self.adjust_lr = adjust_lr\n",
    "        self.adjust_factor = adjust_factor\n",
    "    \n",
    "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
    "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
    "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
    "        else:\n",
    "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr_adjust\n",
    "        if printout: \n",
    "            print('Updating learning rate to {}'.format(lr_adjust))\n",
    "        return \n",
    "\n",
    "    def train(self):\n",
    "        best_valid_loss = np.inf\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "        train_steps = 1\n",
    "        if self.adjust_lr:\n",
    "            self.adjust_learning_rate(train_steps)\n",
    "        for epoch in range(self.epochs):\n",
    "            #train\n",
    "            self.model.train()\n",
    "            iter_count = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for train_x, train_y in self.train_dataloader:\n",
    "                train_x = train_x.to(\"cuda\")\n",
    "                train_y = train_y.to(\"cuda\")\n",
    "                # print(f'train_x.shape: {train_x.shape}')\n",
    "                pred_y = self.model(train_x)\n",
    "                # pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "                train_steps += 1\n",
    "            if self.adjust_lr:\n",
    "                self.adjust_learning_rate(train_steps)\n",
    "\n",
    "            #valid\n",
    "            self.model.eval()\n",
    "            valid_iter_count = 0\n",
    "            valid_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for valid_x, valid_y in self.valid_dataloader:\n",
    "                    valid_x = valid_x.to(\"cuda\")\n",
    "                    valid_y = valid_y.to(\"cuda\")\n",
    "                    pred_y = self.model(valid_x)\n",
    "                    # pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                    loss = self.loss(pred_y, valid_y)\n",
    "                    valid_total_loss += loss.item()\n",
    "                    valid_iter_count += 1\n",
    "            \n",
    "            total_loss /= iter_count\n",
    "            valid_total_loss /= valid_iter_count\n",
    "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
    "            if best_valid_loss >= valid_total_loss:\n",
    "                self.best_weight = self.model.state_dict()\n",
    "                best_valid_loss = valid_total_loss\n",
    "                print(\"Best score! Weights of the model are updated!\")\n",
    "            train_history.append(total_loss)\n",
    "            valid_history.append(valid_total_loss)\n",
    "        return train_history, valid_history\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cuda\")\n",
    "                test_y = test_y.to(\"cuda\")\n",
    "                pred_y = self.model(test_x)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.2360 MSE valid loss: 0.1335\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 6.302740438653415e-06\n",
      "epoch: 1 MSE loss: 0.2280 MSE valid loss: 0.1253\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 9.430054396763887e-06\n",
      "epoch: 2 MSE loss: 0.2101 MSE valid loss: 0.1159\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.2557368354874362e-05\n",
      "epoch: 3 MSE loss: 0.1952 MSE valid loss: 0.1094\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.3846219390542782e-05\n",
      "epoch: 4 MSE loss: 0.1851 MSE valid loss: 0.1052\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.264304343560434e-05\n",
      "epoch: 5 MSE loss: 0.1787 MSE valid loss: 0.1023\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.1707322644771175e-05\n",
      "epoch: 6 MSE loss: 0.1739 MSE valid loss: 0.1007\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.0952698858458087e-05\n",
      "epoch: 7 MSE loss: 0.1711 MSE valid loss: 0.0995\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.0327404809650346e-05\n",
      "epoch: 8 MSE loss: 0.1670 MSE valid loss: 0.0983\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 9.798272520870257e-06\n",
      "epoch: 9 MSE loss: 0.1649 MSE valid loss: 0.0976\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 9.342938659399199e-06\n",
      "epoch: 10 MSE loss: 0.1629 MSE valid loss: 0.0970\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 8.945703337056415e-06\n",
      "epoch: 11 MSE loss: 0.1614 MSE valid loss: 0.0964\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 8.595177052156612e-06\n",
      "epoch: 12 MSE loss: 0.1608 MSE valid loss: 0.0963\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 8.282869524032146e-06\n",
      "epoch: 13 MSE loss: 0.1586 MSE valid loss: 0.0959\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 8.002304995806e-06\n",
      "epoch: 14 MSE loss: 0.1571 MSE valid loss: 0.0953\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 7.748446592171797e-06\n",
      "epoch: 15 MSE loss: 0.1564 MSE valid loss: 0.0952\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 7.517309741553296e-06\n",
      "epoch: 16 MSE loss: 0.1548 MSE valid loss: 0.0950\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 7.305695402335044e-06\n",
      "epoch: 17 MSE loss: 0.1541 MSE valid loss: 0.0949\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 7.1110015498571785e-06\n",
      "epoch: 18 MSE loss: 0.1531 MSE valid loss: 0.0947\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 6.931087162517846e-06\n",
      "epoch: 19 MSE loss: 0.1533 MSE valid loss: 0.0948\n",
      "Updating learning rate to 6.76417225936176e-06\n",
      "epoch: 20 MSE loss: 0.1521 MSE valid loss: 0.0947\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 6.608763214317868e-06\n",
      "epoch: 21 MSE loss: 0.1506 MSE valid loss: 0.0947\n",
      "Updating learning rate to 6.463596124937739e-06\n",
      "epoch: 22 MSE loss: 0.1503 MSE valid loss: 0.0948\n",
      "Updating learning rate to 6.327593294406922e-06\n",
      "epoch: 23 MSE loss: 0.1496 MSE valid loss: 0.0949\n",
      "Updating learning rate to 6.199829383043036e-06\n",
      "epoch: 24 MSE loss: 0.1486 MSE valid loss: 0.0950\n",
      "Updating learning rate to 6.079504788572469e-06\n",
      "epoch: 25 MSE loss: 0.1480 MSE valid loss: 0.0950\n",
      "Updating learning rate to 5.965924498791846e-06\n",
      "epoch: 26 MSE loss: 0.1482 MSE valid loss: 0.0951\n",
      "Updating learning rate to 5.8584811349126495e-06\n",
      "epoch: 27 MSE loss: 0.1471 MSE valid loss: 0.0951\n",
      "Updating learning rate to 5.7566412382313e-06\n",
      "epoch: 28 MSE loss: 0.1459 MSE valid loss: 0.0954\n",
      "Updating learning rate to 5.659934091583234e-06\n",
      "epoch: 29 MSE loss: 0.1457 MSE valid loss: 0.0955\n",
      "Updating learning rate to 5.567942539842175e-06\n",
      "epoch: 30 MSE loss: 0.1464 MSE valid loss: 0.0954\n",
      "Updating learning rate to 5.48029540026768e-06\n",
      "epoch: 31 MSE loss: 0.1453 MSE valid loss: 0.0958\n",
      "Updating learning rate to 5.39666114720432e-06\n",
      "epoch: 32 MSE loss: 0.1442 MSE valid loss: 0.0959\n",
      "Updating learning rate to 5.316742625738919e-06\n",
      "epoch: 33 MSE loss: 0.1437 MSE valid loss: 0.0962\n",
      "Updating learning rate to 5.240272601878983e-06\n",
      "epoch: 34 MSE loss: 0.1441 MSE valid loss: 0.0964\n",
      "Updating learning rate to 5.16700999718195e-06\n",
      "epoch: 35 MSE loss: 0.1442 MSE valid loss: 0.0964\n",
      "Updating learning rate to 5.096736686795811e-06\n",
      "epoch: 36 MSE loss: 0.1432 MSE valid loss: 0.0967\n",
      "Updating learning rate to 5.029254763916053e-06\n",
      "epoch: 37 MSE loss: 0.1426 MSE valid loss: 0.0970\n",
      "Updating learning rate to 4.964384192434611e-06\n",
      "epoch: 38 MSE loss: 0.1437 MSE valid loss: 0.0974\n",
      "Updating learning rate to 4.901960784313726e-06\n",
      "epoch: 39 MSE loss: 0.1422 MSE valid loss: 0.0971\n",
      "Updating learning rate to 4.841834449897069e-06\n",
      "epoch: 40 MSE loss: 0.1420 MSE valid loss: 0.0978\n",
      "Updating learning rate to 4.783867678672252e-06\n",
      "epoch: 41 MSE loss: 0.1423 MSE valid loss: 0.0979\n",
      "Updating learning rate to 4.727934215451461e-06\n",
      "epoch: 42 MSE loss: 0.1414 MSE valid loss: 0.0981\n",
      "Updating learning rate to 4.673917902941745e-06\n",
      "epoch: 43 MSE loss: 0.1413 MSE valid loss: 0.0985\n",
      "Updating learning rate to 4.621711666540848e-06\n",
      "epoch: 44 MSE loss: 0.1410 MSE valid loss: 0.0985\n",
      "Updating learning rate to 4.571216621155238e-06\n",
      "epoch: 45 MSE loss: 0.1404 MSE valid loss: 0.0989\n",
      "Updating learning rate to 4.5223412830776355e-06\n",
      "epoch: 46 MSE loss: 0.1395 MSE valid loss: 0.0990\n",
      "Updating learning rate to 4.475000872625255e-06\n",
      "epoch: 47 MSE loss: 0.1390 MSE valid loss: 0.0991\n",
      "Updating learning rate to 4.42911669543945e-06\n",
      "epoch: 48 MSE loss: 0.1404 MSE valid loss: 0.0995\n",
      "Updating learning rate to 4.3846155921711576e-06\n",
      "epoch: 49 MSE loss: 0.1396 MSE valid loss: 0.0995\n",
      "Elapsed Time: 114.84179722703993\n"
     ]
    }
   ],
   "source": [
    "c_in = 7\n",
    "context_window = 336\n",
    "target_window = 96\n",
    "patch_len = 16\n",
    "stride = 8 \n",
    "\n",
    "patchtst_model = PatchTST(c_in=c_in, context_window=context_window, target_window=target_window, patch_len=patch_len, stride=stride)\n",
    "\n",
    "# Linear_model = Linear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
    "# DLinear_model = DLinear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
    "\n",
    "# Linear_learner = Learner_2(model=Linear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
    "# DLinear_learner = Learner_2(model=DLinear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
    "patchtst_learner = Learner(model=patchtst_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "\n",
    "# Linear_train_history, Linear_valid_history = Linear_learner.train()\n",
    "# DLinear_train_history, DLinear_valid_history = DLinear_learner.train()\n",
    "# import torch.autograd.profiler as profiler\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "patchtst_train_history, patchtst_valid_history = patchtst_learner.train()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed Time:\", elapsed_time)\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchTST(\n",
      "  (revin_layer): RevIN()\n",
      "  (backbone): TSTiEncoder(\n",
      "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (encoder): TSTEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TSTEncoderLayer(\n",
      "          (self_attn): _MultiheadAttention(\n",
      "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (sdp_attn): _ScaledDotProductAttention(\n",
      "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (1): Dropout(p=0.3, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "          (norm_attn): Sequential(\n",
      "            (0): Transpose()\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Transpose()\n",
      "          )\n",
      "          (ff): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.3, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
      "          (norm_ffn): Sequential(\n",
      "            (0): Transpose()\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Transpose()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Flatten_Head(\n",
      "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "copied_model = copy.deepcopy(patchtst_model)\n",
    "print(copied_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 810094 || all params: 810097 || trainable%: 99.99962967397731\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "print_trainable_parameters(patchtst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[ 0.0133,  0.0256,  0.0615,  ..., -0.0682,  0.0224,  0.0298],\n",
      "        [ 0.0661, -0.0278, -0.0495,  ..., -0.0265,  0.0061,  0.0772],\n",
      "        [-0.0641,  0.0565,  0.0738,  ..., -0.0133,  0.0293, -0.0393],\n",
      "        ...,\n",
      "        [-0.0855,  0.0113, -0.0263,  ..., -0.0205, -0.0333,  0.0889],\n",
      "        [ 0.0771, -0.0664, -0.0387,  ...,  0.0526,  0.0190,  0.0865],\n",
      "        [-0.0391, -0.0678, -0.0355,  ..., -0.0746,  0.0732,  0.0504]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 7.5959e-02, -6.2605e-02,  4.2299e-03, -2.0599e-02,  7.5626e-02,\n",
      "         2.3209e-02,  5.5336e-02, -4.7392e-02, -5.3491e-02, -7.9857e-02,\n",
      "         7.7934e-02,  1.1591e-02, -1.6918e-02, -1.0809e-02, -8.1386e-02,\n",
      "         1.1333e-02,  7.5122e-02, -1.6398e-02,  1.1527e-05, -4.2927e-02,\n",
      "         2.1708e-02,  8.6472e-02, -2.3894e-02,  7.8156e-02,  7.0666e-02,\n",
      "        -5.9276e-02,  7.5374e-02, -7.6898e-02, -3.6440e-03, -8.4150e-02,\n",
      "        -1.2445e-02, -7.2536e-02,  3.1372e-03,  7.9626e-02,  7.7160e-02,\n",
      "        -4.0067e-02, -7.9514e-02, -5.3899e-02,  2.5128e-02, -7.7070e-03,\n",
      "         3.4118e-02, -3.0855e-02,  6.5864e-03, -4.5029e-02, -7.7932e-02,\n",
      "         5.4825e-02, -7.6324e-02,  3.9833e-02, -8.7483e-02, -3.6304e-02,\n",
      "        -3.4101e-02,  1.0003e-02, -7.7364e-02, -4.1903e-02,  4.2427e-02,\n",
      "         4.9545e-02, -7.4451e-02, -2.8823e-02,  1.9742e-02,  6.4062e-02,\n",
      "        -4.9827e-03, -1.2656e-03,  3.1298e-03, -6.4646e-02,  9.2150e-03,\n",
      "        -7.5977e-02,  2.7698e-02, -2.3129e-02, -3.7142e-02,  3.6999e-02,\n",
      "        -5.7372e-02,  4.2467e-02, -5.1366e-02, -3.5054e-02,  2.2333e-02,\n",
      "         1.8701e-02,  8.1485e-03, -3.8181e-02,  1.8244e-02, -1.9909e-03,\n",
      "        -1.1085e-02, -5.5946e-02, -3.5941e-03, -8.3659e-02,  6.8014e-02,\n",
      "         4.6195e-02,  5.8728e-02, -3.4187e-03,  3.7348e-02, -5.0846e-02,\n",
      "         3.9027e-02,  3.9795e-02,  6.0228e-02,  8.4263e-03, -1.4763e-02,\n",
      "        -7.8874e-02,  1.9602e-02, -1.8571e-02, -1.0087e-02,  7.3578e-02,\n",
      "         6.4823e-02,  8.0560e-02,  1.4207e-02, -5.1228e-02, -5.3646e-02,\n",
      "        -3.7689e-02,  4.6430e-02,  7.8274e-02,  2.2353e-03, -3.4104e-02,\n",
      "        -1.3340e-02, -7.1125e-02, -5.2352e-02, -8.2946e-02, -5.5542e-02,\n",
      "        -3.2268e-02,  1.0346e-02,  6.1979e-02,  3.2588e-02, -2.5393e-02,\n",
      "        -7.7211e-02, -2.5933e-03, -1.6685e-02, -7.2264e-02, -1.8944e-02,\n",
      "         3.2334e-02, -2.2860e-02, -5.2602e-02], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=128, out_features=128, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "module = copied_model.backbone.encoder.layers[0].self_attn.to_out[0]\n",
    "print(list(module.named_parameters()))\n",
    "prune.random_unstructured(module, name=\"weight\", amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 810094 || all params: 810097 || trainable%: 99.99962967397731\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(copied_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[ 0.0882,  0.0138,  0.0186,  ...,  0.0106, -0.0811,  0.0149],\n",
      "        [-0.0118,  0.0736, -0.0498,  ..., -0.0054, -0.0386, -0.0460],\n",
      "        [-0.0923, -0.0614,  0.0413,  ...,  0.0385, -0.0315, -0.0287],\n",
      "        ...,\n",
      "        [ 0.0679, -0.0553, -0.0360,  ..., -0.0651,  0.0623,  0.0445],\n",
      "        [ 0.0877,  0.0625,  0.0757,  ..., -0.0610,  0.0139,  0.0788],\n",
      "        [-0.0191, -0.0019, -0.0053,  ..., -0.0541,  0.0722,  0.0237]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0766, -0.0024, -0.0803, -0.0787,  0.0363,  0.0210, -0.0582, -0.0382,\n",
      "         0.0691,  0.0605, -0.0397,  0.0772,  0.0389,  0.0133, -0.0495, -0.0038,\n",
      "        -0.0685, -0.0107,  0.0045, -0.0207,  0.0339,  0.0632, -0.0269,  0.0256,\n",
      "         0.0248,  0.0089, -0.0766,  0.0541,  0.0639,  0.0361,  0.0883, -0.0362,\n",
      "        -0.0595,  0.0773, -0.0190,  0.0374, -0.0449,  0.0733,  0.0684,  0.0853,\n",
      "         0.0620,  0.0776,  0.0192, -0.0067,  0.0138, -0.0293,  0.0493,  0.0736,\n",
      "        -0.0825,  0.0231, -0.0383, -0.0768, -0.0548,  0.0047,  0.0392, -0.0725,\n",
      "        -0.0439,  0.0594,  0.0661,  0.0495, -0.0162, -0.0407, -0.0499, -0.0579,\n",
      "        -0.0219,  0.0279,  0.0174, -0.0609,  0.0189,  0.0087, -0.0419,  0.0681,\n",
      "         0.0838,  0.0520, -0.0352,  0.0844, -0.0172,  0.0225,  0.0182,  0.0935,\n",
      "         0.0426,  0.0793,  0.0579,  0.0908,  0.0446, -0.0445,  0.0020, -0.0670,\n",
      "        -0.0674, -0.0526, -0.0062, -0.0353,  0.0038, -0.0668,  0.0381, -0.0264,\n",
      "         0.0528, -0.0687,  0.0016,  0.0268,  0.0602,  0.0591, -0.0434,  0.0196,\n",
      "        -0.0388, -0.0655,  0.0443,  0.0098,  0.0684,  0.0504,  0.0131,  0.0093,\n",
      "         0.0312,  0.0619, -0.0853, -0.0804, -0.0190,  0.0241,  0.0249, -0.0703,\n",
      "        -0.0199, -0.0396,  0.0567,  0.0629, -0.0042, -0.0568, -0.0390,  0.0043],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "module = copied_model.backbone.encoder.layers[0].self_attn.W_Q\n",
    "print(list(module.named_parameters()))\n",
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({7: <torch.nn.utils.prune.PruningContainer object at 0x7f6411ea4e60>})\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.0289,  0.0043, -0.0665, -0.0493, -0.0553,  0.0771, -0.0405,  0.0465,\n",
      "         0.0870,  0.0089, -0.0160, -0.0190,  0.0193, -0.0827, -0.0595, -0.0373,\n",
      "         0.0466, -0.0348,  0.0555,  0.0624,  0.0442,  0.0622, -0.0881, -0.0529,\n",
      "        -0.0211,  0.0753, -0.0515, -0.0607,  0.0234,  0.0816,  0.0384, -0.0140,\n",
      "        -0.0231, -0.0789,  0.0104, -0.0342, -0.0547, -0.0173,  0.0677,  0.0535,\n",
      "         0.0236,  0.0285,  0.0850, -0.0240, -0.0657, -0.0260,  0.0828, -0.0301,\n",
      "        -0.0244, -0.0868, -0.0689,  0.0671, -0.0714, -0.0260,  0.0442,  0.0752,\n",
      "        -0.0690,  0.0449,  0.0082,  0.0059, -0.0684,  0.0377,  0.0341,  0.0168,\n",
      "         0.0535, -0.0558,  0.0494,  0.0151,  0.0591, -0.0810, -0.0849, -0.0045,\n",
      "        -0.0130, -0.0806,  0.0405, -0.0841, -0.0140, -0.0262, -0.0072, -0.0469,\n",
      "        -0.0108, -0.0806, -0.0273, -0.0236,  0.0837,  0.0428,  0.0221,  0.0753,\n",
      "        -0.0063,  0.0218, -0.0216,  0.0051, -0.0438,  0.0514, -0.0172,  0.0873,\n",
      "        -0.0721,  0.0486, -0.0874, -0.0356, -0.0366,  0.0382,  0.0493,  0.0442,\n",
      "         0.0525, -0.0239, -0.0639, -0.0749, -0.0709,  0.0226,  0.0291, -0.0436,\n",
      "         0.0821, -0.0285, -0.0288,  0.0397, -0.0669, -0.0839,  0.0820,  0.0196,\n",
      "         0.0125, -0.0777, -0.0435, -0.0880, -0.0321, -0.0018, -0.0653,  0.0430],\n",
      "       device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.0796,  0.0507,  0.0383,  ...,  0.0514, -0.0250, -0.0119],\n",
      "        [ 0.0713,  0.0150, -0.0107,  ...,  0.0274, -0.0510,  0.0289],\n",
      "        [-0.0111, -0.0550,  0.0224,  ..., -0.0267,  0.0684, -0.0498],\n",
      "        ...,\n",
      "        [-0.0445, -0.0526, -0.0569,  ...,  0.0582, -0.0123,  0.0680],\n",
      "        [ 0.0176, -0.0767,  0.0495,  ...,  0.0569, -0.0680,  0.0657],\n",
      "        [-0.0686, -0.0170,  0.0111,  ..., -0.0852,  0.0058, -0.0551]],\n",
      "       device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 3.096MB\n"
     ]
    }
   ],
   "source": [
    "model1 = patchtst_model\n",
    "model1.eval()\n",
    "param_size = 0\n",
    "for param in model1.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model1.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 3.221MB\n"
     ]
    }
   ],
   "source": [
    "model1 = copied_model\n",
    "model1.eval()\n",
    "param_size = 0\n",
    "for param in model1.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model1.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test loss: 0.0621\n",
      "Elapsed Time: 0.25192865496501327\n"
     ]
    }
   ],
   "source": [
    "patchtst_learner = Learner(model=patchtst_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "patchtst_learner.test()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed Time:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test loss: 0.0622\n",
      "Elapsed Time: 0.24424319388344884\n"
     ]
    }
   ],
   "source": [
    "patchtst_learner = Learner(model=copied_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "patchtst_learner.test()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed Time:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0-2): 3 x TSTEncoderLayer(\n",
      "    (self_attn): _MultiheadAttention(\n",
      "      (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (sdp_attn): _ScaledDotProductAttention(\n",
      "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (to_out): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout_attn): Dropout(p=0.3, inplace=False)\n",
      "    (norm_attn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Transpose()\n",
      "    )\n",
      "    (ff): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
      "    (norm_ffn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Transpose()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "module = copied_model.backbone.encoder.layers\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-6.9109e-02, -3.1112e-02,  8.5259e-03, -2.5748e-02,  4.5353e-02,\n",
      "        -1.0702e-02, -2.5744e-02, -1.1569e-02, -8.5171e-02,  8.1739e-02,\n",
      "        -6.7620e-02,  2.9832e-02, -8.3390e-02,  2.4027e-03,  2.5204e-02,\n",
      "         3.8952e-02, -1.8755e-02, -1.6623e-03,  7.4353e-02, -4.4131e-03,\n",
      "         7.7732e-02, -6.2896e-02, -6.1328e-02,  4.1302e-02, -8.1144e-02,\n",
      "         8.8027e-02, -5.2444e-02,  1.5008e-02, -4.6099e-02,  3.4469e-02,\n",
      "        -2.1460e-02,  1.8658e-02, -3.1223e-02, -8.7284e-02,  2.1304e-02,\n",
      "         7.8623e-02, -5.8086e-02,  7.0956e-02,  4.4877e-02,  9.1569e-04,\n",
      "        -5.0979e-02, -7.7258e-02,  8.8254e-02,  3.8582e-02, -4.1149e-02,\n",
      "        -5.6542e-02, -3.4716e-02, -5.3339e-02, -3.7562e-02, -1.6377e-02,\n",
      "        -4.6890e-02, -7.9592e-02, -8.3546e-02,  3.0144e-02, -1.1021e-02,\n",
      "        -4.2286e-02, -4.7519e-02, -5.8302e-02, -4.6120e-05, -5.1187e-02,\n",
      "         4.3727e-02,  5.5675e-02,  7.8901e-02, -5.1252e-03, -5.0947e-02,\n",
      "         2.1314e-03,  1.5752e-04,  3.7701e-02, -7.9674e-02,  5.9953e-02,\n",
      "         2.1638e-02,  2.1511e-02,  3.8598e-02, -4.9904e-02, -6.3230e-02,\n",
      "         6.5249e-02,  1.0239e-02,  2.6600e-02,  1.4651e-02,  2.6064e-02,\n",
      "        -1.4219e-03, -6.7783e-02, -5.8620e-02,  8.0187e-02,  1.0692e-02,\n",
      "        -7.7148e-02, -4.5805e-02, -4.1878e-02,  7.6450e-02, -4.0467e-02,\n",
      "        -7.1810e-02, -1.3767e-02,  6.7317e-02, -2.2445e-02,  5.4250e-02,\n",
      "         8.1510e-02, -8.0551e-02,  2.4050e-02,  2.8612e-02,  2.6614e-02,\n",
      "        -2.5523e-02,  4.7651e-04, -2.7237e-02,  7.0488e-02,  6.0867e-02,\n",
      "         3.2675e-02,  1.4916e-02, -4.9744e-02, -5.3958e-02, -3.4003e-02,\n",
      "         4.0085e-02,  1.2458e-02, -6.3153e-02, -7.1160e-02,  8.6224e-02,\n",
      "         8.2596e-02,  1.2809e-03, -2.8964e-02, -5.8422e-02, -4.9667e-02,\n",
      "        -7.8603e-02, -1.0962e-02, -4.6211e-02,  7.5598e-02,  3.0421e-02,\n",
      "        -2.2520e-02, -8.2094e-03, -5.7753e-02], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.0465, -0.0104, -0.0084,  ...,  0.0464, -0.0622, -0.0072],\n",
      "        [-0.0113, -0.0772,  0.0658,  ...,  0.0071,  0.0650,  0.0686],\n",
      "        [-0.0644, -0.0540,  0.0352,  ..., -0.0163,  0.0153,  0.0291],\n",
      "        ...,\n",
      "        [-0.0869, -0.0473, -0.0530,  ...,  0.0218,  0.0377, -0.0432],\n",
      "        [-0.0634,  0.0118,  0.0731,  ...,  0.0391, -0.0662, -0.0734],\n",
      "        [ 0.0849,  0.0460, -0.0252,  ..., -0.0783, -0.0254,  0.0717]],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0382, -0.0008,  0.0404, -0.0844,  0.0160, -0.0195,  0.0446, -0.0814,\n",
      "        -0.0102, -0.0581,  0.0214,  0.0278, -0.0727,  0.0114,  0.0008, -0.0136,\n",
      "        -0.0389, -0.0002,  0.0685, -0.0619, -0.0463, -0.0641,  0.0342, -0.0149,\n",
      "        -0.0108, -0.0549,  0.0044,  0.0384,  0.0148, -0.0486,  0.0686, -0.0394,\n",
      "         0.0828, -0.0727,  0.0384,  0.0176, -0.0121,  0.0696,  0.0883,  0.0433,\n",
      "        -0.0662,  0.0448, -0.0813, -0.0161, -0.0532, -0.0191,  0.0431, -0.0748,\n",
      "        -0.0209,  0.0028, -0.0875,  0.0298, -0.0141, -0.0679,  0.0373, -0.0374,\n",
      "         0.0048,  0.0413, -0.0245, -0.0859,  0.0795,  0.0263, -0.0592, -0.0360,\n",
      "         0.0040, -0.0177,  0.0258,  0.0272,  0.0423,  0.0342, -0.0056,  0.0809,\n",
      "         0.0683, -0.0065,  0.0782,  0.0635,  0.0022, -0.0476,  0.0568, -0.0173,\n",
      "        -0.0430,  0.0133, -0.0545, -0.0247, -0.0853, -0.0303, -0.0004, -0.0485,\n",
      "        -0.0375, -0.0156,  0.0437,  0.0328, -0.0609,  0.0808, -0.0626, -0.0829,\n",
      "        -0.0291,  0.0800,  0.0746, -0.0136, -0.0737, -0.0102,  0.0769, -0.0633,\n",
      "        -0.0520, -0.0183, -0.0021,  0.0517,  0.0649,  0.0866, -0.0151,  0.0114,\n",
      "         0.0607, -0.0844, -0.0319, -0.0136, -0.0366, -0.0769, -0.0264,  0.0856,\n",
      "         0.0677,  0.0509, -0.0785, -0.0790, -0.0518,  0.0137, -0.0198,  0.0618],\n",
      "       device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.0831,  0.0434, -0.0173,  ...,  0.0725,  0.0880, -0.0786],\n",
      "        [ 0.0878,  0.0350,  0.0167,  ...,  0.0176, -0.0195,  0.0283],\n",
      "        [-0.0323,  0.0526,  0.0879,  ..., -0.0014, -0.0783, -0.0371],\n",
      "        ...,\n",
      "        [-0.0586,  0.0269, -0.0778,  ...,  0.0826, -0.0767, -0.0671],\n",
      "        [-0.0845, -0.0015,  0.0655,  ..., -0.0365, -0.0574, -0.0691],\n",
      "        [-0.0387,  0.0712, -0.0105,  ...,  0.0446,  0.0761, -0.0323]],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "module1 = copied_model.backbone.encoder.layers[0].self_attn.W_Q\n",
    "module2 = copied_model.backbone.encoder.layers[0].self_attn.W_K\n",
    "module3 = copied_model.backbone.encoder.layers[0].self_attn.W_V\n",
    "\n",
    "print(list(module1.named_parameters()))\n",
    "prune.ln_structured(module1, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module1)\n",
    "print(list(module2.named_parameters()))\n",
    "prune.ln_structured(module2, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module2)\n",
    "print(list(module3.named_parameters()))\n",
    "prune.ln_structured(module3, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[-0.0693,  0.0690,  0.0107,  ...,  0.0121,  0.0184,  0.0880],\n",
      "        [ 0.0724, -0.0314,  0.0503,  ...,  0.0091,  0.0265, -0.0793],\n",
      "        [ 0.0279, -0.0014, -0.0286,  ..., -0.0267,  0.0575, -0.0134],\n",
      "        ...,\n",
      "        [-0.0661, -0.0755,  0.0358,  ..., -0.0320,  0.0535,  0.0575],\n",
      "        [ 0.0443,  0.0768,  0.0634,  ...,  0.0313,  0.0048,  0.0835],\n",
      "        [ 0.0506,  0.0279, -0.0503,  ..., -0.0868, -0.0444,  0.0633]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.0419,  0.0088,  0.0295, -0.0210,  0.0625, -0.0459, -0.0288, -0.0109,\n",
      "         0.0103, -0.0036,  0.0079,  0.0342,  0.0254, -0.0357, -0.0611, -0.0179,\n",
      "         0.0211,  0.0359,  0.0382,  0.0805,  0.0159,  0.0246, -0.0178, -0.0312,\n",
      "         0.0752, -0.0743,  0.0087,  0.0429, -0.0019, -0.0336,  0.0314, -0.0190,\n",
      "        -0.0226, -0.0280,  0.0800,  0.0558, -0.0882,  0.0592,  0.0074, -0.0310,\n",
      "        -0.0310, -0.0783, -0.0486,  0.0361,  0.0508,  0.0495,  0.0199, -0.0098,\n",
      "        -0.0198, -0.0757,  0.0427, -0.0255,  0.0528,  0.0115, -0.0481, -0.0372,\n",
      "        -0.0496, -0.0505, -0.0163,  0.0875, -0.0009, -0.0354, -0.0236, -0.0691,\n",
      "        -0.0458, -0.0005, -0.0074, -0.0824, -0.0347, -0.0585, -0.0663,  0.0219,\n",
      "         0.0051,  0.0445, -0.0080, -0.0809, -0.0424,  0.0536,  0.0221, -0.0540,\n",
      "         0.0544, -0.0563, -0.0130,  0.0475,  0.0263, -0.0241,  0.0332,  0.0527,\n",
      "         0.0601, -0.0769,  0.0200, -0.0402,  0.0830,  0.0063, -0.0816,  0.0465,\n",
      "        -0.0747, -0.0120, -0.0372, -0.0545, -0.0758,  0.0678,  0.0316,  0.0859,\n",
      "         0.0343, -0.0384, -0.0660,  0.0525, -0.0234, -0.0827,  0.0025,  0.0321,\n",
      "        -0.0582, -0.0503,  0.0768, -0.0218, -0.0377, -0.0646, -0.0492,  0.0127,\n",
      "        -0.0071,  0.0485, -0.0531,  0.0379,  0.0663, -0.0771, -0.0727,  0.0445],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n",
      "[('weight', Parameter containing:\n",
      "tensor([[ 0.0570,  0.0120, -0.0366,  ...,  0.0010, -0.0516,  0.0292],\n",
      "        [-0.0127, -0.0720, -0.0024,  ...,  0.0366, -0.0095, -0.0553],\n",
      "        [-0.0341, -0.0116,  0.0238,  ...,  0.0528,  0.0828,  0.0147],\n",
      "        ...,\n",
      "        [ 0.0312,  0.0136, -0.0201,  ..., -0.0114, -0.0278, -0.0514],\n",
      "        [-0.0609,  0.0434, -0.0766,  ..., -0.0123,  0.0068,  0.0550],\n",
      "        [ 0.0251, -0.0618,  0.0236,  ...,  0.0720,  0.0064, -0.0119]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0494,  0.0480,  0.0635,  0.0812,  0.0250,  0.0529,  0.0861, -0.0448,\n",
      "         0.0701, -0.0452, -0.0111, -0.0767,  0.0609,  0.0353, -0.0628,  0.0683,\n",
      "        -0.0577,  0.0201, -0.0284, -0.0002, -0.0478, -0.0681, -0.0718,  0.0611,\n",
      "        -0.0786, -0.0029, -0.0469,  0.0578,  0.0692,  0.0233, -0.0754,  0.0822,\n",
      "         0.0264,  0.0470, -0.0471, -0.0699,  0.0730, -0.0361,  0.0058,  0.0870,\n",
      "        -0.0371,  0.0169,  0.0414,  0.0620, -0.0523,  0.0842, -0.0459,  0.0623,\n",
      "        -0.0243, -0.0392, -0.0873,  0.0557,  0.0167, -0.0152, -0.0670,  0.0448,\n",
      "         0.0766,  0.0285, -0.0350, -0.0848, -0.0580, -0.0095, -0.0676, -0.0525,\n",
      "         0.0026,  0.0383, -0.0665,  0.0516, -0.0807,  0.0010,  0.0697,  0.0821,\n",
      "        -0.0386, -0.0543,  0.0034, -0.0550,  0.0197,  0.0603,  0.0776,  0.0492,\n",
      "         0.0539,  0.0144,  0.0819, -0.0130,  0.0234,  0.0761, -0.0591, -0.0872,\n",
      "         0.0045, -0.0112,  0.0378,  0.0817, -0.0248,  0.0498, -0.0504, -0.0879,\n",
      "        -0.0269, -0.0213,  0.0198,  0.0785, -0.0381,  0.0526, -0.0589, -0.0631,\n",
      "         0.0469, -0.0471,  0.0830, -0.0093,  0.0535,  0.0202,  0.0251, -0.0425,\n",
      "        -0.0880,  0.0107,  0.0546,  0.0644,  0.0585,  0.0494,  0.0663, -0.0569,\n",
      "        -0.0718,  0.0472,  0.0453, -0.0721,  0.0122,  0.0035,  0.0024,  0.0017],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n",
      "[('weight', Parameter containing:\n",
      "tensor([[-0.0511, -0.0625, -0.0148,  ..., -0.0394, -0.0317, -0.0778],\n",
      "        [-0.0871, -0.0595,  0.0471,  ...,  0.0519, -0.0664, -0.0411],\n",
      "        [-0.0712, -0.0831,  0.0159,  ...,  0.0124, -0.0149,  0.0557],\n",
      "        ...,\n",
      "        [-0.0813,  0.0692,  0.0435,  ...,  0.0367, -0.0333,  0.0041],\n",
      "        [-0.0883, -0.0121,  0.0687,  ..., -0.0588, -0.0863, -0.0342],\n",
      "        [ 0.0733, -0.0081,  0.0230,  ..., -0.0371, -0.0440,  0.0220]],\n",
      "       device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0438,  0.0625, -0.0444, -0.0686,  0.0665, -0.0400,  0.0641, -0.0680,\n",
      "        -0.0728, -0.0747,  0.0181,  0.0197, -0.0251,  0.0407, -0.0854, -0.0203,\n",
      "         0.0748,  0.0108, -0.0841, -0.0027, -0.0469, -0.0621,  0.0061, -0.0030,\n",
      "        -0.0492, -0.0269,  0.0512, -0.0849,  0.0766, -0.0853, -0.0055,  0.0646,\n",
      "         0.0550, -0.0191, -0.0217,  0.0222,  0.0020, -0.0864, -0.0107, -0.0370,\n",
      "        -0.0465,  0.0521, -0.0615,  0.0248, -0.0273,  0.0197, -0.0738,  0.0744,\n",
      "         0.0606, -0.0446, -0.0098,  0.0687,  0.0694, -0.0611,  0.0694, -0.0345,\n",
      "         0.0588, -0.0727,  0.0759, -0.0260, -0.0350, -0.0297, -0.0672,  0.0335,\n",
      "        -0.0319, -0.0714, -0.0529, -0.0074, -0.0127, -0.0814,  0.0127, -0.0040,\n",
      "         0.0403,  0.0862, -0.0208,  0.0856, -0.0427,  0.0832,  0.0197,  0.0717,\n",
      "         0.0864,  0.0446,  0.0108,  0.0453,  0.0289, -0.0292, -0.0076,  0.0222,\n",
      "         0.0872, -0.0429,  0.0558,  0.0379, -0.0562,  0.0649, -0.0196,  0.0307,\n",
      "         0.0563, -0.0872, -0.0777,  0.0191, -0.0800, -0.0870, -0.0787,  0.0792,\n",
      "        -0.0703, -0.0565, -0.0659, -0.0278, -0.0187, -0.0789,  0.0033, -0.0059,\n",
      "         0.0343, -0.0555,  0.0122, -0.0693,  0.0856,  0.0354,  0.0038,  0.0209,\n",
      "         0.0872, -0.0135, -0.0077,  0.0867, -0.0165,  0.0782, -0.0651, -0.0712],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "module1 = copied_model.backbone.encoder.layers[1].self_attn.W_Q\n",
    "module2 = copied_model.backbone.encoder.layers[1].self_attn.W_K\n",
    "module3 = copied_model.backbone.encoder.layers[1].self_attn.W_V\n",
    "\n",
    "print(list(module1.named_parameters()))\n",
    "prune.ln_structured(module1, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module1)\n",
    "print(list(module2.named_parameters()))\n",
    "prune.ln_structured(module2, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module2)\n",
    "print(list(module3.named_parameters()))\n",
    "prune.ln_structured(module3, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0100, -0.0062, -0.0228,  0.0458,  0.0159, -0.0326, -0.0411,  0.0148,\n",
      "        -0.0727,  0.0195,  0.0237,  0.0741,  0.0682, -0.0826,  0.0476,  0.0495,\n",
      "         0.0640,  0.0837,  0.0288, -0.0548,  0.0378, -0.0496,  0.0713,  0.0236,\n",
      "         0.0293,  0.0487,  0.0309,  0.0526, -0.0288, -0.0814, -0.0136, -0.0370,\n",
      "         0.0121, -0.0394, -0.0060,  0.0134, -0.0261, -0.0649,  0.0729,  0.0391,\n",
      "        -0.0100,  0.0814,  0.0417,  0.0076, -0.0284,  0.0013,  0.0479, -0.0150,\n",
      "        -0.0287,  0.0601, -0.0345, -0.0614, -0.0151,  0.0390,  0.0125,  0.0814,\n",
      "        -0.0449,  0.0220, -0.0750,  0.0145,  0.0803,  0.0037,  0.0108,  0.0455,\n",
      "         0.0509, -0.0424,  0.0296, -0.0551,  0.0394, -0.0244, -0.0713, -0.0058,\n",
      "        -0.0488,  0.0097, -0.0884,  0.0597, -0.0799,  0.0667,  0.0443, -0.0204,\n",
      "         0.0790,  0.0360,  0.0821,  0.0088, -0.0471, -0.0418, -0.0021,  0.0753,\n",
      "        -0.0462, -0.0241, -0.0779, -0.0580,  0.0452, -0.0193, -0.0722, -0.0690,\n",
      "         0.0488,  0.0330,  0.0780, -0.0598, -0.0433,  0.0801, -0.0098, -0.0144,\n",
      "         0.0729, -0.0139, -0.0181, -0.0347,  0.0765, -0.0820,  0.0150,  0.0581,\n",
      "         0.0004, -0.0631, -0.0467, -0.0352,  0.0808,  0.0044, -0.0577,  0.0007,\n",
      "        -0.0620,  0.0636, -0.0112, -0.0207,  0.0704, -0.0595,  0.0636, -0.0184],\n",
      "       device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0732,  0.0812, -0.0547,  ..., -0.0529,  0.0830,  0.0561],\n",
      "        [ 0.0624, -0.0597, -0.0286,  ...,  0.0004, -0.0529, -0.0370],\n",
      "        [-0.0012,  0.0210,  0.0223,  ...,  0.0509, -0.0414,  0.0569],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0474,  0.0620,  ..., -0.0781,  0.0802,  0.0033],\n",
      "        [-0.0808, -0.0630, -0.0634,  ..., -0.0749, -0.0254,  0.0408],\n",
      "        [-0.0004, -0.0225, -0.0481,  ...,  0.0304,  0.0208,  0.0353]],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0879, -0.0139,  0.0432,  0.0725,  0.0108, -0.0628,  0.0006, -0.0756,\n",
      "        -0.0548,  0.0302,  0.0677,  0.0183, -0.0495, -0.0537,  0.0130,  0.0528,\n",
      "         0.0003, -0.0537, -0.0084, -0.0252, -0.0434, -0.0515, -0.0344, -0.0773,\n",
      "        -0.0242,  0.0044, -0.0528, -0.0741, -0.0547,  0.0509,  0.0215, -0.0507,\n",
      "         0.0578,  0.0138,  0.0523,  0.0834, -0.0548,  0.0207,  0.0058, -0.0007,\n",
      "         0.0404, -0.0407, -0.0542,  0.0171,  0.0425,  0.0549,  0.0398,  0.0647,\n",
      "         0.0117,  0.0220, -0.0315, -0.0353,  0.0610,  0.0146,  0.0762,  0.0441,\n",
      "         0.0760,  0.0709,  0.0716,  0.0430, -0.0798, -0.0791, -0.0662, -0.0312,\n",
      "         0.0428,  0.0497, -0.0021,  0.0282, -0.0729,  0.0831,  0.0267, -0.0364,\n",
      "         0.0394,  0.0657, -0.0414,  0.0216,  0.0881,  0.0595,  0.0056, -0.0473,\n",
      "         0.0613, -0.0770,  0.0431, -0.0768,  0.0508, -0.0690,  0.0839, -0.0091,\n",
      "        -0.0109, -0.0760,  0.0236,  0.0820, -0.0292, -0.0783, -0.0027, -0.0767,\n",
      "        -0.0834, -0.0160, -0.0149, -0.0367,  0.0832, -0.0447, -0.0134,  0.0820,\n",
      "         0.0539,  0.0810, -0.0768, -0.0348,  0.0656, -0.0227,  0.0838,  0.0320,\n",
      "        -0.0375,  0.0021, -0.0283, -0.0061,  0.0776, -0.0278,  0.0550,  0.0287,\n",
      "         0.0467, -0.0288, -0.0588,  0.0700,  0.0258, -0.0276,  0.0856, -0.0762],\n",
      "       device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0872, -0.0871, -0.0609,  ..., -0.0760,  0.0376,  0.0623],\n",
      "        [ 0.0701,  0.0100,  0.0426,  ..., -0.0061, -0.0623, -0.0530],\n",
      "        [ 0.0408, -0.0646, -0.0337,  ..., -0.0066,  0.0368,  0.0644],\n",
      "        ...,\n",
      "        [ 0.0157, -0.0543,  0.0502,  ..., -0.0762, -0.0125,  0.0793],\n",
      "        [-0.0087, -0.0065, -0.0482,  ...,  0.0578, -0.0589, -0.0470],\n",
      "        [ 0.0704, -0.0589,  0.0057,  ..., -0.0619,  0.0111,  0.0114]],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n",
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0395,  0.0728,  0.0507,  0.0140,  0.0790, -0.0420,  0.0690,  0.0059,\n",
      "         0.0573,  0.0722, -0.0352,  0.0122, -0.0737,  0.0234, -0.0730,  0.0173,\n",
      "        -0.0167,  0.0883, -0.0747,  0.0076, -0.0562, -0.0515, -0.0622,  0.0706,\n",
      "        -0.0628, -0.0092, -0.0725, -0.0061,  0.0086,  0.0024,  0.0401, -0.0717,\n",
      "         0.0518,  0.0153, -0.0441,  0.0610, -0.0836, -0.0206,  0.0450,  0.0634,\n",
      "         0.0283, -0.0366,  0.0107,  0.0148,  0.0324, -0.0662,  0.0223,  0.0386,\n",
      "        -0.0311,  0.0736, -0.0564,  0.0399,  0.0115, -0.0172,  0.0274, -0.0176,\n",
      "         0.0433,  0.0760,  0.0253,  0.0597, -0.0411,  0.0101, -0.0074, -0.0249,\n",
      "         0.0490, -0.0165,  0.0381,  0.0330,  0.0020,  0.0487,  0.0382,  0.0862,\n",
      "        -0.0590, -0.0701,  0.0766,  0.0609, -0.0218,  0.0252,  0.0402, -0.0022,\n",
      "        -0.0080,  0.0755,  0.0316, -0.0603,  0.0807,  0.0045,  0.0568, -0.0407,\n",
      "         0.0834,  0.0467, -0.0321, -0.0104, -0.0553,  0.0782, -0.0227,  0.0527,\n",
      "        -0.0285, -0.0481, -0.0010, -0.0047, -0.0101, -0.0148,  0.0158, -0.0013,\n",
      "        -0.0389,  0.0058, -0.0140,  0.0014,  0.0772,  0.0200, -0.0509,  0.0210,\n",
      "         0.0862,  0.0459,  0.0712,  0.0296,  0.0303,  0.0223, -0.0080, -0.0841,\n",
      "        -0.0493, -0.0830, -0.0469, -0.0366,  0.0593, -0.0755, -0.0625, -0.0204],\n",
      "       device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.0284, -0.0630, -0.0570,  ..., -0.0761, -0.0756,  0.0459],\n",
      "        [-0.0797,  0.0121,  0.0159,  ...,  0.0757,  0.0201, -0.0465],\n",
      "        [ 0.0514,  0.0679,  0.0005,  ..., -0.0752,  0.0460,  0.0364],\n",
      "        ...,\n",
      "        [-0.0826,  0.0460,  0.0052,  ...,  0.0350, -0.0647, -0.0513],\n",
      "        [-0.0192,  0.0690, -0.0139,  ...,  0.0430,  0.0097, -0.0861],\n",
      "        [ 0.0440,  0.0759,  0.0832,  ..., -0.0728,  0.0636,  0.0219]],\n",
      "       device='cuda:0', requires_grad=True))]\n",
      "trainable params: 16512 || all params: 16512 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "module1 = copied_model.backbone.encoder.layers[2].self_attn.W_Q\n",
    "module2 = copied_model.backbone.encoder.layers[2].self_attn.W_K\n",
    "module3 = copied_model.backbone.encoder.layers[2].self_attn.W_V\n",
    "\n",
    "print(list(module1.named_parameters()))\n",
    "module1 = prune.ln_structured(module1, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module1)\n",
    "print(list(module2.named_parameters()))\n",
    "module2 = prune.ln_structured(module2, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module2)\n",
    "print(list(module3.named_parameters()))\n",
    "module3 = prune.ln_structured(module3, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "print_trainable_parameters(module3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 3.721MB\n"
     ]
    }
   ],
   "source": [
    "model1 = copied_model\n",
    "model1.eval()\n",
    "param_size = 0\n",
    "for param in model1.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model1.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1962 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1954 MSE valid loss: 0.1135\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1965 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1963 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1957 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Iteration 2/5\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1957 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1951 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1954 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1960 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1958 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Iteration 3/5\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1955 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1952 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1951 MSE valid loss: 0.1134\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1952 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1949 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Iteration 4/5\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1969 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1956 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1968 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1945 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1950 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Iteration 5/5\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1954 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1961 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1942 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1950 MSE valid loss: 0.1133\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.1950 MSE valid loss: 0.1132\n",
      "Best score! Weights of the model are updated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define pruning parameters\n",
    "pruning_iterations = 5  # Number of pruning iterations\n",
    "pruning_ratio_per_iteration = 0.2  # Pruning ratio for each iteration\n",
    "epochs_per_iteration = 5  # Number of epochs to retrain the model after pruning\n",
    "\n",
    "# Instantiate your model\n",
    "model = copied_model\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "# Define a function for pruning and retraining\n",
    "def iterative_pruning(model, pruning_iterations, pruning_ratio_per_iteration, epochs_per_iteration, criterion, optimizer):\n",
    "    for i in range(pruning_iterations):\n",
    "        print(f\"Iteration {i+1}/{pruning_iterations}\")\n",
    "\n",
    "        # Prune the model\n",
    "        module1 = copied_model.backbone.encoder.layers[2].self_attn.W_Q\n",
    "        prune.ln_structured(module1, name=\"weight\", amount=pruning_ratio_per_iteration, n=2, dim=0)\n",
    "\n",
    "        # Retrain the model\n",
    "        for epoch in range(epochs_per_iteration):\n",
    "            learner = Learner(model=model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "            learner.train()\n",
    "            # Your training loop here\n",
    "\n",
    "        # Evaluate the pruned model\n",
    "        model.eval()\n",
    "        # Your evaluation code here\n",
    "\n",
    "# Apply iterative pruning\n",
    "iterative_pruning(model, pruning_iterations, pruning_ratio_per_iteration, epochs_per_iteration, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 6.151MB\n"
     ]
    }
   ],
   "source": [
    "pruned_model = model\n",
    "pruned_model.eval()\n",
    "param_size = 0\n",
    "for param in pruned_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in pruned_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
