{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch import Tensor\n",
    "from typing import Callable, Optional\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
      "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
      "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
      "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
      "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n"
     ]
    }
   ],
   "source": [
    "df_ETTh1 = pd.read_csv(\"/scratch/ab10445/hpml/PatchTST/dataset/ETT-small/ETTh1.csv\")\n",
    "print(df_ETTh1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare dataset - split into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset=\"ETTh1\", mode=\"train\", scale=True, seq_len=336, pred_len=96):\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(\"/scratch/ab10445/hpml/PatchTST/dataset/ETT-small/ETTh1.csv\".format(dataset))\n",
    "        x_y = df.iloc[:,1:]\n",
    "        time_stamp = df.iloc[:,0]\n",
    "\n",
    "        assert mode in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[mode]\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        if scale:\n",
    "            train_x_y = x_y.iloc[border1s[0]: border2s[0]]\n",
    "            self.ss = StandardScaler()\n",
    "            self.ss.fit(train_x_y.to_numpy(dtype=np.float32))\n",
    "            x_y = self.ss.transform(x_y.to_numpy(dtype=np.float32))\n",
    "        else:\n",
    "            x_y = x_y.to_numpy(dtype=np.float32)\n",
    "        \n",
    "        time_stamp = time_stamp.to_numpy()     \n",
    "        \n",
    "        self.data_x = x_y[border1: border2, :]\n",
    "        self.data_y = x_y[border1: border2, -1]\n",
    "\n",
    "        self.data_stamp = time_stamp[border1: border2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return seq_x, seq_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.ss.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revin.py - normalizes/denomalizes data\n",
    "class nonq_RevIN(torch.nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        # self.quant = torch.ao.quantization.QuantStub()\n",
    "        # self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        # x = torch.to(x, torch.float32)\n",
    "        # x.quant()\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        # x = torch.to(x, torch.int8) #change to 32 while training initial model\n",
    "        # x.dequant()\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        # initialize RevIN params: (C,)\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            # x.to(torch.float32)\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "            # x.to(torch.uint8)\n",
    "            # self.mean.to(torch.uint8)\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            # print(f'x.mT.shape: {x.mT.shape} | self.affine_weight: {self.affine_weight.shape}')\n",
    "            x = x * self.affine_weight \n",
    "            x += self.affine_bias\n",
    "            # print(f'x.shape: {x.shape} | self.affine_weight: {self.affine_bias.shape}')\n",
    "            # x = x + self.affine_bias\n",
    "        return x.mT\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revin.py - normalizes/denomalizes data\n",
    "class RevIN(torch.nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        # x = torch.to(x, torch.float32)\n",
    "        # self.quant(x)\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        # x = torch.to(x, torch.int8) #change to 32 while training initial model\n",
    "        # self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        # initialize RevIN params: (C,)\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            # x.to(torch.float32)\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "            # x.to(torch.uint8)\n",
    "            # self.mean.to(torch.uint8)\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            # print(f'x.mT.shape: {x.mT.shape} | self.affine_weight: {self.affine_weight.shape}')\n",
    "            x = x * self.affine_weight \n",
    "            x += self.affine_bias\n",
    "            # print(f'x.shape: {x.shape} | self.affine_weight: {self.affine_bias.shape}')\n",
    "            # x = x + self.affine_bias\n",
    "        return x.mT\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False): \n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
    "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ScaledDotProductAttention(torch.nn.Module):\n",
    "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
    "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
    "    by Lee et al, 2021)\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
    "        super().__init__()\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.res_attention = res_attention\n",
    "        head_dim = d_model // n_heads\n",
    "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
    "        self.lsa = lsa\n",
    "\n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "        Output shape:\n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev\n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _MultiheadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
    "        \"\"\"Multi Head Attention Layer\n",
    "        Input shape:\n",
    "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
    "            K, V:    [batch_size (bs) x q_len x d_model]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
    "\n",
    "        # Poject output\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
    "\n",
    "\n",
    "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,\n",
    "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSTEncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=128, store_attn=False,\n",
    "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
    "                                torch.nn.GELU(),\n",
    "                                nn.Dropout(dropout),\n",
    "                                nn.Linear(d_ff, d_model, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "\n",
    "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn:\n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "\n",
    "class TSTEncoder(torch.nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, \n",
    "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
    "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
    "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                                      activation=activation, res_attention=res_attention,\n",
    "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "        else:\n",
    "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "\n",
    "\n",
    "\n",
    "class TSTiEncoder(torch.nn.Module):  #i means channel-independent\n",
    "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
    "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
    "                 d_ff=128, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
    "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True, verbose=False, **kwargs):\n",
    "                 #act=\"gelu\" \n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_num = patch_num\n",
    "        self.patch_len = patch_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = patch_num\n",
    "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "        self.seq_len = q_len\n",
    "\n",
    "        # Positional encoding\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
    "\n",
    "        \n",
    "    def forward(self, x) -> Tensor:                                              # x: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        n_vars = x.shape[1]\n",
    "        # Input encoding\n",
    "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
    "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
    "\n",
    "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
    "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
    "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
    "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
    "        \n",
    "        return z         \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten_Head(torch.nn.Module):\n",
    "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.individual = individual\n",
    "        self.n_vars = n_vars\n",
    "        \n",
    "        if self.individual:\n",
    "            self.linears = nn.ModuleList()\n",
    "            self.dropouts = nn.ModuleList()\n",
    "            self.flattens = nn.ModuleList()\n",
    "            for i in range(self.n_vars):\n",
    "                self.flattens.append(nn.Flatten(start_dim=-2)) #flattens last 2\n",
    "                self.linears.append(nn.Linear(nf, target_window))\n",
    "                self.dropouts.append(nn.Dropout(head_dropout))\n",
    "        else:\n",
    "            self.flatten = nn.Flatten(start_dim=-2)\n",
    "            self.linear = nn.Linear(nf, target_window)\n",
    "            self.dropout = nn.Dropout(head_dropout)\n",
    "            \n",
    "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
    "        if self.individual:\n",
    "            x_out = []\n",
    "            for i in range(self.n_vars):\n",
    "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
    "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
    "                z = self.dropouts[i](z)\n",
    "                x_out.append(z)\n",
    "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
    "        else:\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "#Implementation of PatchTST\n",
    "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n",
    "    x = .5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
    "        pv(f'{i:4.0f}  {x:5.3f}  {cpe.mean():+6.3f}', verbose)\n",
    "        if abs(cpe.mean()) <= eps: break\n",
    "        elif cpe.mean() > eps: x += .001\n",
    "        else: x -= .001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchTST(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window, patch_len, stride, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers=3, d_model=128, n_heads=4, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 d_ff:int=128, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0.3, act:str=\"gelu\", key_padding_mask:bool='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0.3, head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
    "                 verbose:bool=False, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "        \n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((context_window - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "        \n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = d_model * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        if self.revin: \n",
    "            # z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            # z = z.permute(0,2,1)\n",
    "            \n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        # print(f'z.shape: {z.shape}')\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x target_window] \n",
    "        \n",
    "        # denorm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            # z = z.permute(0,2,1)\n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear model\n",
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window):\n",
    "        super().__init__()\n",
    "        self.c_in = c_in\n",
    "        self.context_winsoq = context_window\n",
    "        self.target_window = target_window\n",
    "\n",
    "        self.flatten = torch.nn.Flatten(start_dim=-2)\n",
    "\n",
    "        self.linear = torch.nn.Linear(c_in * context_window, target_window)\n",
    "    \n",
    "    def forward(self, x):                   # x: [bs x seq_len × nvars]\n",
    "        x = self.flatten(x)                 # x: [bs x seq_len * nvars]\n",
    "        x = self.linear(x)                  # x: [bs x target_window]\n",
    "        return x\n",
    "    \n",
    "\n",
    "class moving_avg(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = torch.nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "class DLinear(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window):\n",
    "        super().__init__()\n",
    "        # Decompsition Kernel Size\n",
    "        kernel_size = 25\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.flatten_Seasonal = torch.nn.Flatten(start_dim=-2)\n",
    "        self.flatten_Trend = torch.nn.Flatten(start_dim=-2)\n",
    "        \n",
    "        self.Linear_Seasonal = torch.nn.Linear(c_in * context_window, target_window)\n",
    "        self.Linear_Trend = torch.nn.Linear(c_in * context_window, target_window)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init = self.flatten_Seasonal(x)\n",
    "        trend_init = self.flatten_Trend(x)\n",
    "\n",
    "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=5, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
    "        self.model = model.to(\"cuda\")\n",
    "        self.batch_size = batch_size\n",
    "        train_dataset = dataset(mode=\"train\")\n",
    "        valid_dataset = dataset(mode=\"val\")\n",
    "        test_dataset = dataset(mode=\"test\")\n",
    "        self.train_datalen = len(train_dataset)\n",
    "        self.valid_datalen = len(valid_dataset)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.lr=lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.epochs = epochs\n",
    "        self.target_window=target_window\n",
    "        self.best_weight = self.model.state_dict()\n",
    "        self.d_model=d_model\n",
    "        self.adjust_lr = adjust_lr\n",
    "        self.adjust_factor = adjust_factor\n",
    "    \n",
    "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
    "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
    "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
    "        else:\n",
    "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr_adjust\n",
    "        if printout: \n",
    "            print('Updating learning rate to {}'.format(lr_adjust))\n",
    "        return \n",
    "\n",
    "    def train(self):\n",
    "        best_valid_loss = np.inf\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "        train_steps = 1\n",
    "        if self.adjust_lr:\n",
    "            self.adjust_learning_rate(train_steps)\n",
    "        for epoch in range(self.epochs):\n",
    "            #train\n",
    "            self.model.train()\n",
    "            iter_count = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for train_x, train_y in self.train_dataloader:\n",
    "                train_x = train_x.to(\"cuda\")\n",
    "                train_y = train_y.to(\"cuda\")\n",
    "                # print(f'train_x.shape: {train_x.shape}')\n",
    "                pred_y = self.model(train_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "                train_steps += 1\n",
    "            if self.adjust_lr:\n",
    "                self.adjust_learning_rate(train_steps)\n",
    "\n",
    "            #valid\n",
    "            self.model.eval()\n",
    "            valid_iter_count = 0\n",
    "            valid_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for valid_x, valid_y in self.valid_dataloader:\n",
    "                    valid_x = valid_x.to(\"cuda\")\n",
    "                    valid_y = valid_y.to(\"cuda\")\n",
    "                    pred_y = self.model(valid_x)\n",
    "                    pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                    loss = self.loss(pred_y, valid_y)\n",
    "                    valid_total_loss += loss.item()\n",
    "                    valid_iter_count += 1\n",
    "            \n",
    "            total_loss /= iter_count\n",
    "            valid_total_loss /= valid_iter_count\n",
    "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
    "            if best_valid_loss >= valid_total_loss:\n",
    "                self.best_weight = self.model.state_dict()\n",
    "                best_valid_loss = valid_total_loss\n",
    "                print(\"Best score! Weights of the model are updated!\")\n",
    "            train_history.append(total_loss)\n",
    "            valid_history.append(valid_total_loss)\n",
    "        return train_history, valid_history\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cuda\")\n",
    "                test_y = test_y.to(\"cuda\")\n",
    "                pred_y = self.model(test_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "\n",
    "    def test_cpu(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cpu\")\n",
    "                test_y = test_y.to(\"cpu\")\n",
    "                pred_y = self.model(test_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner_2:\n",
    "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=5, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
    "        self.model = model.to(\"cuda\")\n",
    "        self.batch_size = batch_size\n",
    "        train_dataset = dataset(mode=\"train\")\n",
    "        valid_dataset = dataset(mode=\"val\")\n",
    "        test_dataset = dataset(mode=\"test\")\n",
    "        self.train_datalen = len(train_dataset)\n",
    "        self.valid_datalen = len(valid_dataset)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.lr=lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.epochs = epochs\n",
    "        self.target_window=target_window\n",
    "        self.best_weight = self.model.state_dict()\n",
    "        self.d_model=d_model\n",
    "        self.adjust_lr = adjust_lr\n",
    "        self.adjust_factor = adjust_factor\n",
    "    \n",
    "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
    "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
    "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
    "        else:\n",
    "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr_adjust\n",
    "        if printout: \n",
    "            print('Updating learning rate to {}'.format(lr_adjust))\n",
    "        return \n",
    "\n",
    "    def train(self):\n",
    "        best_valid_loss = np.inf\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "        train_steps = 1\n",
    "        if self.adjust_lr:\n",
    "            self.adjust_learning_rate(train_steps)\n",
    "        for epoch in range(self.epochs):\n",
    "            #train\n",
    "            self.model.train()\n",
    "            iter_count = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for train_x, train_y in self.train_dataloader:\n",
    "                train_x = train_x.to(\"cuda\")\n",
    "                train_y = train_y.to(\"cuda\")\n",
    "                # print(f'train_x.shape: {train_x.shape}')\n",
    "                pred_y = self.model(train_x)\n",
    "                # pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "                train_steps += 1\n",
    "            if self.adjust_lr:\n",
    "                self.adjust_learning_rate(train_steps)\n",
    "\n",
    "            #valid\n",
    "            self.model.eval()\n",
    "            valid_iter_count = 0\n",
    "            valid_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for valid_x, valid_y in self.valid_dataloader:\n",
    "                    valid_x = valid_x.to(\"cuda\")\n",
    "                    valid_y = valid_y.to(\"cuda\")\n",
    "                    pred_y = self.model(valid_x)\n",
    "                    # pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                    loss = self.loss(pred_y, valid_y)\n",
    "                    valid_total_loss += loss.item()\n",
    "                    valid_iter_count += 1\n",
    "            \n",
    "            total_loss /= iter_count\n",
    "            valid_total_loss /= valid_iter_count\n",
    "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
    "            if best_valid_loss >= valid_total_loss:\n",
    "                self.best_weight = self.model.state_dict()\n",
    "                best_valid_loss = valid_total_loss\n",
    "                print(\"Best score! Weights of the model are updated!\")\n",
    "            train_history.append(total_loss)\n",
    "            valid_history.append(valid_total_loss)\n",
    "        return train_history, valid_history\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cuda\")\n",
    "                test_y = test_y.to(\"cuda\")\n",
    "                pred_y = self.model(test_x)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 4.811252243246882e-08\n",
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.2327 MSE valid loss: 0.1330\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 6.302740438653415e-06\n",
      "epoch: 1 MSE loss: 0.2254 MSE valid loss: 0.1240\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 9.430054396763887e-06\n",
      "epoch: 2 MSE loss: 0.2077 MSE valid loss: 0.1143\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.2557368354874362e-05\n",
      "epoch: 3 MSE loss: 0.1932 MSE valid loss: 0.1079\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.3846219390542782e-05\n",
      "epoch: 4 MSE loss: 0.1838 MSE valid loss: 0.1038\n",
      "Best score! Weights of the model are updated!\n",
      "Elapsed Time: 14.016281106043607\n"
     ]
    }
   ],
   "source": [
    "c_in = 7\n",
    "context_window = 336\n",
    "target_window = 96\n",
    "patch_len = 16\n",
    "stride = 8 \n",
    "\n",
    "patchtst_model = PatchTST(c_in=c_in, context_window=context_window, target_window=target_window, patch_len=patch_len, stride=stride)\n",
    "\n",
    "# Linear_model = Linear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
    "# DLinear_model = DLinear(c_in=c_in, context_window=context_window, target_window=target_window)\n",
    "\n",
    "# Linear_learner = Learner_2(model=Linear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
    "# DLinear_learner = Learner_2(model=DLinear_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.01)\n",
    "patchtst_learner = Learner(model=patchtst_model, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "\n",
    "# Linear_train_history, Linear_valid_history = Linear_learner.train()\n",
    "# DLinear_train_history, DLinear_valid_history = DLinear_learner.train()\n",
    "# import torch.autograd.profiler as profiler\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "patchtst_train_history, patchtst_valid_history = patchtst_learner.train()\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed Time:\", elapsed_time)\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "# print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# # ax.plot(np.arange(1, Linear_learner.epochs+1), Linear_valid_history, label=\"Linear\")\n",
    "# # ax.plot(np.arange(1, DLinear_learner.epochs+1), DLinear_valid_history, label=\"DLinear\")\n",
    "# ax.plot(np.arange(1, patchtst_learner.epochs+1), patchtst_valid_history, label=\"PatchTST\")\n",
    "# ax.set_xlabel(\"epochs\")\n",
    "# ax.set_ylabel(\"MSE Error\")\n",
    "# ax.set_ylim(0, 1.5)\n",
    "# ax.legend()\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantized_PatchTST(torch.nn.Module):\n",
    "    def __init__(self, c_in, context_window, target_window, patch_len, stride, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers=3, d_model=128, n_heads=4, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 d_ff:int=128, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0.3, act:str=\"gelu\", key_padding_mask:bool='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0.3, head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
    "                 verbose:bool=False, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        # self.model = model\n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "        \n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((context_window - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "        \n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = d_model * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
    "        \n",
    "        self.quant = torch.quantization.QuantStub().cpu()\n",
    "        self.dequant = torch.quantization.DeQuantStub().cpu()\n",
    "        \n",
    "    \n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        z = self.quant(z)\n",
    "        if self.revin: \n",
    "            # z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            # z = z.permute(0,2,1)\n",
    "            \n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        # print(f'z.shape: {z.shape}')\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x target_window] \n",
    "        \n",
    "        # denorm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            # z = z.permute(0,2,1)\n",
    "        z = self.dequant(z)\n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )\n",
    "\n",
    "def fuse_modules(model):\n",
    "    modules_to_fuse = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            next_module_name = None\n",
    "            for next_name, next_module in model.named_modules():\n",
    "                if next_module_name is not None and next_module_name.startswith(name) and isinstance(next_module, nn.ReLU):\n",
    "                    modules_to_fuse.append([name, next_name])\n",
    "                    break\n",
    "                if name == next_name:\n",
    "                    next_module_name = next_name\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.BatchNorm1d):\n",
    "            next_module_name = None\n",
    "            for next_name, next_module in model.named_modules():\n",
    "                if next_module_name is not None and next_module_name.startswith(name):\n",
    "                    if isinstance(next_module, nn.ReLU) and not isinstance(next_module, nn.GELU):\n",
    "                        modules_to_fuse.append([name, next_name])\n",
    "                        break\n",
    "                if name == next_name:\n",
    "                    next_module_name = next_name\n",
    "\n",
    "    for modules in modules_to_fuse:\n",
    "        torch.quantization.fuse_modules(model, modules, inplace=True)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantized_Learner:\n",
    "    def __init__(self, model, dataset, batch_size=128, lr=0.0001, epochs=5, target_window=96, d_model=16, adjust_lr=True, adjust_factor=0.001):\n",
    "        self.model = model.to(\"cpu\")\n",
    "        self.batch_size = batch_size\n",
    "        train_dataset = dataset(mode=\"train\")\n",
    "        valid_dataset = dataset(mode=\"val\")\n",
    "        test_dataset = dataset(mode=\"test\")\n",
    "        self.train_datalen = len(train_dataset)\n",
    "        self.valid_datalen = len(valid_dataset)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.lr=lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.epochs = epochs\n",
    "        self.target_window=target_window\n",
    "        self.best_weight = self.model.state_dict()\n",
    "        self.d_model=d_model\n",
    "        self.adjust_lr = adjust_lr\n",
    "        self.adjust_factor = adjust_factor\n",
    "    \n",
    "    def adjust_learning_rate(self, steps, warmup_step=300, printout=True):\n",
    "        if steps**(-0.5) < steps * (warmup_step**-1.5):\n",
    "            lr_adjust = (16**-0.5) * (steps**-0.5) * self.adjust_factor\n",
    "        else:\n",
    "            lr_adjust = (16**-0.5) * (steps * (warmup_step**-1.5)) * self.adjust_factor\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr_adjust\n",
    "        if printout: \n",
    "            print('Updating learning rate to {}'.format(lr_adjust))\n",
    "        return \n",
    "\n",
    "    def train(self):\n",
    "        best_valid_loss = np.inf\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "        train_steps = 1\n",
    "        if self.adjust_lr:\n",
    "            self.adjust_learning_rate(train_steps)\n",
    "        for epoch in range(self.epochs):\n",
    "            #train\n",
    "            self.model.train()\n",
    "            iter_count = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for train_x, train_y in self.train_dataloader:\n",
    "                train_x = train_x.to(\"cpu\")\n",
    "                train_y = train_y.to(\"cpu\")\n",
    "                # print(f'train_x.shape: {train_x.shape}')\n",
    "                pred_y = self.model(train_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, train_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "                train_steps += 1\n",
    "            if self.adjust_lr:\n",
    "                self.adjust_learning_rate(train_steps)\n",
    "\n",
    "            #valid\n",
    "            self.model.eval()\n",
    "            valid_iter_count = 0\n",
    "            valid_total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for valid_x, valid_y in self.valid_dataloader:\n",
    "                    valid_x = valid_x.to(\"cpu\")\n",
    "                    valid_y = valid_y.to(\"cpu\")\n",
    "                    pred_y = self.model(valid_x)\n",
    "                    pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                    loss = self.loss(pred_y, valid_y)\n",
    "                    valid_total_loss += loss.item()\n",
    "                    valid_iter_count += 1\n",
    "            \n",
    "            total_loss /= iter_count\n",
    "            valid_total_loss /= valid_iter_count\n",
    "            print(\"epoch: {} MSE loss: {:.4f} MSE valid loss: {:.4f}\".format(epoch, total_loss, valid_total_loss))\n",
    "            if best_valid_loss >= valid_total_loss:\n",
    "                self.best_weight = self.model.state_dict()\n",
    "                best_valid_loss = valid_total_loss\n",
    "                print(\"Best score! Weights of the model are updated!\")\n",
    "            train_history.append(total_loss)\n",
    "            valid_history.append(valid_total_loss)\n",
    "        return train_history, valid_history\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(self.best_weight)\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cpu\")\n",
    "                test_y = test_y.to(\"cpu\")\n",
    "                pred_y = self.model(test_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss: {:.4f}\".format(total_loss))\n",
    "    \n",
    "    def test_quantized_model(self):\n",
    "        self.model.eval()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in self.test_dataloader:\n",
    "                test_x = test_x.to(\"cpu\")\n",
    "                test_y = test_y.to(\"cpu\")\n",
    "                # Perform inference using the quantized model\n",
    "                # test_x = self.test_dataloader.dataset.quantizer.transform(test_x)\n",
    "                # print(f' test_x.device: {test_x.device} ')\n",
    "                pred_y = self.model(test_x)\n",
    "                pred_y = pred_y[:, -self.target_window:, -1:].squeeze(-1)\n",
    "                # Assuming the prediction is in the correct format, no further processing needed\n",
    "                # Calculate the loss\n",
    "                loss = self.loss(pred_y, test_y)\n",
    "                total_loss += loss.item()\n",
    "                iter_count += 1\n",
    "        total_loss /= iter_count\n",
    "        print(\"MSE test loss for quantized model: {:.4f}\".format(total_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTST(\n",
       "  (revin_layer): RevIN(\n",
       "    (quant): QuantStub()\n",
       "    (dequant): DeQuantStub()\n",
       "  )\n",
       "  (backbone): TSTiEncoder(\n",
       "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (encoder): TSTEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.3, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Flatten_Head(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNotImplementedError: Could not run 'quantized::linear' with arguments from the 'CUDA' backend. \\nThis could be because the operator doesn't exist for this backend, or was omitted during the selective/custom \\nbuild process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes \\nfor possible resolutions. 'quantized::linear' is only available for these backends: \\n    \\n    [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, \\n    Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, \\n    AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, \\n    AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, \\n    FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\\n\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NotImplementedError: Could not run 'quantized::linear' with arguments from the 'CUDA' backend. \n",
    "This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom \n",
    "build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes \n",
    "for possible resolutions. 'quantized::linear' is only available for these backends: \n",
    "    \n",
    "    [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, \n",
    "    Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, \n",
    "    AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, \n",
    "    AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, \n",
    "    FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train and test datasets\n",
    "train_dataset = ETTDataset(mode=\"train\")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataset = ETTDataset(mode=\"test\")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    train_history = []\n",
    "    train_steps = 1\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "        if epoch > 3:\n",
    "            model.apply(torch.ao.quantization.disable_observer)\n",
    "        if epoch > 2:\n",
    "            model.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
    "\n",
    "        for train_x, train_y in train_dataloader:\n",
    "            train_x = train_x.to(\"cpu\")\n",
    "            train_y = train_y.to(\"cpu\")\n",
    "            pred_y = model(train_x)\n",
    "            pred_y = pred_y[:, -96:, -1:].squeeze(-1)\n",
    "            loss = torch.nn.MSELoss()\n",
    "            loss = loss(pred_y, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            iter_count += 1\n",
    "            train_steps += 1\n",
    "        total_loss /= iter_count\n",
    "        train_history.append(total_loss)\n",
    "    return train_history\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    test_history = []\n",
    "    train_steps = 1\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        iter_count = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for train_x, train_y in train_dataloader:\n",
    "            train_x = train_x.to(\"cpu\")\n",
    "            train_y = train_y.to(\"cpu\")\n",
    "            # train_x = quantize_data(train_x)\n",
    "            pred_y = model(train_x)\n",
    "            pred_y = pred_y[:, -96:, -1:].squeeze(-1)\n",
    "            loss = torch.nn.MSELoss()\n",
    "            loss = loss(pred_y, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            iter_count += 1\n",
    "            train_steps += 1\n",
    "        total_loss /= iter_count\n",
    "        test_history.append(total_loss)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantized_PatchTST(\n",
       "  (revin_layer): RevIN(\n",
       "    (quant): QuantStub()\n",
       "    (dequant): DeQuantStub()\n",
       "  )\n",
       "  (backbone): TSTiEncoder(\n",
       "    (W_P): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (encoder): TSTEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.3, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Flatten_Head(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): Linear(in_features=5248, out_features=96, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in = 7\n",
    "context_window = 336\n",
    "target_window = 96\n",
    "patch_len = 16\n",
    "stride = 8 \n",
    "q_patchtst_model_fp32 = Quantized_PatchTST(c_in=c_in, context_window=context_window, target_window=target_window, patch_len=patch_len, stride=stride)\n",
    "q_patchtst_model_fp32.to('cpu')\n",
    "q_patchtst_model_fp32.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "q_patchtst_model_fp32.qconfig = torch.ao.quantization.get_default_qat_qconfig('x86')\n",
    "q_patchtst_model_fp32_fused = fuse_modules(q_patchtst_model_fp32)\n",
    "q_patchtst_model_fp32_prepared = torch.ao.quantization.prepare_qat(q_patchtst_model_fp32_fused.train())\n",
    "optimizer = torch.optim.Adam(q_patchtst_model_fp32_prepared.parameters(), lr=0.00001)\n",
    "\n",
    "# train(q_patchtst_model_fp32_prepared)\n",
    "# q_patchtst_learner.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 4.811252243246882e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:353: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at ../aten/src/ATen/native/ReduceAllOps.cpp:72.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n",
      "/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:353: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:677.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 3.175426480542942e-06\n",
      "epoch: 0 MSE loss: 0.2333 MSE valid loss: 0.1313\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 6.302740438653415e-06\n",
      "epoch: 1 MSE loss: 0.2253 MSE valid loss: 0.1230\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 9.430054396763887e-06\n",
      "epoch: 2 MSE loss: 0.2099 MSE valid loss: 0.1140\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.2557368354874362e-05\n",
      "epoch: 3 MSE loss: 0.1949 MSE valid loss: 0.1079\n",
      "Best score! Weights of the model are updated!\n",
      "Updating learning rate to 1.3846219390542782e-05\n",
      "epoch: 4 MSE loss: 0.1880 MSE valid loss: 0.1042\n",
      "Best score! Weights of the model are updated!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.23326618235844832,\n",
       "  0.22525480893942026,\n",
       "  0.209916123518577,\n",
       "  0.19485767300312334,\n",
       "  0.18803285429110894],\n",
       " [0.13132370805198496,\n",
       "  0.12299844487146898,\n",
       "  0.11401724883101204,\n",
       "  0.10789071379060095,\n",
       "  0.10419452469795942])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_learner = Learner(model=q_patchtst_model_fp32_prepared, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "patchtst_learner.train()\n",
    "# q_patchtst_learner = Quantized_Learner(model=q_patchtst_model_fp32_prepared, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantized_PatchTST(\n",
       "  (revin_layer): RevIN(\n",
       "    (quant): QuantStub(\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (dequant): DeQuantStub()\n",
       "  )\n",
       "  (backbone): TSTiEncoder(\n",
       "    (W_P): Linear(\n",
       "      in_features=16, out_features=128, bias=True\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0018, 0.0019, 0.0019, 0.0019, 0.0019, 0.0018, 0.0020, 0.0019, 0.0019,\n",
       "                0.0014, 0.0018, 0.0019, 0.0018, 0.0018, 0.0020, 0.0018, 0.0018, 0.0019,\n",
       "                0.0018, 0.0018, 0.0018, 0.0019, 0.0019, 0.0019, 0.0018, 0.0019, 0.0019,\n",
       "                0.0018, 0.0016, 0.0019, 0.0019, 0.0019, 0.0018, 0.0018, 0.0020, 0.0019,\n",
       "                0.0017, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0017, 0.0018, 0.0018,\n",
       "                0.0019, 0.0019, 0.0019, 0.0018, 0.0019, 0.0019, 0.0018, 0.0018, 0.0019,\n",
       "                0.0019, 0.0020, 0.0019, 0.0020, 0.0020, 0.0018, 0.0020, 0.0016, 0.0019,\n",
       "                0.0018, 0.0019, 0.0018, 0.0019, 0.0018, 0.0020, 0.0018, 0.0019, 0.0019,\n",
       "                0.0015, 0.0017, 0.0017, 0.0019, 0.0019, 0.0019, 0.0019, 0.0020, 0.0018,\n",
       "                0.0019, 0.0019, 0.0019, 0.0018, 0.0018, 0.0019, 0.0018, 0.0019, 0.0019,\n",
       "                0.0018, 0.0019, 0.0019, 0.0016, 0.0018, 0.0018, 0.0018, 0.0019, 0.0019,\n",
       "                0.0019, 0.0016, 0.0017, 0.0019, 0.0017, 0.0020, 0.0019, 0.0015, 0.0018,\n",
       "                0.0020, 0.0019, 0.0019, 0.0017, 0.0019, 0.0019, 0.0019, 0.0019, 0.0018,\n",
       "                0.0015, 0.0018, 0.0019, 0.0019, 0.0019, 0.0019, 0.0017, 0.0019, 0.0019,\n",
       "                0.0019, 0.0019], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "          min_val=tensor([-0.2315, -0.2369, -0.2455, -0.0979, -0.2381, -0.2245, -0.1644, -0.2442,\n",
       "                  -0.2481, -0.1729, -0.1591, -0.2368, -0.1901, -0.2258, -0.2506, -0.2271,\n",
       "                  -0.2324, -0.1948, -0.2200, -0.2348, -0.2323, -0.2476, -0.2434, -0.2224,\n",
       "                  -0.2324, -0.2494, -0.2376, -0.2264, -0.1987, -0.2464, -0.2165, -0.2441,\n",
       "                  -0.2259, -0.2093, -0.2014, -0.2481, -0.1869, -0.2261, -0.2223, -0.2380,\n",
       "                  -0.2209, -0.2230, -0.2178, -0.2307, -0.2367, -0.2477, -0.1730, -0.2393,\n",
       "                  -0.2365, -0.2487, -0.2419, -0.2233, -0.2337, -0.1634, -0.2461, -0.1971,\n",
       "                  -0.2469, -0.2297, -0.2218, -0.1562, -0.2178, -0.2048, -0.1766, -0.2252,\n",
       "                  -0.2442, -0.1864, -0.2423, -0.2331, -0.2096, -0.2280, -0.2054, -0.1902,\n",
       "                  -0.1972, -0.2221, -0.2002, -0.2416, -0.2484, -0.2407, -0.2011, -0.2034,\n",
       "                  -0.2255, -0.2183, -0.2471, -0.2437, -0.2366, -0.2242, -0.2429, -0.1977,\n",
       "                  -0.2185, -0.2472, -0.1042, -0.2413, -0.2420, -0.1949, -0.2262, -0.2232,\n",
       "                  -0.2366, -0.2370, -0.2335, -0.2193, -0.2065, -0.2184, -0.2469, -0.1981,\n",
       "                  -0.2251, -0.2449, -0.1820, -0.1788, -0.2155, -0.2454, -0.2414, -0.2120,\n",
       "                  -0.1683, -0.2467, -0.2483, -0.2463, -0.2322, -0.1937, -0.2206, -0.2434,\n",
       "                  -0.2086, -0.2322, -0.2451, -0.2115, -0.2417, -0.2289, -0.2039, -0.2427],\n",
       "                 device='cuda:0'), max_val=tensor([0.1990, 0.2403, 0.2475, 0.2395, 0.1196, 0.1711, 0.2479, 0.2335, 0.2344,\n",
       "                  0.1652, 0.2349, 0.2417, 0.2334, 0.2233, 0.2320, 0.1809, 0.2153, 0.2400,\n",
       "                  0.2285, 0.1995, 0.0986, 0.2451, 0.2444, 0.2459, 0.2215, 0.2167, 0.2203,\n",
       "                  0.2216, 0.1464, 0.2200, 0.2354, 0.1883, 0.2027, 0.2316, 0.2485, 0.2117,\n",
       "                  0.2206, 0.2454, 0.2388, 0.2248, 0.2409, 0.2426, 0.1693, 0.1979, 0.2329,\n",
       "                  0.2174, 0.2374, 0.2270, 0.2206, 0.2046, 0.2274, 0.2257, 0.2180, 0.2352,\n",
       "                  0.1989, 0.2500, 0.1831, 0.2487, 0.2492, 0.2305, 0.2485, 0.2083, 0.2377,\n",
       "                  0.2016, 0.2349, 0.2328, 0.2311, 0.2295, 0.2491, 0.2057, 0.2402, 0.2454,\n",
       "                  0.1693, 0.2019, 0.2136, 0.1394, 0.2417, 0.2462, 0.2454, 0.2490, 0.2014,\n",
       "                  0.2450, 0.2148, 0.2426, 0.2146, 0.1748, 0.2443, 0.2348, 0.2430, 0.2069,\n",
       "                  0.2224, 0.2405, 0.2345, 0.2078, 0.2116, 0.2337, 0.2287, 0.2054, 0.2352,\n",
       "                  0.2462, 0.1839, 0.2102, 0.2363, 0.2148, 0.2498, 0.2245, 0.1852, 0.2272,\n",
       "                  0.2487, 0.1983, 0.2314, 0.2172, 0.2428, 0.2275, 0.0922, 0.2180, 0.2094,\n",
       "                  0.1746, 0.2273, 0.2409, 0.2366, 0.2444, 0.2382, 0.2124, 0.1762, 0.2474,\n",
       "                  0.2397, 0.2312], device='cuda:0')\n",
       "        )\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0809], device='cuda:0'), zero_point=tensor([63], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.070293426513672, max_val=5.205967426300049)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (encoder): TSTEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0861, -0.0873, -0.0876, -0.0858, -0.0866, -0.0858, -0.0861, -0.0881,\n",
       "                          -0.0864, -0.0865, -0.0874, -0.0873, -0.0873, -0.0881, -0.0884, -0.0863,\n",
       "                          -0.0867, -0.0875, -0.0871, -0.0880, -0.0871, -0.0862, -0.0841, -0.0878,\n",
       "                          -0.0878, -0.0880, -0.0843, -0.0885, -0.0882, -0.0888, -0.0876, -0.0886,\n",
       "                          -0.0874, -0.0865, -0.0861, -0.0884, -0.0859, -0.0824, -0.0885, -0.0884,\n",
       "                          -0.0880, -0.0870, -0.0882, -0.0865, -0.0887, -0.0878, -0.0877, -0.0884,\n",
       "                          -0.0878, -0.0872, -0.0885, -0.0826, -0.0871, -0.0871, -0.0885, -0.0886,\n",
       "                          -0.0858, -0.0860, -0.0852, -0.0887, -0.0875, -0.0884, -0.0843, -0.0882,\n",
       "                          -0.0880, -0.0858, -0.0871, -0.0862, -0.0877, -0.0878, -0.0886, -0.0880,\n",
       "                          -0.0889, -0.0772, -0.0877, -0.0877, -0.0825, -0.0871, -0.0880, -0.0885,\n",
       "                          -0.0879, -0.0881, -0.0877, -0.0852, -0.0873, -0.0888, -0.0873, -0.0876,\n",
       "                          -0.0877, -0.0873, -0.0877, -0.0856, -0.0850, -0.0866, -0.0883, -0.0864,\n",
       "                          -0.0834, -0.0856, -0.0853, -0.0883, -0.0888, -0.0871, -0.0879, -0.0883,\n",
       "                          -0.0862, -0.0883, -0.0872, -0.0882, -0.0884, -0.0879, -0.0864, -0.0887,\n",
       "                          -0.0861, -0.0879, -0.0881, -0.0884, -0.0875, -0.0871, -0.0880, -0.0879,\n",
       "                          -0.0888, -0.0852, -0.0878, -0.0867, -0.0882, -0.0872, -0.0875, -0.0887],\n",
       "                         device='cuda:0'), max_val=tensor([0.0874, 0.0879, 0.0877, 0.0819, 0.0878, 0.0880, 0.0878, 0.0888, 0.0866,\n",
       "                          0.0821, 0.0878, 0.0887, 0.0866, 0.0859, 0.0861, 0.0846, 0.0795, 0.0878,\n",
       "                          0.0878, 0.0868, 0.0873, 0.0887, 0.0874, 0.0887, 0.0885, 0.0878, 0.0884,\n",
       "                          0.0873, 0.0876, 0.0884, 0.0879, 0.0878, 0.0870, 0.0880, 0.0887, 0.0878,\n",
       "                          0.0885, 0.0881, 0.0877, 0.0849, 0.0880, 0.0870, 0.0867, 0.0869, 0.0885,\n",
       "                          0.0867, 0.0853, 0.0870, 0.0872, 0.0887, 0.0858, 0.0852, 0.0867, 0.0888,\n",
       "                          0.0879, 0.0885, 0.0884, 0.0853, 0.0876, 0.0825, 0.0871, 0.0874, 0.0886,\n",
       "                          0.0869, 0.0874, 0.0865, 0.0881, 0.0860, 0.0887, 0.0880, 0.0878, 0.0867,\n",
       "                          0.0889, 0.0872, 0.0868, 0.0876, 0.0878, 0.0869, 0.0878, 0.0863, 0.0880,\n",
       "                          0.0875, 0.0863, 0.0795, 0.0879, 0.0860, 0.0866, 0.0870, 0.0871, 0.0848,\n",
       "                          0.0868, 0.0883, 0.0888, 0.0883, 0.0875, 0.0878, 0.0873, 0.0879, 0.0881,\n",
       "                          0.0876, 0.0860, 0.0858, 0.0874, 0.0881, 0.0848, 0.0881, 0.0881, 0.0877,\n",
       "                          0.0889, 0.0850, 0.0888, 0.0868, 0.0873, 0.0885, 0.0876, 0.0864, 0.0867,\n",
       "                          0.0886, 0.0873, 0.0878, 0.0875, 0.0883, 0.0877, 0.0875, 0.0884, 0.0875,\n",
       "                          0.0886, 0.0876], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0596], device='cuda:0'), zero_point=tensor([63], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7827670574188232, max_val=3.7861270904541016)\n",
       "              )\n",
       "            )\n",
       "            (W_K): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0847, -0.0870, -0.0890, -0.0873, -0.0871, -0.0866, -0.0886, -0.0872,\n",
       "                          -0.0874, -0.0878, -0.0889, -0.0876, -0.0881, -0.0884, -0.0864, -0.0858,\n",
       "                          -0.0877, -0.0875, -0.0877, -0.0884, -0.0883, -0.0878, -0.0846, -0.0853,\n",
       "                          -0.0876, -0.0881, -0.0874, -0.0843, -0.0875, -0.0879, -0.0844, -0.0863,\n",
       "                          -0.0859, -0.0848, -0.0867, -0.0882, -0.0869, -0.0847, -0.0872, -0.0843,\n",
       "                          -0.0862, -0.0875, -0.0876, -0.0874, -0.0875, -0.0870, -0.0881, -0.0867,\n",
       "                          -0.0841, -0.0885, -0.0800, -0.0876, -0.0866, -0.0867, -0.0856, -0.0857,\n",
       "                          -0.0853, -0.0877, -0.0874, -0.0882, -0.0875, -0.0876, -0.0850, -0.0863,\n",
       "                          -0.0876, -0.0888, -0.0889, -0.0881, -0.0879, -0.0867, -0.0886, -0.0891,\n",
       "                          -0.0878, -0.0847, -0.0874, -0.0884, -0.0883, -0.0886, -0.0857, -0.0874,\n",
       "                          -0.0862, -0.0846, -0.0888, -0.0887, -0.0856, -0.0856, -0.0870, -0.0880,\n",
       "                          -0.0857, -0.0875, -0.0847, -0.0872, -0.0864, -0.0850, -0.0877, -0.0879,\n",
       "                          -0.0826, -0.0864, -0.0885, -0.0869, -0.0863, -0.0868, -0.0873, -0.0872,\n",
       "                          -0.0859, -0.0875, -0.0861, -0.0827, -0.0877, -0.0881, -0.0870, -0.0845,\n",
       "                          -0.0875, -0.0871, -0.0881, -0.0875, -0.0883, -0.0881, -0.0877, -0.0874,\n",
       "                          -0.0876, -0.0878, -0.0847, -0.0872, -0.0884, -0.0882, -0.0880, -0.0860],\n",
       "                         device='cuda:0'), max_val=tensor([0.0863, 0.0863, 0.0870, 0.0882, 0.0876, 0.0890, 0.0884, 0.0873, 0.0881,\n",
       "                          0.0887, 0.0884, 0.0874, 0.0884, 0.0869, 0.0892, 0.0883, 0.0858, 0.0858,\n",
       "                          0.0854, 0.0855, 0.0887, 0.0852, 0.0860, 0.0874, 0.0864, 0.0885, 0.0874,\n",
       "                          0.0876, 0.0871, 0.0885, 0.0881, 0.0871, 0.0879, 0.0873, 0.0843, 0.0867,\n",
       "                          0.0869, 0.0857, 0.0864, 0.0884, 0.0872, 0.0879, 0.0883, 0.0881, 0.0868,\n",
       "                          0.0882, 0.0850, 0.0869, 0.0881, 0.0874, 0.0850, 0.0879, 0.0848, 0.0860,\n",
       "                          0.0873, 0.0889, 0.0862, 0.0858, 0.0885, 0.0885, 0.0862, 0.0871, 0.0861,\n",
       "                          0.0881, 0.0876, 0.0862, 0.0875, 0.0875, 0.0832, 0.0883, 0.0880, 0.0889,\n",
       "                          0.0879, 0.0869, 0.0864, 0.0837, 0.0833, 0.0866, 0.0863, 0.0842, 0.0864,\n",
       "                          0.0884, 0.0860, 0.0881, 0.0878, 0.0887, 0.0870, 0.0879, 0.0844, 0.0881,\n",
       "                          0.0868, 0.0874, 0.0889, 0.0878, 0.0888, 0.0883, 0.0866, 0.0873, 0.0849,\n",
       "                          0.0884, 0.0870, 0.0875, 0.0884, 0.0874, 0.0872, 0.0854, 0.0882, 0.0877,\n",
       "                          0.0859, 0.0847, 0.0842, 0.0875, 0.0880, 0.0878, 0.0875, 0.0818, 0.0847,\n",
       "                          0.0873, 0.0877, 0.0879, 0.0883, 0.0879, 0.0882, 0.0886, 0.0878, 0.0867,\n",
       "                          0.0878, 0.0847], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0698], device='cuda:0'), zero_point=tensor([66], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.576383113861084, max_val=4.285088062286377)\n",
       "              )\n",
       "            )\n",
       "            (W_V): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0876, -0.0883, -0.0862, -0.0863, -0.0889, -0.0886, -0.0815, -0.0867,\n",
       "                          -0.0860, -0.0879, -0.0862, -0.0860, -0.0868, -0.0847, -0.0878, -0.0868,\n",
       "                          -0.0887, -0.0885, -0.0872, -0.0865, -0.0873, -0.0877, -0.0867, -0.0876,\n",
       "                          -0.0853, -0.0865, -0.0871, -0.0857, -0.0857, -0.0876, -0.0881, -0.0878,\n",
       "                          -0.0880, -0.0856, -0.0880, -0.0880, -0.0867, -0.0877, -0.0874, -0.0875,\n",
       "                          -0.0823, -0.0883, -0.0856, -0.0877, -0.0851, -0.0886, -0.0871, -0.0865,\n",
       "                          -0.0871, -0.0856, -0.0872, -0.0860, -0.0874, -0.0867, -0.0813, -0.0882,\n",
       "                          -0.0874, -0.0881, -0.0879, -0.0863, -0.0846, -0.0859, -0.0879, -0.0884,\n",
       "                          -0.0850, -0.0883, -0.0874, -0.0885, -0.0877, -0.0886, -0.0856, -0.0879,\n",
       "                          -0.0869, -0.0868, -0.0874, -0.0878, -0.0875, -0.0869, -0.0889, -0.0875,\n",
       "                          -0.0884, -0.0873, -0.0875, -0.0867, -0.0888, -0.0876, -0.0888, -0.0877,\n",
       "                          -0.0869, -0.0883, -0.0876, -0.0888, -0.0874, -0.0856, -0.0857, -0.0862,\n",
       "                          -0.0879, -0.0884, -0.0885, -0.0888, -0.0877, -0.0884, -0.0876, -0.0865,\n",
       "                          -0.0887, -0.0828, -0.0871, -0.0880, -0.0885, -0.0841, -0.0879, -0.0863,\n",
       "                          -0.0866, -0.0888, -0.0849, -0.0874, -0.0869, -0.0861, -0.0879, -0.0864,\n",
       "                          -0.0885, -0.0877, -0.0825, -0.0883, -0.0864, -0.0871, -0.0847, -0.0884],\n",
       "                         device='cuda:0'), max_val=tensor([0.0884, 0.0861, 0.0816, 0.0880, 0.0882, 0.0836, 0.0860, 0.0884, 0.0876,\n",
       "                          0.0815, 0.0860, 0.0851, 0.0866, 0.0878, 0.0880, 0.0860, 0.0883, 0.0882,\n",
       "                          0.0874, 0.0865, 0.0869, 0.0875, 0.0865, 0.0874, 0.0881, 0.0876, 0.0849,\n",
       "                          0.0856, 0.0884, 0.0830, 0.0888, 0.0888, 0.0882, 0.0874, 0.0881, 0.0838,\n",
       "                          0.0885, 0.0883, 0.0862, 0.0863, 0.0836, 0.0846, 0.0878, 0.0864, 0.0835,\n",
       "                          0.0886, 0.0874, 0.0888, 0.0860, 0.0757, 0.0883, 0.0885, 0.0888, 0.0880,\n",
       "                          0.0826, 0.0875, 0.0875, 0.0841, 0.0885, 0.0830, 0.0869, 0.0860, 0.0882,\n",
       "                          0.0879, 0.0855, 0.0885, 0.0870, 0.0841, 0.0865, 0.0868, 0.0874, 0.0866,\n",
       "                          0.0878, 0.0879, 0.0868, 0.0886, 0.0850, 0.0877, 0.0883, 0.0884, 0.0877,\n",
       "                          0.0859, 0.0882, 0.0873, 0.0880, 0.0885, 0.0873, 0.0873, 0.0874, 0.0880,\n",
       "                          0.0885, 0.0872, 0.0873, 0.0842, 0.0861, 0.0882, 0.0883, 0.0881, 0.0882,\n",
       "                          0.0872, 0.0886, 0.0888, 0.0876, 0.0870, 0.0877, 0.0876, 0.0839, 0.0869,\n",
       "                          0.0851, 0.0841, 0.0855, 0.0870, 0.0870, 0.0888, 0.0855, 0.0869, 0.0875,\n",
       "                          0.0863, 0.0874, 0.0863, 0.0873, 0.0877, 0.0875, 0.0873, 0.0879, 0.0865,\n",
       "                          0.0882, 0.0884], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0567], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.6342508792877197, max_val=3.5634114742279053)\n",
       "              )\n",
       "            )\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(\n",
       "                in_features=128, out_features=128, bias=True\n",
       "                (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                  (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                    min_val=tensor([-0.0855, -0.0874, -0.0885, -0.0877, -0.0866, -0.0864, -0.0835, -0.0866,\n",
       "                            -0.0863, -0.0873, -0.0879, -0.0862, -0.0872, -0.0878, -0.0874, -0.0873,\n",
       "                            -0.0881, -0.0881, -0.0848, -0.0887, -0.0879, -0.0883, -0.0883, -0.0875,\n",
       "                            -0.0873, -0.0868, -0.0871, -0.0871, -0.0864, -0.0881, -0.0861, -0.0883,\n",
       "                            -0.0877, -0.0883, -0.0833, -0.0876, -0.0876, -0.0871, -0.0832, -0.0878,\n",
       "                            -0.0879, -0.0872, -0.0875, -0.0863, -0.0879, -0.0886, -0.0870, -0.0877,\n",
       "                            -0.0871, -0.0879, -0.0861, -0.0881, -0.0880, -0.0886, -0.0877, -0.0865,\n",
       "                            -0.0874, -0.0877, -0.0872, -0.0862, -0.0869, -0.0872, -0.0874, -0.0869,\n",
       "                            -0.0876, -0.0873, -0.0875, -0.0880, -0.0855, -0.0860, -0.0867, -0.0873,\n",
       "                            -0.0882, -0.0867, -0.0863, -0.0825, -0.0868, -0.0870, -0.0872, -0.0807,\n",
       "                            -0.0883, -0.0863, -0.0841, -0.0870, -0.0890, -0.0861, -0.0868, -0.0862,\n",
       "                            -0.0876, -0.0880, -0.0883, -0.0880, -0.0865, -0.0866, -0.0861, -0.0881,\n",
       "                            -0.0864, -0.0840, -0.0882, -0.0853, -0.0881, -0.0879, -0.0868, -0.0833,\n",
       "                            -0.0877, -0.0875, -0.0846, -0.0880, -0.0885, -0.0886, -0.0877, -0.0865,\n",
       "                            -0.0861, -0.0878, -0.0874, -0.0869, -0.0881, -0.0868, -0.0855, -0.0861,\n",
       "                            -0.0869, -0.0881, -0.0883, -0.0874, -0.0879, -0.0878, -0.0881, -0.0880],\n",
       "                           device='cuda:0'), max_val=tensor([0.0879, 0.0882, 0.0838, 0.0864, 0.0879, 0.0864, 0.0880, 0.0857, 0.0842,\n",
       "                            0.0876, 0.0816, 0.0868, 0.0836, 0.0873, 0.0876, 0.0861, 0.0883, 0.0874,\n",
       "                            0.0878, 0.0889, 0.0887, 0.0870, 0.0884, 0.0878, 0.0879, 0.0887, 0.0875,\n",
       "                            0.0878, 0.0867, 0.0872, 0.0885, 0.0882, 0.0869, 0.0884, 0.0880, 0.0883,\n",
       "                            0.0881, 0.0882, 0.0887, 0.0856, 0.0836, 0.0864, 0.0880, 0.0871, 0.0862,\n",
       "                            0.0876, 0.0881, 0.0834, 0.0878, 0.0873, 0.0877, 0.0874, 0.0854, 0.0809,\n",
       "                            0.0885, 0.0869, 0.0862, 0.0885, 0.0877, 0.0869, 0.0882, 0.0882, 0.0876,\n",
       "                            0.0873, 0.0846, 0.0880, 0.0878, 0.0879, 0.0884, 0.0884, 0.0865, 0.0831,\n",
       "                            0.0881, 0.0874, 0.0881, 0.0863, 0.0876, 0.0872, 0.0875, 0.0883, 0.0887,\n",
       "                            0.0875, 0.0861, 0.0862, 0.0887, 0.0839, 0.0871, 0.0847, 0.0865, 0.0879,\n",
       "                            0.0872, 0.0873, 0.0882, 0.0878, 0.0868, 0.0843, 0.0881, 0.0873, 0.0844,\n",
       "                            0.0868, 0.0862, 0.0869, 0.0872, 0.0853, 0.0858, 0.0873, 0.0844, 0.0853,\n",
       "                            0.0879, 0.0878, 0.0878, 0.0885, 0.0878, 0.0876, 0.0864, 0.0867, 0.0868,\n",
       "                            0.0867, 0.0843, 0.0884, 0.0871, 0.0881, 0.0878, 0.0882, 0.0883, 0.0881,\n",
       "                            0.0879, 0.0883], device='cuda:0')\n",
       "                  )\n",
       "                )\n",
       "                (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0062], device='cuda:0'), zero_point=tensor([63], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3912670612335205, max_val=0.3931117653846741)\n",
       "                )\n",
       "              )\n",
       "              (1): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0875, -0.0864, -0.0853, -0.0870, -0.0881, -0.0874, -0.0872, -0.0867,\n",
       "                          -0.0873, -0.0869, -0.0884, -0.0883, -0.0889, -0.0877, -0.0871, -0.0880,\n",
       "                          -0.0873, -0.0875, -0.0869, -0.0881, -0.0881, -0.0864, -0.0884, -0.0881,\n",
       "                          -0.0877, -0.0887, -0.0864, -0.0869, -0.0886, -0.0868, -0.0875, -0.0866,\n",
       "                          -0.0885, -0.0875, -0.0870, -0.0882, -0.0845, -0.0875, -0.0886, -0.0853,\n",
       "                          -0.0860, -0.0887, -0.0873, -0.0890, -0.0881, -0.0878, -0.0883, -0.0878,\n",
       "                          -0.0887, -0.0880, -0.0863, -0.0877, -0.0880, -0.0876, -0.0882, -0.0888,\n",
       "                          -0.0880, -0.0844, -0.0879, -0.0869, -0.0881, -0.0834, -0.0886, -0.0868,\n",
       "                          -0.0866, -0.0876, -0.0880, -0.0879, -0.0836, -0.0880, -0.0879, -0.0872,\n",
       "                          -0.0881, -0.0885, -0.0879, -0.0882, -0.0872, -0.0859, -0.0879, -0.0866,\n",
       "                          -0.0885, -0.0866, -0.0867, -0.0881, -0.0886, -0.0855, -0.0872, -0.0844,\n",
       "                          -0.0877, -0.0878, -0.0859, -0.0847, -0.0873, -0.0849, -0.0875, -0.0881,\n",
       "                          -0.0840, -0.0859, -0.0873, -0.0877, -0.0885, -0.0885, -0.0881, -0.0874,\n",
       "                          -0.0866, -0.0874, -0.0869, -0.0873, -0.0880, -0.0864, -0.0873, -0.0873,\n",
       "                          -0.0858, -0.0861, -0.0873, -0.0874, -0.0870, -0.0872, -0.0859, -0.0887,\n",
       "                          -0.0865, -0.0872, -0.0881, -0.0845, -0.0858, -0.0879, -0.0886, -0.0888],\n",
       "                         device='cuda:0'), max_val=tensor([0.0859, 0.0876, 0.0868, 0.0876, 0.0871, 0.0865, 0.0881, 0.0873, 0.0881,\n",
       "                          0.0881, 0.0879, 0.0885, 0.0876, 0.0878, 0.0809, 0.0877, 0.0863, 0.0872,\n",
       "                          0.0850, 0.0854, 0.0865, 0.0872, 0.0881, 0.0872, 0.0879, 0.0868, 0.0874,\n",
       "                          0.0875, 0.0882, 0.0858, 0.0858, 0.0863, 0.0850, 0.0843, 0.0831, 0.0889,\n",
       "                          0.0873, 0.0860, 0.0885, 0.0881, 0.0857, 0.0878, 0.0873, 0.0879, 0.0863,\n",
       "                          0.0875, 0.0881, 0.0818, 0.0871, 0.0881, 0.0877, 0.0867, 0.0881, 0.0886,\n",
       "                          0.0880, 0.0864, 0.0855, 0.0883, 0.0884, 0.0869, 0.0861, 0.0858, 0.0869,\n",
       "                          0.0879, 0.0869, 0.0885, 0.0878, 0.0869, 0.0869, 0.0875, 0.0881, 0.0871,\n",
       "                          0.0852, 0.0870, 0.0879, 0.0878, 0.0873, 0.0887, 0.0870, 0.0861, 0.0878,\n",
       "                          0.0862, 0.0888, 0.0866, 0.0867, 0.0886, 0.0881, 0.0884, 0.0872, 0.0834,\n",
       "                          0.0877, 0.0857, 0.0869, 0.0865, 0.0851, 0.0888, 0.0864, 0.0858, 0.0880,\n",
       "                          0.0886, 0.0863, 0.0835, 0.0861, 0.0865, 0.0878, 0.0883, 0.0843, 0.0854,\n",
       "                          0.0869, 0.0815, 0.0877, 0.0854, 0.0876, 0.0878, 0.0889, 0.0858, 0.0872,\n",
       "                          0.0887, 0.0870, 0.0878, 0.0880, 0.0873, 0.0869, 0.0876, 0.0887, 0.0886,\n",
       "                          0.0883, 0.0886], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0821], device='cuda:0'), zero_point=tensor([63], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.165726661682129, max_val=5.261214733123779)\n",
       "              )\n",
       "            )\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.3, inplace=False)\n",
       "            (3): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0859, -0.0866, -0.0883, -0.0872, -0.0867, -0.0879, -0.0858, -0.0864,\n",
       "                          -0.0874, -0.0872, -0.0882, -0.0871, -0.0841, -0.0876, -0.0884, -0.0884,\n",
       "                          -0.0877, -0.0873, -0.0868, -0.0878, -0.0876, -0.0883, -0.0832, -0.0845,\n",
       "                          -0.0878, -0.0885, -0.0857, -0.0880, -0.0873, -0.0862, -0.0875, -0.0880,\n",
       "                          -0.0880, -0.0873, -0.0872, -0.0865, -0.0881, -0.0870, -0.0863, -0.0859,\n",
       "                          -0.0866, -0.0882, -0.0874, -0.0873, -0.0884, -0.0872, -0.0882, -0.0883,\n",
       "                          -0.0878, -0.0886, -0.0879, -0.0881, -0.0882, -0.0882, -0.0873, -0.0869,\n",
       "                          -0.0864, -0.0874, -0.0875, -0.0880, -0.0884, -0.0876, -0.0876, -0.0880,\n",
       "                          -0.0837, -0.0877, -0.0879, -0.0874, -0.0881, -0.0845, -0.0878, -0.0871,\n",
       "                          -0.0885, -0.0856, -0.0869, -0.0861, -0.0864, -0.0866, -0.0874, -0.0864,\n",
       "                          -0.0852, -0.0845, -0.0872, -0.0877, -0.0873, -0.0880, -0.0884, -0.0881,\n",
       "                          -0.0875, -0.0882, -0.0871, -0.0878, -0.0872, -0.0875, -0.0877, -0.0875,\n",
       "                          -0.0880, -0.0825, -0.0875, -0.0877, -0.0866, -0.0873, -0.0878, -0.0841,\n",
       "                          -0.0867, -0.0877, -0.0878, -0.0870, -0.0878, -0.0872, -0.0884, -0.0871,\n",
       "                          -0.0881, -0.0866, -0.0876, -0.0860, -0.0883, -0.0878, -0.0882, -0.0866,\n",
       "                          -0.0877, -0.0882, -0.0874, -0.0852, -0.0874, -0.0885, -0.0872, -0.0836],\n",
       "                         device='cuda:0'), max_val=tensor([0.0876, 0.0874, 0.0863, 0.0879, 0.0866, 0.0868, 0.0853, 0.0872, 0.0851,\n",
       "                          0.0833, 0.0875, 0.0875, 0.0854, 0.0868, 0.0888, 0.0874, 0.0856, 0.0877,\n",
       "                          0.0880, 0.0875, 0.0870, 0.0879, 0.0866, 0.0872, 0.0881, 0.0862, 0.0872,\n",
       "                          0.0875, 0.0879, 0.0852, 0.0878, 0.0863, 0.0864, 0.0867, 0.0871, 0.0878,\n",
       "                          0.0878, 0.0875, 0.0867, 0.0861, 0.0883, 0.0873, 0.0884, 0.0876, 0.0872,\n",
       "                          0.0871, 0.0874, 0.0858, 0.0878, 0.0865, 0.0867, 0.0865, 0.0868, 0.0877,\n",
       "                          0.0877, 0.0879, 0.0875, 0.0866, 0.0870, 0.0891, 0.0881, 0.0858, 0.0872,\n",
       "                          0.0871, 0.0879, 0.0885, 0.0888, 0.0862, 0.0865, 0.0875, 0.0874, 0.0833,\n",
       "                          0.0875, 0.0885, 0.0879, 0.0880, 0.0870, 0.0845, 0.0856, 0.0862, 0.0861,\n",
       "                          0.0878, 0.0868, 0.0874, 0.0883, 0.0878, 0.0865, 0.0873, 0.0874, 0.0827,\n",
       "                          0.0858, 0.0866, 0.0859, 0.0844, 0.0867, 0.0881, 0.0867, 0.0874, 0.0882,\n",
       "                          0.0884, 0.0879, 0.0883, 0.0883, 0.0854, 0.0876, 0.0868, 0.0883, 0.0853,\n",
       "                          0.0879, 0.0866, 0.0836, 0.0846, 0.0878, 0.0879, 0.0873, 0.0875, 0.0867,\n",
       "                          0.0875, 0.0873, 0.0871, 0.0877, 0.0866, 0.0869, 0.0871, 0.0871, 0.0863,\n",
       "                          0.0873, 0.0872], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0367], device='cuda:0'), zero_point=tensor([62], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2814362049102783, max_val=2.376239061355591)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "        (1): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0863, -0.0877, -0.0871, -0.0879, -0.0861, -0.0865, -0.0881, -0.0874,\n",
       "                          -0.0884, -0.0852, -0.0881, -0.0864, -0.0882, -0.0873, -0.0848, -0.0884,\n",
       "                          -0.0844, -0.0880, -0.0853, -0.0851, -0.0880, -0.0825, -0.0883, -0.0866,\n",
       "                          -0.0877, -0.0884, -0.0883, -0.0852, -0.0869, -0.0853, -0.0873, -0.0879,\n",
       "                          -0.0849, -0.0842, -0.0864, -0.0884, -0.0885, -0.0874, -0.0888, -0.0882,\n",
       "                          -0.0877, -0.0889, -0.0881, -0.0878, -0.0875, -0.0851, -0.0878, -0.0869,\n",
       "                          -0.0867, -0.0883, -0.0874, -0.0875, -0.0871, -0.0877, -0.0859, -0.0886,\n",
       "                          -0.0878, -0.0854, -0.0868, -0.0875, -0.0881, -0.0864, -0.0864, -0.0875,\n",
       "                          -0.0874, -0.0874, -0.0861, -0.0843, -0.0878, -0.0833, -0.0869, -0.0878,\n",
       "                          -0.0853, -0.0886, -0.0881, -0.0883, -0.0872, -0.0881, -0.0886, -0.0886,\n",
       "                          -0.0862, -0.0886, -0.0862, -0.0849, -0.0877, -0.0883, -0.0872, -0.0866,\n",
       "                          -0.0885, -0.0883, -0.0875, -0.0866, -0.0881, -0.0878, -0.0861, -0.0880,\n",
       "                          -0.0878, -0.0871, -0.0865, -0.0887, -0.0886, -0.0871, -0.0872, -0.0871,\n",
       "                          -0.0882, -0.0865, -0.0868, -0.0885, -0.0878, -0.0868, -0.0878, -0.0880,\n",
       "                          -0.0860, -0.0860, -0.0837, -0.0882, -0.0874, -0.0889, -0.0873, -0.0873,\n",
       "                          -0.0872, -0.0875, -0.0868, -0.0841, -0.0871, -0.0879, -0.0873, -0.0862],\n",
       "                         device='cuda:0'), max_val=tensor([0.0830, 0.0875, 0.0875, 0.0883, 0.0830, 0.0833, 0.0881, 0.0867, 0.0875,\n",
       "                          0.0878, 0.0879, 0.0830, 0.0815, 0.0865, 0.0871, 0.0880, 0.0879, 0.0874,\n",
       "                          0.0884, 0.0864, 0.0851, 0.0886, 0.0882, 0.0877, 0.0880, 0.0868, 0.0879,\n",
       "                          0.0849, 0.0862, 0.0871, 0.0885, 0.0857, 0.0882, 0.0837, 0.0801, 0.0870,\n",
       "                          0.0873, 0.0881, 0.0878, 0.0861, 0.0881, 0.0853, 0.0877, 0.0872, 0.0881,\n",
       "                          0.0882, 0.0883, 0.0879, 0.0827, 0.0880, 0.0883, 0.0876, 0.0874, 0.0881,\n",
       "                          0.0854, 0.0882, 0.0873, 0.0865, 0.0880, 0.0869, 0.0871, 0.0873, 0.0874,\n",
       "                          0.0887, 0.0886, 0.0857, 0.0858, 0.0881, 0.0866, 0.0836, 0.0876, 0.0882,\n",
       "                          0.0872, 0.0882, 0.0871, 0.0881, 0.0815, 0.0877, 0.0847, 0.0872, 0.0808,\n",
       "                          0.0863, 0.0873, 0.0872, 0.0878, 0.0866, 0.0862, 0.0887, 0.0863, 0.0871,\n",
       "                          0.0835, 0.0877, 0.0880, 0.0855, 0.0880, 0.0880, 0.0878, 0.0883, 0.0878,\n",
       "                          0.0876, 0.0877, 0.0857, 0.0873, 0.0884, 0.0867, 0.0858, 0.0875, 0.0871,\n",
       "                          0.0874, 0.0872, 0.0848, 0.0881, 0.0881, 0.0878, 0.0834, 0.0836, 0.0878,\n",
       "                          0.0889, 0.0872, 0.0842, 0.0874, 0.0888, 0.0871, 0.0882, 0.0860, 0.0871,\n",
       "                          0.0879, 0.0866], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0807], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.151749610900879, max_val=5.09750509262085)\n",
       "              )\n",
       "            )\n",
       "            (W_K): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0882, -0.0872, -0.0860, -0.0858, -0.0875, -0.0872, -0.0870, -0.0871,\n",
       "                          -0.0843, -0.0857, -0.0885, -0.0884, -0.0862, -0.0870, -0.0883, -0.0861,\n",
       "                          -0.0881, -0.0867, -0.0861, -0.0869, -0.0887, -0.0866, -0.0881, -0.0870,\n",
       "                          -0.0847, -0.0826, -0.0888, -0.0870, -0.0873, -0.0885, -0.0856, -0.0867,\n",
       "                          -0.0851, -0.0875, -0.0864, -0.0875, -0.0867, -0.0873, -0.0886, -0.0864,\n",
       "                          -0.0878, -0.0866, -0.0879, -0.0881, -0.0854, -0.0868, -0.0872, -0.0877,\n",
       "                          -0.0883, -0.0837, -0.0873, -0.0878, -0.0835, -0.0853, -0.0861, -0.0882,\n",
       "                          -0.0863, -0.0836, -0.0880, -0.0863, -0.0874, -0.0873, -0.0871, -0.0866,\n",
       "                          -0.0884, -0.0865, -0.0881, -0.0839, -0.0887, -0.0871, -0.0873, -0.0873,\n",
       "                          -0.0873, -0.0865, -0.0838, -0.0874, -0.0872, -0.0888, -0.0876, -0.0872,\n",
       "                          -0.0872, -0.0868, -0.0885, -0.0844, -0.0883, -0.0821, -0.0881, -0.0866,\n",
       "                          -0.0874, -0.0872, -0.0861, -0.0860, -0.0862, -0.0886, -0.0851, -0.0880,\n",
       "                          -0.0881, -0.0883, -0.0877, -0.0871, -0.0888, -0.0867, -0.0887, -0.0877,\n",
       "                          -0.0883, -0.0875, -0.0874, -0.0852, -0.0856, -0.0860, -0.0887, -0.0833,\n",
       "                          -0.0886, -0.0873, -0.0885, -0.0884, -0.0815, -0.0871, -0.0862, -0.0840,\n",
       "                          -0.0882, -0.0862, -0.0872, -0.0882, -0.0867, -0.0886, -0.0882, -0.0867],\n",
       "                         device='cuda:0'), max_val=tensor([0.0841, 0.0886, 0.0882, 0.0855, 0.0849, 0.0868, 0.0847, 0.0855, 0.0867,\n",
       "                          0.0871, 0.0875, 0.0873, 0.0866, 0.0864, 0.0882, 0.0866, 0.0846, 0.0875,\n",
       "                          0.0873, 0.0883, 0.0885, 0.0875, 0.0879, 0.0879, 0.0850, 0.0831, 0.0885,\n",
       "                          0.0827, 0.0868, 0.0871, 0.0851, 0.0878, 0.0878, 0.0873, 0.0848, 0.0878,\n",
       "                          0.0872, 0.0862, 0.0881, 0.0864, 0.0879, 0.0879, 0.0879, 0.0869, 0.0856,\n",
       "                          0.0882, 0.0880, 0.0882, 0.0883, 0.0884, 0.0839, 0.0866, 0.0879, 0.0867,\n",
       "                          0.0876, 0.0862, 0.0852, 0.0866, 0.0832, 0.0885, 0.0873, 0.0835, 0.0884,\n",
       "                          0.0884, 0.0875, 0.0862, 0.0848, 0.0875, 0.0876, 0.0875, 0.0884, 0.0886,\n",
       "                          0.0876, 0.0888, 0.0884, 0.0879, 0.0875, 0.0880, 0.0867, 0.0876, 0.0884,\n",
       "                          0.0877, 0.0835, 0.0886, 0.0853, 0.0869, 0.0888, 0.0877, 0.0879, 0.0880,\n",
       "                          0.0880, 0.0861, 0.0879, 0.0874, 0.0859, 0.0840, 0.0886, 0.0858, 0.0886,\n",
       "                          0.0865, 0.0880, 0.0868, 0.0863, 0.0879, 0.0882, 0.0860, 0.0878, 0.0880,\n",
       "                          0.0878, 0.0876, 0.0874, 0.0880, 0.0885, 0.0881, 0.0877, 0.0882, 0.0884,\n",
       "                          0.0878, 0.0880, 0.0889, 0.0875, 0.0871, 0.0868, 0.0868, 0.0876, 0.0869,\n",
       "                          0.0854, 0.0882], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0795], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.096560955047607, max_val=5.00372314453125)\n",
       "              )\n",
       "            )\n",
       "            (W_V): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0872, -0.0885, -0.0866, -0.0870, -0.0847, -0.0880, -0.0883, -0.0878,\n",
       "                          -0.0879, -0.0879, -0.0880, -0.0862, -0.0864, -0.0863, -0.0865, -0.0869,\n",
       "                          -0.0875, -0.0869, -0.0887, -0.0886, -0.0879, -0.0880, -0.0873, -0.0878,\n",
       "                          -0.0879, -0.0864, -0.0855, -0.0877, -0.0870, -0.0865, -0.0888, -0.0865,\n",
       "                          -0.0860, -0.0881, -0.0881, -0.0860, -0.0873, -0.0862, -0.0883, -0.0863,\n",
       "                          -0.0879, -0.0861, -0.0870, -0.0885, -0.0883, -0.0885, -0.0849, -0.0874,\n",
       "                          -0.0861, -0.0858, -0.0869, -0.0880, -0.0859, -0.0869, -0.0876, -0.0884,\n",
       "                          -0.0860, -0.0877, -0.0871, -0.0880, -0.0869, -0.0879, -0.0879, -0.0875,\n",
       "                          -0.0858, -0.0863, -0.0851, -0.0870, -0.0876, -0.0869, -0.0876, -0.0866,\n",
       "                          -0.0869, -0.0862, -0.0871, -0.0879, -0.0862, -0.0882, -0.0852, -0.0840,\n",
       "                          -0.0845, -0.0879, -0.0857, -0.0884, -0.0845, -0.0865, -0.0878, -0.0818,\n",
       "                          -0.0876, -0.0855, -0.0849, -0.0881, -0.0882, -0.0846, -0.0867, -0.0888,\n",
       "                          -0.0876, -0.0881, -0.0876, -0.0886, -0.0889, -0.0876, -0.0880, -0.0846,\n",
       "                          -0.0837, -0.0875, -0.0868, -0.0882, -0.0881, -0.0869, -0.0875, -0.0887,\n",
       "                          -0.0874, -0.0857, -0.0845, -0.0869, -0.0867, -0.0862, -0.0884, -0.0854,\n",
       "                          -0.0854, -0.0876, -0.0880, -0.0881, -0.0876, -0.0880, -0.0861, -0.0882],\n",
       "                         device='cuda:0'), max_val=tensor([0.0874, 0.0876, 0.0881, 0.0878, 0.0867, 0.0850, 0.0877, 0.0877, 0.0869,\n",
       "                          0.0882, 0.0862, 0.0875, 0.0879, 0.0869, 0.0874, 0.0872, 0.0883, 0.0825,\n",
       "                          0.0878, 0.0880, 0.0883, 0.0885, 0.0875, 0.0878, 0.0821, 0.0878, 0.0883,\n",
       "                          0.0877, 0.0872, 0.0877, 0.0869, 0.0885, 0.0887, 0.0856, 0.0881, 0.0878,\n",
       "                          0.0873, 0.0877, 0.0829, 0.0866, 0.0841, 0.0875, 0.0882, 0.0877, 0.0866,\n",
       "                          0.0878, 0.0873, 0.0878, 0.0862, 0.0889, 0.0870, 0.0879, 0.0863, 0.0868,\n",
       "                          0.0879, 0.0857, 0.0880, 0.0865, 0.0866, 0.0874, 0.0850, 0.0865, 0.0872,\n",
       "                          0.0890, 0.0867, 0.0864, 0.0869, 0.0870, 0.0877, 0.0862, 0.0879, 0.0870,\n",
       "                          0.0885, 0.0867, 0.0869, 0.0878, 0.0866, 0.0872, 0.0839, 0.0862, 0.0879,\n",
       "                          0.0882, 0.0881, 0.0890, 0.0888, 0.0856, 0.0877, 0.0883, 0.0885, 0.0881,\n",
       "                          0.0884, 0.0879, 0.0878, 0.0878, 0.0885, 0.0882, 0.0872, 0.0874, 0.0874,\n",
       "                          0.0865, 0.0887, 0.0878, 0.0872, 0.0873, 0.0874, 0.0863, 0.0862, 0.0866,\n",
       "                          0.0876, 0.0869, 0.0882, 0.0877, 0.0876, 0.0880, 0.0884, 0.0856, 0.0864,\n",
       "                          0.0888, 0.0870, 0.0880, 0.0867, 0.0883, 0.0879, 0.0883, 0.0827, 0.0867,\n",
       "                          0.0876, 0.0871], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0858], device='cuda:0'), zero_point=tensor([66], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.6306610107421875, max_val=5.265841484069824)\n",
       "              )\n",
       "            )\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(\n",
       "                in_features=128, out_features=128, bias=True\n",
       "                (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                  (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                    min_val=tensor([-0.0888, -0.0859, -0.0882, -0.0881, -0.0884, -0.0863, -0.0880, -0.0880,\n",
       "                            -0.0871, -0.0886, -0.0887, -0.0866, -0.0868, -0.0882, -0.0856, -0.0837,\n",
       "                            -0.0878, -0.0859, -0.0877, -0.0885, -0.0883, -0.0867, -0.0873, -0.0855,\n",
       "                            -0.0878, -0.0852, -0.0866, -0.0844, -0.0840, -0.0867, -0.0886, -0.0837,\n",
       "                            -0.0883, -0.0882, -0.0877, -0.0852, -0.0885, -0.0882, -0.0866, -0.0879,\n",
       "                            -0.0880, -0.0857, -0.0871, -0.0860, -0.0865, -0.0863, -0.0882, -0.0871,\n",
       "                            -0.0877, -0.0859, -0.0879, -0.0880, -0.0886, -0.0872, -0.0883, -0.0882,\n",
       "                            -0.0835, -0.0863, -0.0837, -0.0848, -0.0880, -0.0818, -0.0863, -0.0870,\n",
       "                            -0.0869, -0.0886, -0.0874, -0.0886, -0.0854, -0.0880, -0.0876, -0.0868,\n",
       "                            -0.0860, -0.0835, -0.0877, -0.0867, -0.0885, -0.0875, -0.0880, -0.0878,\n",
       "                            -0.0869, -0.0883, -0.0879, -0.0852, -0.0855, -0.0876, -0.0874, -0.0880,\n",
       "                            -0.0844, -0.0869, -0.0860, -0.0868, -0.0844, -0.0874, -0.0883, -0.0841,\n",
       "                            -0.0884, -0.0867, -0.0880, -0.0874, -0.0875, -0.0872, -0.0881, -0.0884,\n",
       "                            -0.0878, -0.0878, -0.0841, -0.0874, -0.0841, -0.0874, -0.0881, -0.0887,\n",
       "                            -0.0865, -0.0882, -0.0878, -0.0861, -0.0865, -0.0868, -0.0877, -0.0877,\n",
       "                            -0.0886, -0.0861, -0.0881, -0.0827, -0.0866, -0.0862, -0.0878, -0.0875],\n",
       "                           device='cuda:0'), max_val=tensor([0.0876, 0.0882, 0.0833, 0.0880, 0.0864, 0.0877, 0.0878, 0.0875, 0.0882,\n",
       "                            0.0877, 0.0879, 0.0844, 0.0847, 0.0851, 0.0880, 0.0887, 0.0882, 0.0867,\n",
       "                            0.0876, 0.0858, 0.0856, 0.0885, 0.0864, 0.0880, 0.0869, 0.0872, 0.0872,\n",
       "                            0.0877, 0.0873, 0.0870, 0.0875, 0.0857, 0.0865, 0.0848, 0.0860, 0.0879,\n",
       "                            0.0884, 0.0880, 0.0873, 0.0869, 0.0869, 0.0869, 0.0879, 0.0884, 0.0872,\n",
       "                            0.0852, 0.0876, 0.0883, 0.0881, 0.0880, 0.0868, 0.0880, 0.0862, 0.0882,\n",
       "                            0.0874, 0.0880, 0.0867, 0.0862, 0.0870, 0.0881, 0.0864, 0.0880, 0.0879,\n",
       "                            0.0869, 0.0873, 0.0884, 0.0862, 0.0886, 0.0876, 0.0875, 0.0853, 0.0872,\n",
       "                            0.0884, 0.0852, 0.0872, 0.0887, 0.0854, 0.0868, 0.0875, 0.0817, 0.0885,\n",
       "                            0.0884, 0.0889, 0.0867, 0.0881, 0.0880, 0.0883, 0.0880, 0.0833, 0.0884,\n",
       "                            0.0881, 0.0866, 0.0880, 0.0865, 0.0880, 0.0865, 0.0861, 0.0861, 0.0845,\n",
       "                            0.0880, 0.0858, 0.0882, 0.0879, 0.0879, 0.0872, 0.0879, 0.0865, 0.0882,\n",
       "                            0.0875, 0.0881, 0.0881, 0.0880, 0.0856, 0.0860, 0.0884, 0.0875, 0.0888,\n",
       "                            0.0872, 0.0863, 0.0886, 0.0868, 0.0859, 0.0875, 0.0848, 0.0875, 0.0874,\n",
       "                            0.0851, 0.0874], device='cuda:0')\n",
       "                  )\n",
       "                )\n",
       "                (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0206], device='cuda:0'), zero_point=tensor([66], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3543424606323242, max_val=1.2573257684707642)\n",
       "                )\n",
       "              )\n",
       "              (1): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0874, -0.0865, -0.0886, -0.0875, -0.0865, -0.0868, -0.0856, -0.0875,\n",
       "                          -0.0883, -0.0882, -0.0869, -0.0874, -0.0888, -0.0848, -0.0872, -0.0882,\n",
       "                          -0.0879, -0.0852, -0.0874, -0.0839, -0.0883, -0.0882, -0.0874, -0.0878,\n",
       "                          -0.0881, -0.0882, -0.0876, -0.0796, -0.0862, -0.0882, -0.0871, -0.0877,\n",
       "                          -0.0876, -0.0885, -0.0881, -0.0879, -0.0879, -0.0858, -0.0883, -0.0879,\n",
       "                          -0.0874, -0.0870, -0.0833, -0.0879, -0.0876, -0.0877, -0.0885, -0.0844,\n",
       "                          -0.0885, -0.0871, -0.0877, -0.0881, -0.0891, -0.0864, -0.0873, -0.0886,\n",
       "                          -0.0877, -0.0875, -0.0877, -0.0867, -0.0888, -0.0828, -0.0885, -0.0876,\n",
       "                          -0.0886, -0.0876, -0.0850, -0.0889, -0.0889, -0.0884, -0.0848, -0.0880,\n",
       "                          -0.0886, -0.0859, -0.0881, -0.0883, -0.0882, -0.0862, -0.0873, -0.0860,\n",
       "                          -0.0875, -0.0880, -0.0868, -0.0882, -0.0888, -0.0842, -0.0876, -0.0875,\n",
       "                          -0.0869, -0.0889, -0.0884, -0.0876, -0.0875, -0.0856, -0.0882, -0.0881,\n",
       "                          -0.0892, -0.0871, -0.0871, -0.0855, -0.0869, -0.0876, -0.0881, -0.0872,\n",
       "                          -0.0878, -0.0832, -0.0882, -0.0881, -0.0872, -0.0856, -0.0883, -0.0883,\n",
       "                          -0.0886, -0.0844, -0.0870, -0.0876, -0.0839, -0.0885, -0.0884, -0.0875,\n",
       "                          -0.0889, -0.0850, -0.0875, -0.0878, -0.0868, -0.0870, -0.0850, -0.0857],\n",
       "                         device='cuda:0'), max_val=tensor([0.0881, 0.0880, 0.0886, 0.0877, 0.0880, 0.0871, 0.0828, 0.0882, 0.0878,\n",
       "                          0.0876, 0.0871, 0.0850, 0.0888, 0.0882, 0.0866, 0.0881, 0.0855, 0.0882,\n",
       "                          0.0882, 0.0849, 0.0856, 0.0879, 0.0857, 0.0855, 0.0856, 0.0877, 0.0876,\n",
       "                          0.0891, 0.0877, 0.0886, 0.0885, 0.0860, 0.0862, 0.0878, 0.0874, 0.0886,\n",
       "                          0.0863, 0.0880, 0.0881, 0.0874, 0.0874, 0.0882, 0.0878, 0.0818, 0.0863,\n",
       "                          0.0859, 0.0873, 0.0872, 0.0865, 0.0851, 0.0869, 0.0885, 0.0874, 0.0869,\n",
       "                          0.0873, 0.0881, 0.0880, 0.0879, 0.0879, 0.0886, 0.0849, 0.0866, 0.0880,\n",
       "                          0.0876, 0.0887, 0.0879, 0.0885, 0.0882, 0.0835, 0.0870, 0.0885, 0.0878,\n",
       "                          0.0876, 0.0839, 0.0859, 0.0882, 0.0861, 0.0853, 0.0882, 0.0860, 0.0864,\n",
       "                          0.0881, 0.0880, 0.0857, 0.0880, 0.0852, 0.0873, 0.0879, 0.0886, 0.0865,\n",
       "                          0.0868, 0.0881, 0.0870, 0.0860, 0.0865, 0.0853, 0.0884, 0.0851, 0.0862,\n",
       "                          0.0885, 0.0877, 0.0860, 0.0879, 0.0879, 0.0857, 0.0888, 0.0878, 0.0885,\n",
       "                          0.0883, 0.0867, 0.0871, 0.0875, 0.0876, 0.0859, 0.0885, 0.0877, 0.0877,\n",
       "                          0.0874, 0.0882, 0.0875, 0.0880, 0.0880, 0.0867, 0.0873, 0.0882, 0.0874,\n",
       "                          0.0877, 0.0865], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0763], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.869352340698242, max_val=4.8250651359558105)\n",
       "              )\n",
       "            )\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.3, inplace=False)\n",
       "            (3): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0858, -0.0874, -0.0832, -0.0875, -0.0878, -0.0849, -0.0880, -0.0857,\n",
       "                          -0.0865, -0.0873, -0.0884, -0.0842, -0.0877, -0.0867, -0.0883, -0.0887,\n",
       "                          -0.0881, -0.0878, -0.0872, -0.0862, -0.0865, -0.0878, -0.0871, -0.0859,\n",
       "                          -0.0873, -0.0876, -0.0879, -0.0865, -0.0870, -0.0871, -0.0875, -0.0869,\n",
       "                          -0.0865, -0.0882, -0.0876, -0.0881, -0.0869, -0.0876, -0.0878, -0.0869,\n",
       "                          -0.0879, -0.0866, -0.0886, -0.0854, -0.0860, -0.0866, -0.0878, -0.0860,\n",
       "                          -0.0884, -0.0874, -0.0873, -0.0878, -0.0876, -0.0876, -0.0865, -0.0872,\n",
       "                          -0.0865, -0.0885, -0.0866, -0.0874, -0.0880, -0.0865, -0.0874, -0.0883,\n",
       "                          -0.0870, -0.0874, -0.0872, -0.0881, -0.0819, -0.0856, -0.0868, -0.0855,\n",
       "                          -0.0869, -0.0873, -0.0831, -0.0879, -0.0861, -0.0876, -0.0878, -0.0879,\n",
       "                          -0.0882, -0.0845, -0.0885, -0.0880, -0.0858, -0.0886, -0.0875, -0.0870,\n",
       "                          -0.0868, -0.0875, -0.0841, -0.0866, -0.0870, -0.0886, -0.0881, -0.0877,\n",
       "                          -0.0887, -0.0801, -0.0868, -0.0824, -0.0875, -0.0879, -0.0875, -0.0881,\n",
       "                          -0.0844, -0.0872, -0.0847, -0.0875, -0.0878, -0.0880, -0.0878, -0.0867,\n",
       "                          -0.0884, -0.0870, -0.0864, -0.0873, -0.0866, -0.0886, -0.0880, -0.0860,\n",
       "                          -0.0882, -0.0876, -0.0870, -0.0874, -0.0866, -0.0879, -0.0837, -0.0867],\n",
       "                         device='cuda:0'), max_val=tensor([0.0855, 0.0843, 0.0868, 0.0858, 0.0868, 0.0851, 0.0886, 0.0884, 0.0885,\n",
       "                          0.0888, 0.0875, 0.0836, 0.0872, 0.0873, 0.0869, 0.0867, 0.0860, 0.0861,\n",
       "                          0.0882, 0.0866, 0.0883, 0.0868, 0.0841, 0.0877, 0.0866, 0.0857, 0.0881,\n",
       "                          0.0864, 0.0878, 0.0878, 0.0877, 0.0870, 0.0872, 0.0876, 0.0866, 0.0881,\n",
       "                          0.0874, 0.0871, 0.0867, 0.0868, 0.0872, 0.0878, 0.0871, 0.0884, 0.0874,\n",
       "                          0.0876, 0.0858, 0.0863, 0.0866, 0.0885, 0.0879, 0.0862, 0.0870, 0.0869,\n",
       "                          0.0868, 0.0874, 0.0874, 0.0884, 0.0887, 0.0882, 0.0882, 0.0874, 0.0872,\n",
       "                          0.0872, 0.0802, 0.0870, 0.0867, 0.0860, 0.0884, 0.0832, 0.0882, 0.0866,\n",
       "                          0.0856, 0.0878, 0.0881, 0.0878, 0.0877, 0.0875, 0.0883, 0.0880, 0.0877,\n",
       "                          0.0886, 0.0857, 0.0873, 0.0879, 0.0869, 0.0862, 0.0880, 0.0859, 0.0882,\n",
       "                          0.0886, 0.0879, 0.0877, 0.0870, 0.0874, 0.0853, 0.0869, 0.0866, 0.0844,\n",
       "                          0.0888, 0.0883, 0.0878, 0.0887, 0.0869, 0.0884, 0.0878, 0.0818, 0.0880,\n",
       "                          0.0857, 0.0885, 0.0876, 0.0866, 0.0864, 0.0877, 0.0869, 0.0881, 0.0884,\n",
       "                          0.0885, 0.0882, 0.0877, 0.0873, 0.0864, 0.0881, 0.0851, 0.0877, 0.0850,\n",
       "                          0.0861, 0.0875], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0356], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2728095054626465, max_val=2.2543985843658447)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "        (2): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0867, -0.0887, -0.0839, -0.0885, -0.0888, -0.0874, -0.0889, -0.0882,\n",
       "                          -0.0878, -0.0816, -0.0873, -0.0887, -0.0869, -0.0867, -0.0876, -0.0878,\n",
       "                          -0.0874, -0.0854, -0.0891, -0.0877, -0.0886, -0.0864, -0.0881, -0.0863,\n",
       "                          -0.0873, -0.0884, -0.0859, -0.0856, -0.0853, -0.0873, -0.0865, -0.0862,\n",
       "                          -0.0860, -0.0845, -0.0847, -0.0875, -0.0876, -0.0879, -0.0878, -0.0876,\n",
       "                          -0.0862, -0.0877, -0.0873, -0.0885, -0.0864, -0.0875, -0.0886, -0.0883,\n",
       "                          -0.0858, -0.0871, -0.0870, -0.0872, -0.0862, -0.0885, -0.0879, -0.0860,\n",
       "                          -0.0875, -0.0881, -0.0871, -0.0878, -0.0851, -0.0885, -0.0884, -0.0872,\n",
       "                          -0.0847, -0.0876, -0.0881, -0.0872, -0.0875, -0.0854, -0.0885, -0.0885,\n",
       "                          -0.0870, -0.0856, -0.0877, -0.0884, -0.0876, -0.0860, -0.0879, -0.0879,\n",
       "                          -0.0883, -0.0870, -0.0877, -0.0864, -0.0862, -0.0868, -0.0882, -0.0867,\n",
       "                          -0.0862, -0.0882, -0.0860, -0.0882, -0.0879, -0.0876, -0.0864, -0.0888,\n",
       "                          -0.0888, -0.0853, -0.0838, -0.0851, -0.0873, -0.0845, -0.0871, -0.0836,\n",
       "                          -0.0874, -0.0848, -0.0879, -0.0870, -0.0861, -0.0876, -0.0882, -0.0859,\n",
       "                          -0.0865, -0.0882, -0.0882, -0.0872, -0.0881, -0.0878, -0.0870, -0.0880,\n",
       "                          -0.0875, -0.0885, -0.0884, -0.0873, -0.0882, -0.0884, -0.0883, -0.0883],\n",
       "                         device='cuda:0'), max_val=tensor([0.0882, 0.0867, 0.0869, 0.0885, 0.0854, 0.0874, 0.0879, 0.0875, 0.0884,\n",
       "                          0.0880, 0.0872, 0.0875, 0.0866, 0.0869, 0.0885, 0.0871, 0.0879, 0.0856,\n",
       "                          0.0858, 0.0842, 0.0842, 0.0864, 0.0862, 0.0875, 0.0862, 0.0882, 0.0879,\n",
       "                          0.0888, 0.0887, 0.0878, 0.0877, 0.0869, 0.0887, 0.0856, 0.0873, 0.0862,\n",
       "                          0.0877, 0.0872, 0.0866, 0.0847, 0.0877, 0.0846, 0.0879, 0.0876, 0.0882,\n",
       "                          0.0886, 0.0888, 0.0877, 0.0872, 0.0809, 0.0881, 0.0884, 0.0865, 0.0873,\n",
       "                          0.0868, 0.0845, 0.0875, 0.0869, 0.0850, 0.0826, 0.0865, 0.0881, 0.0866,\n",
       "                          0.0868, 0.0878, 0.0862, 0.0874, 0.0879, 0.0876, 0.0881, 0.0848, 0.0867,\n",
       "                          0.0874, 0.0876, 0.0866, 0.0870, 0.0861, 0.0877, 0.0876, 0.0869, 0.0888,\n",
       "                          0.0866, 0.0873, 0.0866, 0.0873, 0.0879, 0.0881, 0.0877, 0.0874, 0.0890,\n",
       "                          0.0874, 0.0887, 0.0839, 0.0873, 0.0877, 0.0875, 0.0863, 0.0883, 0.0860,\n",
       "                          0.0859, 0.0813, 0.0867, 0.0871, 0.0853, 0.0875, 0.0878, 0.0863, 0.0861,\n",
       "                          0.0869, 0.0873, 0.0872, 0.0866, 0.0880, 0.0876, 0.0839, 0.0885, 0.0876,\n",
       "                          0.0880, 0.0854, 0.0881, 0.0882, 0.0878, 0.0869, 0.0861, 0.0883, 0.0826,\n",
       "                          0.0880, 0.0867], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0846], device='cuda:0'), zero_point=tensor([65], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.5016984939575195, max_val=5.240687370300293)\n",
       "              )\n",
       "            )\n",
       "            (W_K): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0873, -0.0878, -0.0873, -0.0867, -0.0879, -0.0869, -0.0840, -0.0877,\n",
       "                          -0.0887, -0.0863, -0.0854, -0.0862, -0.0876, -0.0874, -0.0866, -0.0882,\n",
       "                          -0.0873, -0.0888, -0.0886, -0.0871, -0.0885, -0.0879, -0.0888, -0.0877,\n",
       "                          -0.0886, -0.0862, -0.0871, -0.0831, -0.0878, -0.0881, -0.0878, -0.0871,\n",
       "                          -0.0881, -0.0841, -0.0836, -0.0871, -0.0873, -0.0876, -0.0876, -0.0883,\n",
       "                          -0.0860, -0.0872, -0.0871, -0.0863, -0.0883, -0.0825, -0.0881, -0.0866,\n",
       "                          -0.0850, -0.0853, -0.0876, -0.0886, -0.0875, -0.0872, -0.0879, -0.0888,\n",
       "                          -0.0879, -0.0879, -0.0845, -0.0799, -0.0883, -0.0871, -0.0868, -0.0852,\n",
       "                          -0.0875, -0.0882, -0.0878, -0.0878, -0.0880, -0.0877, -0.0833, -0.0878,\n",
       "                          -0.0865, -0.0879, -0.0882, -0.0852, -0.0888, -0.0870, -0.0867, -0.0855,\n",
       "                          -0.0876, -0.0869, -0.0871, -0.0862, -0.0883, -0.0867, -0.0872, -0.0872,\n",
       "                          -0.0875, -0.0867, -0.0868, -0.0852, -0.0860, -0.0873, -0.0871, -0.0883,\n",
       "                          -0.0886, -0.0873, -0.0866, -0.0866, -0.0875, -0.0879, -0.0868, -0.0881,\n",
       "                          -0.0877, -0.0876, -0.0873, -0.0871, -0.0861, -0.0884, -0.0869, -0.0836,\n",
       "                          -0.0886, -0.0852, -0.0874, -0.0847, -0.0865, -0.0883, -0.0849, -0.0866,\n",
       "                          -0.0875, -0.0848, -0.0876, -0.0872, -0.0863, -0.0874, -0.0877, -0.0865],\n",
       "                         device='cuda:0'), max_val=tensor([0.0829, 0.0865, 0.0877, 0.0883, 0.0880, 0.0878, 0.0873, 0.0870, 0.0864,\n",
       "                          0.0879, 0.0847, 0.0864, 0.0880, 0.0876, 0.0869, 0.0879, 0.0871, 0.0876,\n",
       "                          0.0881, 0.0888, 0.0863, 0.0877, 0.0874, 0.0880, 0.0876, 0.0877, 0.0876,\n",
       "                          0.0880, 0.0885, 0.0881, 0.0879, 0.0839, 0.0870, 0.0886, 0.0885, 0.0867,\n",
       "                          0.0867, 0.0882, 0.0869, 0.0872, 0.0880, 0.0884, 0.0858, 0.0852, 0.0877,\n",
       "                          0.0871, 0.0870, 0.0868, 0.0885, 0.0859, 0.0859, 0.0880, 0.0860, 0.0842,\n",
       "                          0.0880, 0.0882, 0.0883, 0.0879, 0.0878, 0.0880, 0.0866, 0.0857, 0.0873,\n",
       "                          0.0858, 0.0872, 0.0883, 0.0885, 0.0872, 0.0884, 0.0853, 0.0872, 0.0872,\n",
       "                          0.0883, 0.0882, 0.0878, 0.0875, 0.0889, 0.0876, 0.0887, 0.0870, 0.0872,\n",
       "                          0.0866, 0.0885, 0.0881, 0.0871, 0.0861, 0.0883, 0.0880, 0.0870, 0.0886,\n",
       "                          0.0868, 0.0879, 0.0866, 0.0865, 0.0887, 0.0879, 0.0855, 0.0879, 0.0874,\n",
       "                          0.0887, 0.0867, 0.0887, 0.0875, 0.0866, 0.0875, 0.0871, 0.0881, 0.0869,\n",
       "                          0.0868, 0.0879, 0.0874, 0.0873, 0.0862, 0.0880, 0.0887, 0.0885, 0.0884,\n",
       "                          0.0852, 0.0860, 0.0875, 0.0877, 0.0875, 0.0837, 0.0784, 0.0871, 0.0871,\n",
       "                          0.0884, 0.0877], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0790], device='cuda:0'), zero_point=tensor([65], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.11017370223999, max_val=4.924267292022705)\n",
       "              )\n",
       "            )\n",
       "            (W_V): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0871, -0.0873, -0.0879, -0.0888, -0.0871, -0.0885, -0.0867, -0.0880,\n",
       "                          -0.0889, -0.0867, -0.0866, -0.0882, -0.0845, -0.0872, -0.0881, -0.0870,\n",
       "                          -0.0881, -0.0881, -0.0867, -0.0880, -0.0871, -0.0870, -0.0855, -0.0890,\n",
       "                          -0.0879, -0.0818, -0.0852, -0.0872, -0.0870, -0.0878, -0.0879, -0.0872,\n",
       "                          -0.0883, -0.0883, -0.0882, -0.0887, -0.0884, -0.0879, -0.0869, -0.0879,\n",
       "                          -0.0839, -0.0888, -0.0836, -0.0871, -0.0872, -0.0873, -0.0878, -0.0875,\n",
       "                          -0.0858, -0.0877, -0.0873, -0.0881, -0.0872, -0.0867, -0.0880, -0.0867,\n",
       "                          -0.0873, -0.0861, -0.0863, -0.0847, -0.0881, -0.0873, -0.0864, -0.0873,\n",
       "                          -0.0869, -0.0868, -0.0870, -0.0875, -0.0865, -0.0877, -0.0878, -0.0876,\n",
       "                          -0.0865, -0.0875, -0.0852, -0.0862, -0.0841, -0.0869, -0.0859, -0.0838,\n",
       "                          -0.0864, -0.0883, -0.0855, -0.0873, -0.0871, -0.0875, -0.0888, -0.0861,\n",
       "                          -0.0885, -0.0883, -0.0870, -0.0884, -0.0879, -0.0882, -0.0884, -0.0856,\n",
       "                          -0.0872, -0.0843, -0.0829, -0.0862, -0.0870, -0.0879, -0.0853, -0.0877,\n",
       "                          -0.0874, -0.0875, -0.0839, -0.0878, -0.0876, -0.0884, -0.0868, -0.0864,\n",
       "                          -0.0884, -0.0878, -0.0885, -0.0878, -0.0879, -0.0879, -0.0884, -0.0847,\n",
       "                          -0.0855, -0.0850, -0.0882, -0.0870, -0.0853, -0.0838, -0.0870, -0.0836],\n",
       "                         device='cuda:0'), max_val=tensor([0.0851, 0.0864, 0.0879, 0.0872, 0.0843, 0.0879, 0.0880, 0.0850, 0.0858,\n",
       "                          0.0883, 0.0883, 0.0875, 0.0849, 0.0891, 0.0882, 0.0865, 0.0884, 0.0864,\n",
       "                          0.0870, 0.0845, 0.0861, 0.0859, 0.0876, 0.0888, 0.0875, 0.0867, 0.0866,\n",
       "                          0.0882, 0.0869, 0.0853, 0.0878, 0.0886, 0.0859, 0.0851, 0.0876, 0.0879,\n",
       "                          0.0859, 0.0881, 0.0871, 0.0880, 0.0866, 0.0880, 0.0866, 0.0866, 0.0874,\n",
       "                          0.0880, 0.0868, 0.0876, 0.0880, 0.0876, 0.0881, 0.0875, 0.0877, 0.0881,\n",
       "                          0.0863, 0.0839, 0.0853, 0.0881, 0.0872, 0.0878, 0.0871, 0.0852, 0.0871,\n",
       "                          0.0870, 0.0884, 0.0871, 0.0870, 0.0888, 0.0882, 0.0830, 0.0874, 0.0879,\n",
       "                          0.0879, 0.0872, 0.0842, 0.0882, 0.0876, 0.0876, 0.0881, 0.0886, 0.0878,\n",
       "                          0.0882, 0.0876, 0.0863, 0.0872, 0.0884, 0.0878, 0.0851, 0.0884, 0.0880,\n",
       "                          0.0877, 0.0811, 0.0870, 0.0864, 0.0876, 0.0816, 0.0874, 0.0862, 0.0872,\n",
       "                          0.0889, 0.0884, 0.0878, 0.0872, 0.0872, 0.0846, 0.0867, 0.0880, 0.0875,\n",
       "                          0.0861, 0.0887, 0.0871, 0.0882, 0.0878, 0.0875, 0.0879, 0.0886, 0.0887,\n",
       "                          0.0880, 0.0822, 0.0882, 0.0866, 0.0879, 0.0868, 0.0876, 0.0871, 0.0873,\n",
       "                          0.0886, 0.0883], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0795], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.086848735809326, max_val=5.010912895202637)\n",
       "              )\n",
       "            )\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(\n",
       "                in_features=128, out_features=128, bias=True\n",
       "                (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                          0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                          0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                  (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                    min_val=tensor([-0.0858, -0.0875, -0.0856, -0.0861, -0.0850, -0.0876, -0.0871, -0.0876,\n",
       "                            -0.0877, -0.0858, -0.0833, -0.0883, -0.0854, -0.0858, -0.0857, -0.0883,\n",
       "                            -0.0880, -0.0889, -0.0873, -0.0847, -0.0872, -0.0877, -0.0880, -0.0884,\n",
       "                            -0.0869, -0.0882, -0.0878, -0.0877, -0.0873, -0.0884, -0.0859, -0.0867,\n",
       "                            -0.0874, -0.0883, -0.0859, -0.0874, -0.0862, -0.0873, -0.0885, -0.0872,\n",
       "                            -0.0879, -0.0883, -0.0873, -0.0866, -0.0816, -0.0878, -0.0852, -0.0848,\n",
       "                            -0.0885, -0.0865, -0.0843, -0.0827, -0.0863, -0.0861, -0.0863, -0.0880,\n",
       "                            -0.0876, -0.0885, -0.0839, -0.0881, -0.0875, -0.0879, -0.0880, -0.0877,\n",
       "                            -0.0877, -0.0842, -0.0868, -0.0879, -0.0878, -0.0878, -0.0859, -0.0875,\n",
       "                            -0.0853, -0.0881, -0.0856, -0.0842, -0.0841, -0.0876, -0.0857, -0.0882,\n",
       "                            -0.0884, -0.0863, -0.0870, -0.0877, -0.0872, -0.0884, -0.0871, -0.0869,\n",
       "                            -0.0855, -0.0890, -0.0881, -0.0877, -0.0855, -0.0839, -0.0879, -0.0880,\n",
       "                            -0.0851, -0.0877, -0.0883, -0.0878, -0.0883, -0.0886, -0.0848, -0.0855,\n",
       "                            -0.0878, -0.0880, -0.0828, -0.0873, -0.0843, -0.0881, -0.0877, -0.0865,\n",
       "                            -0.0878, -0.0873, -0.0888, -0.0871, -0.0869, -0.0879, -0.0883, -0.0863,\n",
       "                            -0.0879, -0.0837, -0.0882, -0.0870, -0.0881, -0.0867, -0.0884, -0.0867],\n",
       "                           device='cuda:0'), max_val=tensor([0.0873, 0.0866, 0.0863, 0.0831, 0.0885, 0.0876, 0.0875, 0.0846, 0.0879,\n",
       "                            0.0880, 0.0890, 0.0864, 0.0879, 0.0879, 0.0879, 0.0888, 0.0879, 0.0869,\n",
       "                            0.0880, 0.0878, 0.0884, 0.0876, 0.0855, 0.0825, 0.0882, 0.0881, 0.0863,\n",
       "                            0.0880, 0.0847, 0.0878, 0.0862, 0.0855, 0.0865, 0.0881, 0.0885, 0.0868,\n",
       "                            0.0884, 0.0878, 0.0861, 0.0840, 0.0882, 0.0853, 0.0876, 0.0871, 0.0888,\n",
       "                            0.0873, 0.0862, 0.0870, 0.0873, 0.0881, 0.0885, 0.0872, 0.0870, 0.0854,\n",
       "                            0.0886, 0.0885, 0.0877, 0.0878, 0.0869, 0.0862, 0.0855, 0.0861, 0.0878,\n",
       "                            0.0878, 0.0870, 0.0869, 0.0860, 0.0886, 0.0857, 0.0827, 0.0872, 0.0867,\n",
       "                            0.0872, 0.0881, 0.0888, 0.0839, 0.0865, 0.0841, 0.0877, 0.0871, 0.0875,\n",
       "                            0.0843, 0.0838, 0.0876, 0.0877, 0.0879, 0.0864, 0.0880, 0.0862, 0.0878,\n",
       "                            0.0884, 0.0874, 0.0876, 0.0885, 0.0884, 0.0883, 0.0880, 0.0883, 0.0876,\n",
       "                            0.0879, 0.0854, 0.0865, 0.0861, 0.0870, 0.0866, 0.0887, 0.0878, 0.0881,\n",
       "                            0.0877, 0.0865, 0.0868, 0.0877, 0.0867, 0.0876, 0.0860, 0.0871, 0.0871,\n",
       "                            0.0864, 0.0857, 0.0832, 0.0885, 0.0870, 0.0875, 0.0858, 0.0863, 0.0868,\n",
       "                            0.0876, 0.0849], device='cuda:0')\n",
       "                  )\n",
       "                )\n",
       "                (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0245], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5589970350265503, max_val=1.5534934997558594)\n",
       "                )\n",
       "              )\n",
       "              (1): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0872, -0.0876, -0.0868, -0.0874, -0.0875, -0.0865, -0.0880, -0.0875,\n",
       "                          -0.0877, -0.0861, -0.0887, -0.0874, -0.0874, -0.0878, -0.0874, -0.0882,\n",
       "                          -0.0872, -0.0856, -0.0872, -0.0875, -0.0878, -0.0882, -0.0887, -0.0887,\n",
       "                          -0.0820, -0.0821, -0.0881, -0.0890, -0.0877, -0.0878, -0.0876, -0.0874,\n",
       "                          -0.0878, -0.0882, -0.0880, -0.0887, -0.0880, -0.0869, -0.0875, -0.0858,\n",
       "                          -0.0871, -0.0860, -0.0863, -0.0872, -0.0868, -0.0872, -0.0862, -0.0879,\n",
       "                          -0.0878, -0.0859, -0.0854, -0.0883, -0.0832, -0.0891, -0.0875, -0.0866,\n",
       "                          -0.0840, -0.0873, -0.0887, -0.0858, -0.0878, -0.0875, -0.0872, -0.0886,\n",
       "                          -0.0872, -0.0875, -0.0877, -0.0885, -0.0883, -0.0879, -0.0873, -0.0859,\n",
       "                          -0.0886, -0.0873, -0.0860, -0.0850, -0.0878, -0.0870, -0.0870, -0.0880,\n",
       "                          -0.0868, -0.0882, -0.0887, -0.0868, -0.0884, -0.0878, -0.0877, -0.0877,\n",
       "                          -0.0874, -0.0874, -0.0868, -0.0882, -0.0880, -0.0869, -0.0888, -0.0850,\n",
       "                          -0.0881, -0.0877, -0.0875, -0.0867, -0.0869, -0.0870, -0.0871, -0.0845,\n",
       "                          -0.0884, -0.0878, -0.0872, -0.0820, -0.0877, -0.0841, -0.0872, -0.0876,\n",
       "                          -0.0879, -0.0874, -0.0885, -0.0865, -0.0818, -0.0860, -0.0875, -0.0882,\n",
       "                          -0.0878, -0.0873, -0.0876, -0.0837, -0.0885, -0.0875, -0.0875, -0.0874],\n",
       "                         device='cuda:0'), max_val=tensor([0.0865, 0.0877, 0.0888, 0.0871, 0.0874, 0.0874, 0.0821, 0.0888, 0.0879,\n",
       "                          0.0878, 0.0877, 0.0875, 0.0877, 0.0815, 0.0838, 0.0862, 0.0878, 0.0868,\n",
       "                          0.0886, 0.0872, 0.0884, 0.0883, 0.0866, 0.0879, 0.0887, 0.0868, 0.0862,\n",
       "                          0.0874, 0.0881, 0.0877, 0.0880, 0.0874, 0.0882, 0.0882, 0.0880, 0.0871,\n",
       "                          0.0881, 0.0878, 0.0880, 0.0867, 0.0886, 0.0867, 0.0867, 0.0873, 0.0875,\n",
       "                          0.0858, 0.0866, 0.0871, 0.0863, 0.0876, 0.0852, 0.0870, 0.0872, 0.0879,\n",
       "                          0.0877, 0.0870, 0.0853, 0.0866, 0.0885, 0.0842, 0.0882, 0.0878, 0.0858,\n",
       "                          0.0875, 0.0847, 0.0875, 0.0887, 0.0875, 0.0866, 0.0880, 0.0885, 0.0868,\n",
       "                          0.0883, 0.0850, 0.0873, 0.0886, 0.0883, 0.0849, 0.0876, 0.0872, 0.0849,\n",
       "                          0.0867, 0.0874, 0.0879, 0.0870, 0.0884, 0.0888, 0.0877, 0.0888, 0.0846,\n",
       "                          0.0862, 0.0881, 0.0878, 0.0868, 0.0872, 0.0874, 0.0883, 0.0886, 0.0860,\n",
       "                          0.0866, 0.0885, 0.0843, 0.0827, 0.0889, 0.0868, 0.0868, 0.0883, 0.0874,\n",
       "                          0.0873, 0.0880, 0.0873, 0.0882, 0.0879, 0.0886, 0.0873, 0.0887, 0.0881,\n",
       "                          0.0804, 0.0832, 0.0857, 0.0831, 0.0873, 0.0882, 0.0885, 0.0852, 0.0878,\n",
       "                          0.0860, 0.0866], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0825], device='cuda:0'), zero_point=tensor([62], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.148969650268555, max_val=5.331402778625488)\n",
       "              )\n",
       "            )\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.3, inplace=False)\n",
       "            (3): Linear(\n",
       "              in_features=128, out_features=128, bias=True\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                        0.0007, 0.0007], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "                  min_val=tensor([-0.0877, -0.0856, -0.0868, -0.0868, -0.0858, -0.0872, -0.0885, -0.0890,\n",
       "                          -0.0873, -0.0873, -0.0879, -0.0875, -0.0888, -0.0880, -0.0885, -0.0882,\n",
       "                          -0.0880, -0.0873, -0.0875, -0.0874, -0.0876, -0.0882, -0.0878, -0.0861,\n",
       "                          -0.0860, -0.0875, -0.0824, -0.0875, -0.0875, -0.0872, -0.0877, -0.0865,\n",
       "                          -0.0878, -0.0856, -0.0872, -0.0882, -0.0880, -0.0883, -0.0861, -0.0871,\n",
       "                          -0.0882, -0.0863, -0.0888, -0.0883, -0.0891, -0.0865, -0.0847, -0.0874,\n",
       "                          -0.0857, -0.0873, -0.0871, -0.0875, -0.0878, -0.0862, -0.0884, -0.0827,\n",
       "                          -0.0879, -0.0885, -0.0884, -0.0883, -0.0871, -0.0872, -0.0878, -0.0869,\n",
       "                          -0.0875, -0.0885, -0.0850, -0.0879, -0.0838, -0.0873, -0.0876, -0.0880,\n",
       "                          -0.0828, -0.0881, -0.0881, -0.0867, -0.0849, -0.0866, -0.0887, -0.0883,\n",
       "                          -0.0873, -0.0890, -0.0883, -0.0869, -0.0875, -0.0858, -0.0852, -0.0883,\n",
       "                          -0.0857, -0.0840, -0.0828, -0.0882, -0.0881, -0.0854, -0.0868, -0.0876,\n",
       "                          -0.0874, -0.0886, -0.0855, -0.0818, -0.0880, -0.0887, -0.0843, -0.0868,\n",
       "                          -0.0861, -0.0861, -0.0884, -0.0850, -0.0850, -0.0872, -0.0887, -0.0849,\n",
       "                          -0.0868, -0.0881, -0.0880, -0.0884, -0.0876, -0.0871, -0.0872, -0.0870,\n",
       "                          -0.0859, -0.0883, -0.0821, -0.0886, -0.0889, -0.0887, -0.0879, -0.0857],\n",
       "                         device='cuda:0'), max_val=tensor([0.0842, 0.0890, 0.0877, 0.0881, 0.0835, 0.0885, 0.0872, 0.0883, 0.0882,\n",
       "                          0.0882, 0.0856, 0.0872, 0.0855, 0.0879, 0.0885, 0.0875, 0.0879, 0.0870,\n",
       "                          0.0878, 0.0874, 0.0879, 0.0850, 0.0836, 0.0865, 0.0882, 0.0809, 0.0879,\n",
       "                          0.0849, 0.0867, 0.0867, 0.0870, 0.0872, 0.0879, 0.0871, 0.0877, 0.0857,\n",
       "                          0.0879, 0.0875, 0.0879, 0.0878, 0.0854, 0.0884, 0.0879, 0.0881, 0.0881,\n",
       "                          0.0850, 0.0863, 0.0869, 0.0880, 0.0868, 0.0871, 0.0840, 0.0876, 0.0882,\n",
       "                          0.0887, 0.0880, 0.0880, 0.0864, 0.0869, 0.0865, 0.0859, 0.0854, 0.0877,\n",
       "                          0.0880, 0.0876, 0.0840, 0.0882, 0.0862, 0.0881, 0.0858, 0.0885, 0.0890,\n",
       "                          0.0877, 0.0833, 0.0873, 0.0886, 0.0870, 0.0870, 0.0880, 0.0875, 0.0864,\n",
       "                          0.0843, 0.0875, 0.0871, 0.0869, 0.0855, 0.0855, 0.0885, 0.0879, 0.0871,\n",
       "                          0.0871, 0.0871, 0.0875, 0.0882, 0.0878, 0.0876, 0.0877, 0.0886, 0.0878,\n",
       "                          0.0875, 0.0884, 0.0872, 0.0873, 0.0878, 0.0860, 0.0827, 0.0878, 0.0871,\n",
       "                          0.0871, 0.0876, 0.0875, 0.0866, 0.0881, 0.0846, 0.0872, 0.0873, 0.0808,\n",
       "                          0.0880, 0.0882, 0.0867, 0.0879, 0.0876, 0.0881, 0.0874, 0.0871, 0.0875,\n",
       "                          0.0880, 0.0865], device='cuda:0')\n",
       "                )\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0400], device='cuda:0'), zero_point=tensor([63], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5062766075134277, max_val=2.5784480571746826)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (dropout_ffn): Dropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Flatten_Head(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): Linear(\n",
       "      in_features=5248, out_features=96, bias=True\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001], device='cuda:0'), zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "               device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(\n",
       "          min_val=tensor([-0.0141, -0.0142, -0.0142, -0.0142, -0.0142, -0.0141, -0.0142, -0.0142,\n",
       "                  -0.0142, -0.0142, -0.0142, -0.0141, -0.0142, -0.0142, -0.0142, -0.0141,\n",
       "                  -0.0142, -0.0142, -0.0141, -0.0142, -0.0142, -0.0141, -0.0142, -0.0142,\n",
       "                  -0.0141, -0.0142, -0.0141, -0.0141, -0.0141, -0.0141, -0.0142, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0142,\n",
       "                  -0.0141, -0.0141, -0.0142, -0.0141, -0.0141, -0.0142, -0.0141, -0.0141,\n",
       "                  -0.0142, -0.0142, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141,\n",
       "                  -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141, -0.0141],\n",
       "                 device='cuda:0'), max_val=tensor([0.0140, 0.0141, 0.0141, 0.0141, 0.0141, 0.0140, 0.0140, 0.0141, 0.0141,\n",
       "                  0.0141, 0.0141, 0.0140, 0.0141, 0.0141, 0.0141, 0.0140, 0.0141, 0.0141,\n",
       "                  0.0141, 0.0141, 0.0141, 0.0140, 0.0140, 0.0141, 0.0140, 0.0141, 0.0141,\n",
       "                  0.0140, 0.0140, 0.0140, 0.0141, 0.0140, 0.0141, 0.0140, 0.0141, 0.0140,\n",
       "                  0.0140, 0.0141, 0.0140, 0.0140, 0.0140, 0.0141, 0.0141, 0.0140, 0.0140,\n",
       "                  0.0141, 0.0140, 0.0141, 0.0140, 0.0140, 0.0140, 0.0141, 0.0140, 0.0140,\n",
       "                  0.0140, 0.0140, 0.0141, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
       "                  0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
       "                  0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
       "                  0.0140, 0.0140, 0.0140, 0.0141, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
       "                  0.0140, 0.0140, 0.0141, 0.0140, 0.0140, 0.0141], device='cuda:0')\n",
       "        )\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0361], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3198821544647217, max_val=2.2663979530334473)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0718], device='cuda:0'), zero_point=tensor([64], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.6182541847229, max_val=4.50146484375)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_patchtst_model_fp32_prepared.eval()\n",
    "# q_patchtst_model_fp32_prepared.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/utils.py:339: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported qscheme: per_channel_affine",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m q_patchtst_model_int8 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mao\u001b[39m.\u001b[39mquantization\u001b[39m.\u001b[39mconvert(q_patchtst_model_fp32_prepared)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgreene-compute/scratch/ab10445/PatchTST/PatchTST_QAT.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m q_patchtst_model_int8\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:553\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n\u001b[1;32m    552\u001b[0m     module \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 553\u001b[0m _convert(\n\u001b[1;32m    554\u001b[0m     module, mapping, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, is_reference\u001b[39m=\u001b[39mis_reference,\n\u001b[1;32m    555\u001b[0m     convert_custom_config_dict\u001b[39m=\u001b[39mconvert_custom_config_dict)\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    557\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:591\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mfor\u001b[39;00m name, mod \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39mnamed_children():\n\u001b[1;32m    587\u001b[0m     \u001b[39m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    588\u001b[0m     \u001b[39m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, _FusedModule) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    590\u001b[0m        type_before_parametrizations(mod) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 591\u001b[0m         _convert(mod, mapping, \u001b[39mTrue\u001b[39;00m,  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m    592\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[1;32m    593\u001b[0m     reassign[name] \u001b[39m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    595\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m reassign\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:593\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, _FusedModule) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    590\u001b[0m        type_before_parametrizations(mod) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    591\u001b[0m         _convert(mod, mapping, \u001b[39mTrue\u001b[39;00m,  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m    592\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[0;32m--> 593\u001b[0m     reassign[name] \u001b[39m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    595\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m reassign\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    596\u001b[0m     module\u001b[39m.\u001b[39m_modules[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:626\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    624\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39mfrom_float(mod, weight_qparams)\n\u001b[1;32m    625\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 626\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39mfrom_float(mod)\n\u001b[1;32m    627\u001b[0m     swapped \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39mif\u001b[39;00m swapped:\n\u001b[1;32m    630\u001b[0m     \u001b[39m# Preserve module's pre forward hooks. They'll be called on quantized input\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/linear.py:280\u001b[0m, in \u001b[0;36mLinear.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    276\u001b[0m qweight \u001b[39m=\u001b[39m _quantize_weight(mod\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mfloat(), weight_post_process)\n\u001b[1;32m    277\u001b[0m qlinear \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(mod\u001b[39m.\u001b[39min_features,\n\u001b[1;32m    278\u001b[0m               mod\u001b[39m.\u001b[39mout_features,\n\u001b[1;32m    279\u001b[0m               dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m--> 280\u001b[0m qlinear\u001b[39m.\u001b[39mset_weight_bias(qweight, mod\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    281\u001b[0m qlinear\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(act_scale)\n\u001b[1;32m    282\u001b[0m qlinear\u001b[39m.\u001b[39mzero_point \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(act_zp)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/linear.py:241\u001b[0m, in \u001b[0;36mLinear.set_weight_bias\u001b[0;34m(self, w, b)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_weight_bias\u001b[39m(\u001b[39mself\u001b[39m, w: torch\u001b[39m.\u001b[39mTensor, b: Optional[torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params\u001b[39m.\u001b[39mset_weight_bias(w, b)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/linear.py:32\u001b[0m, in \u001b[0;36mLinearPackedParams.set_weight_bias\u001b[0;34m(self, weight, bias)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_weight_bias\u001b[39m(\u001b[39mself\u001b[39m, weight: torch\u001b[39m.\u001b[39mTensor, bias: Optional[torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mqint8:\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mquantized\u001b[39m.\u001b[39mlinear_prepack(weight, bias)\n\u001b[1;32m     33\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mquantized\u001b[39m.\u001b[39mlinear_prepack_fp16(weight, bias)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(kwargs \u001b[39mor\u001b[39;00m {}))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsupported qscheme: per_channel_affine"
     ]
    }
   ],
   "source": [
    "q_patchtst_model_int8 = torch.ao.quantization.convert(q_patchtst_model_fp32_prepared)\n",
    "q_patchtst_model_int8 #have to shift model to cpu to resolve this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantized_PatchTST(\n",
       "  (revin_layer): RevIN(\n",
       "    (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "    (dequant): DeQuantize()\n",
       "  )\n",
       "  (backbone): TSTiEncoder(\n",
       "    (W_P): QuantizedLinear(in_features=16, out_features=128, scale=0.0809154361486435, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "    (dropout): QuantizedDropout(p=0.3, inplace=False)\n",
       "    (encoder): TSTEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): QuantizedLinear(in_features=128, out_features=128, scale=0.05959759280085564, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "            (W_K): QuantizedLinear(in_features=128, out_features=128, scale=0.06977536529302597, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "            (W_V): QuantizedLinear(in_features=128, out_features=128, scale=0.05667450651526451, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): QuantizedLinear(in_features=128, out_features=128, scale=0.006176211405545473, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "              (1): QuantizedDropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): QuantizedLinear(in_features=128, out_features=128, scale=0.08210189640522003, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): QuantizedDropout(p=0.3, inplace=False)\n",
       "            (3): QuantizedLinear(in_features=128, out_features=128, scale=0.036674607545137405, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "          )\n",
       "          (dropout_ffn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "        (1): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): QuantizedLinear(in_features=128, out_features=128, scale=0.08070278912782669, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "            (W_K): QuantizedLinear(in_features=128, out_features=128, scale=0.07952979952096939, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "            (W_V): QuantizedLinear(in_features=128, out_features=128, scale=0.08579923212528229, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): QuantizedLinear(in_features=128, out_features=128, scale=0.02056431584060192, zero_point=66, qscheme=torch.per_channel_affine)\n",
       "              (1): QuantizedDropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): QuantizedLinear(in_features=128, out_features=128, scale=0.07633399963378906, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): QuantizedDropout(p=0.3, inplace=False)\n",
       "            (3): QuantizedLinear(in_features=128, out_features=128, scale=0.03564731031656265, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "          )\n",
       "          (dropout_ffn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "        (2): TSTEncoderLayer(\n",
       "          (self_attn): _MultiheadAttention(\n",
       "            (W_Q): QuantizedLinear(in_features=128, out_features=128, scale=0.08458571881055832, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "            (W_K): QuantizedLinear(in_features=128, out_features=128, scale=0.07901134341955185, zero_point=65, qscheme=torch.per_channel_affine)\n",
       "            (W_V): QuantizedLinear(in_features=128, out_features=128, scale=0.0795099288225174, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "            (sdp_attn): _ScaledDotProductAttention(\n",
       "              (attn_dropout): QuantizedDropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Sequential(\n",
       "              (0): QuantizedLinear(in_features=128, out_features=128, scale=0.024507800117135048, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "              (1): QuantizedDropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (dropout_attn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_attn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): QuantizedLinear(in_features=128, out_features=128, scale=0.08252261579036713, zero_point=62, qscheme=torch.per_channel_affine)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): QuantizedDropout(p=0.3, inplace=False)\n",
       "            (3): QuantizedLinear(in_features=128, out_features=128, scale=0.04003719985485077, zero_point=63, qscheme=torch.per_channel_affine)\n",
       "          )\n",
       "          (dropout_ffn): QuantizedDropout(p=0.3, inplace=False)\n",
       "          (norm_ffn): Sequential(\n",
       "            (0): Transpose()\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Transpose()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Flatten_Head(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (linear): QuantizedLinear(in_features=5248, out_features=96, scale=0.03611243888735771, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "    (dropout): QuantizedDropout(p=0, inplace=False)\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0718]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_patchtst_model_int8 = torch.ao.quantization.convert(q_patchtst_model_fp32_prepared.to('cpu'))\n",
    "q_patchtst_model_int8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model: 0.93 MB\n",
      "Size of model: 3.27 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"Size of model: %.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "print_model_size(q_patchtst_model_int8)\n",
    "print_model_size(patchtst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating learning rate to 4.811252243246882e-08\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "q_patchtst_learner = Quantized_Learner(model=q_patchtst_model_fp32_prepared, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "q_patchtst_learner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_patchtst_learner = Learner(model=q_patchtst_model_fp32_prepared, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n",
    "# q_patchtst_learner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_patchtst_learner = Quantized_Learner(model=q_patchtst_model_int8, dataset=ETTDataset, adjust_lr=True, adjust_factor=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     q_patchtst_learner.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
